"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[1477],{30010:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"/common-intermediate-language","metadata":{"permalink":"/blog/common-intermediate-language","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/common-intermediate-language.md","source":"@site/../../blog/common-intermediate-language.md","title":"CIL(Common Intermediate Language)","description":"Verifying your own .NET IL-Code","date":"2024-04-09T08:36:23.000Z","formattedDate":"April 9, 2024","tags":[],"readingTime":0.585,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"nextItem":{"title":"Data Center","permalink":"/blog/data-center"}},"content":"[Verifying your own .NET IL-Code](https://www.dynatrace.com/news/blog/verifying-your-own-dotnet-il-code/)\\n\\n[linux - .net-core: Equivalent of ILDASM / ILASM - Stack Overflow](https://stackoverflow.com/questions/39979851/net-core-equivalent-of-ildasm-ilasm)\\n\\n[What is Just-In-Time(JIT) Compiler in .NET - GeeksforGeeks](https://www.geeksforgeeks.org/what-is-just-in-time-jit-compiler-in-dot-net/)\\n\\n[GitHub - Konard/ILProj: The example class library project, with code written in the CIL.](https://github.com/Konard/ILProj)\\n\\n## What is CIl/IL\\n\\nFor C# or Java, the program is not directly compiled to machine code, but **intermediate language** code. For C#, the `intermediate` code is called Common Intermediate Language(CIL, or IL). So whether the `*.dll` or `*.exe` compiled from C#, is composed of IL code and its corresponding meta data. At runtime, the JIT(Just-In-Compiler) compile the IL code to the native machine code.\\n\\n## What is JIT\\n\\n```sh\\n./ilasm ~/Documents/peggy-foam-wiki/docs/IL/test/test.il -dll\\n./ildasm ~/Documents/peggy-foam-wiki/docs/IL/test/test.dll -t\\ndotnet myapp.dll\\n```"},{"id":"/data-center","metadata":{"permalink":"/blog/data-center","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/data-center.md","source":"@site/../../blog/data-center.md","title":"Data Center","description":"Economic Data","date":"2024-04-09T08:36:23.000Z","formattedDate":"April 9, 2024","tags":[],"readingTime":0.045,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"prevItem":{"title":"CIL(Common Intermediate Language)","permalink":"/blog/common-intermediate-language"},"nextItem":{"title":".NET Finalizer","permalink":"/blog/dotnet-finalizer"}},"content":"## Economic Data\\n\\n[FRED ECONOMIC DATA](https://fred.stlouisfed.org/)\\n\\n[US inflation cpi](https://tradingeconomics.com/united-states/inflation-cpi)"},{"id":"/dotnet-finalizer","metadata":{"permalink":"/blog/dotnet-finalizer","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/dotnet-finalizer.md","source":"@site/../../blog/dotnet-finalizer.md","title":".NET Finalizer","description":"c# - Finalizer launched while its object was still being used - Stack Overflow","date":"2024-04-09T08:36:23.000Z","formattedDate":"April 9, 2024","tags":[],"readingTime":0.12,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"prevItem":{"title":"Data Center","permalink":"/blog/data-center"},"nextItem":{"title":"Frequently Asked Questions","permalink":"/blog/frequently-asked-questions"}},"content":"[c# - Finalizer launched while its object was still being used - Stack Overflow](https://stackoverflow.com/questions/134653/finalizer-launched-while-its-object-was-still-being-used)\\n\\n## Tips\\n\\n1. finalizers should not be accessing managed objects."},{"id":"/frequently-asked-questions","metadata":{"permalink":"/blog/frequently-asked-questions","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/frequently-asked-questions.md","source":"@site/../../blog/frequently-asked-questions.md","title":"Frequently Asked Questions","description":"\u26a0\ufe0f Foam is still in preview. Expect the experience to be a little rough.","date":"2024-04-09T08:36:23.000Z","formattedDate":"April 9, 2024","tags":[],"readingTime":1.2,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"prevItem":{"title":".NET Finalizer","permalink":"/blog/dotnet-finalizer"},"nextItem":{"title":"Graphical User Interface(GUI)","permalink":"/blog/graphical-user-interface"}},"content":"> \u26a0\ufe0f Foam is still in preview. Expect the experience to be a little rough.\\n\\n- [Frequently Asked Questions](#frequently-asked-questions)\\n  - [Links/Graphs/BackLinks don\'t work. How do I enable them?](#linksgraphsbacklinks-dont-work-how-do-i-enable-them)\\n  - [I don\'t want Foam enabled for all my workspaces](#i-dont-want-foam-enabled-for-all-my-workspaces)\\n  - [I want to publish the graph view to GitHub pages or Vercel](#i-want-to-publish-the-graph-view-to-github-pages-or-vercel)\\n\\n## Links/Graphs/BackLinks don\'t work. How do I enable them?\\n\\n- Ensure that you have all the [[recommended-extensions]] installed in Visual Studio Code\\n- Reload Visual Studio Code by running `Cmd` + `Shift` + `P` (`Ctrl` + `Shift` + `P` for Windows), type \\"reload\\" and run the **Developer: Reload Window** command to for the updated extensions take effect\\n- Check the formatting rules for links on [[foam-file-format]] and [[wikilinks]]\\n\\n## I don\'t want Foam enabled for all my workspaces\\nAny extension you install in Visual Studio Code is enabled by default. Given the philosophy of Foam, it works out of the box without doing any configuration upfront. In case you want to disable Foam for a specific workspace, or disable Foam by default and enable it for specific workspaces, it is advised to follow the best practices as [documented by Visual Studio Code](https://code.visualstudio.com/docs/editor/extension-marketplace#_manage-extensions)\\n\\n## I want to publish the graph view to GitHub pages or Vercel\\nIf you want a different front-end look to your published foam and a way to see your graph view, we\'d recommend checking out these templates:\\n- [foam-gatsby](https://github.com/mathieudutour/foam-gatsby-template) by [Mathieu Dutour](https://github.com/mathieudutour)\\n- [foam-gatsby-kb](https://github.com/hikerpig/foam-template-gatsby-kb) by [hikerpig](https://github.com/hikerpig)"},{"id":"/graphical-user-interface","metadata":{"permalink":"/blog/graphical-user-interface","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/graphical-user-interface.md","source":"@site/../../blog/graphical-user-interface.md","title":"Graphical User Interface(GUI)","description":"Modern GUI composition of:","date":"2024-04-09T08:36:23.000Z","formattedDate":"April 9, 2024","tags":[],"readingTime":1.155,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"prevItem":{"title":"Frequently Asked Questions","permalink":"/blog/frequently-asked-questions"},"nextItem":{"title":"IoC","permalink":"/blog/ioc"}},"content":"Modern GUI composition of:\\n\\n- Windowing System/Compositor\\n  - Quartz Compositor(OSX)\\n  - Desktop Window Manager(Windows)\\n  - X11(Linux)\\n  - Wayland(Linux)\\n  - SurfaceFlinger(Android)\\n- Graphic Rendering\\n  - Hardware-Accelerated Rendering\\n    - OpenGL\\n    - Vulkan\\n    - DirectX\\n  - Software Rendering\\n    - QT Rasterization Engine\\n\\nWindowing System\\n\\nIt\'s very essential to apply the `native Windowing System` library for Cross-platform GUI framework in different platforms. Here\'s a cue from [including native windowing system headers from GLFW](https://github.com/glfw/glfw/blob/3a60992a418aad88717db32353bec22e8bb7dab3/include/GLFW/glfw3native.h#L94-L118)\\n\\n```c\\n#if !defined(GLFW_NATIVE_INCLUDE_NONE)\\n #if defined(GLFW_EXPOSE_NATIVE_WIN32) || defined(GLFW_EXPOSE_NATIVE_WGL)\\n  /* This is a workaround for the fact that glfw3.h needs to export APIENTRY (for\\n   * example to allow applications to correctly declare a GL_KHR_debug callback)\\n   * but windows.h assumes no one will define APIENTRY before it does\\n   */\\n  #if defined(GLFW_APIENTRY_DEFINED)\\n   #undef APIENTRY\\n   #undef GLFW_APIENTRY_DEFINED\\n  #endif\\n  #include <windows.h>\\n #elif defined(GLFW_EXPOSE_NATIVE_COCOA) || defined(GLFW_EXPOSE_NATIVE_NSGL)\\n  #if defined(__OBJC__)\\n   #import <Cocoa/Cocoa.h>\\n  #else\\n   #include <ApplicationServices/ApplicationServices.h>\\n   #include <objc/objc.h>\\n  #endif\\n #elif defined(GLFW_EXPOSE_NATIVE_X11) || defined(GLFW_EXPOSE_NATIVE_GLX)\\n  #include <X11/Xlib.h>\\n  #include <X11/extensions/Xrandr.h>\\n #elif defined(GLFW_EXPOSE_NATIVE_WAYLAND)\\n  #include <wayland-client.h>\\n #endif\\n```\\n\\n[Windowing system - Wikipedia](https://en.wikipedia.org/wiki/Windowing_system)\\n\\n[GUI Under Linux | Baeldung on Linux](https://www.baeldung.com/linux/gui)\\n\\n[GTK - Wikipedia](https://en.wikipedia.org/wiki/GTK)\\n\\nGraphic Render APIs/Libraries\\n\\n[A Comparison of Modern Graphics APIs](https://alain.xyz/blog/comparison-of-modern-graphics-apis)\\n\\n## Android graphics\\n\\ntwo core pieces:\\n\\n- SurfaceFlinger\\n- Skia\\n\\n[Graphics \xa0|\xa0 Android Open Source Project](https://source.android.com/devices/graphics)\\n[Android Graphics Internals - Stack Overflow](https://stackoverflow.com/questions/4579573/android-graphics-internals)\\n\\n## WayLand\\n\\n[What is Wayland? \xb7 Writing Wayland clients](https://bugaevc.gitbooks.io/writing-wayland-clients/content/about-this-book/what-is-wayland.html)\\n\\n[The Hello Wayland Tutorial | FLOSS & Cia](https://hdante.wordpress.com/2014/07/08/the-hello-wayland-tutorial/)\\n\\n[How to use Wayland with C to make a Linux app | by Sergey Bugaev | Medium](https://medium.com/@bugaevc/how-to-use-wayland-with-c-to-make-a-linux-app-c2673a35ce05)"},{"id":"/ioc","metadata":{"permalink":"/blog/ioc","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/ioc.md","source":"@site/../../blog/ioc.md","title":"IoC","description":"Introduction IoC, DIP, DI and IoC Container","date":"2024-04-09T08:36:23.000Z","formattedDate":"April 9, 2024","tags":[{"label":"circular-dependencies","permalink":"/blog/tags/circular-dependencies"},{"label":"inversion-of-control","permalink":"/blog/tags/inversion-of-control"},{"label":"dependency-injection","permalink":"/blog/tags/dependency-injection"}],"readingTime":0.16,"hasTruncateMarker":false,"authors":[],"frontMatter":{"tags":["circular-dependencies","inversion-of-control","dependency-injection"]},"prevItem":{"title":"Graphical User Interface(GUI)","permalink":"/blog/graphical-user-interface"},"nextItem":{"title":"LevelDB","permalink":"/blog/leveldb"}},"content":"[Introduction IoC, DIP, DI and IoC Container](https://www.tutorialsteacher.com/ioc/introduction)\\n\\n[Lazily resolving services to fix `circular dependencies` in .NET Core - Thomas Levesque\'s .NET Blog](https://thomaslevesque.com/2020/03/18/lazily-resolving-services-to-fix-circular-dependencies-in-net-core/)\\n\\n[Dealing With `Circular Dependency` Injection References - .NET Core Tutorials](https://dotnetcoretutorials.com/2020/09/14/dealing-with-circular-dependency-injection-references/)"},{"id":"/leveldb","metadata":{"permalink":"/blog/leveldb","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/leveldb.md","source":"@site/../../blog/leveldb.md","title":"LevelDB","description":"Principle and use of leveldb - Birost","date":"2024-04-09T08:36:23.000Z","formattedDate":"April 9, 2024","tags":[],"readingTime":0.085,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"prevItem":{"title":"IoC","permalink":"/blog/ioc"},"nextItem":{"title":"Your markdown including PlantUML code block","permalink":"/blog/markdown-plantuml"}},"content":"[Principle and use of leveldb - Birost](https://blog.birost.com/a?ID=00650-1d5c18b6-1dac-46da-bbf8-80a5257e7bdd)\\n\\n[SSTable and Log Structured Storage: LevelDB - igvita.com](https://www.igvita.com/2012/02/06/sstable-and-log-structured-storage-leveldb/)\\n\\n[LevelDB Benchmarks](http://www.lmdb.tech/bench/microbench/benchmark.html)"},{"id":"/markdown-plantuml","metadata":{"permalink":"/blog/markdown-plantuml","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/markdown-plantuml.md","source":"@site/../../blog/markdown-plantuml.md","title":"Your markdown including PlantUML code block","description":"","date":"2024-04-09T08:36:23.000Z","formattedDate":"April 9, 2024","tags":[],"readingTime":0.665,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"prevItem":{"title":"LevelDB","permalink":"/blog/leveldb"},"nextItem":{"title":"OpenCV tips","permalink":"/blog/opencv-tips"}},"content":"```plantumlcode\\n@startuml\\n:User: --\x3e (Use)\\n\\"Main Admin\\" as Admin\\n\\"Use the application\\" as (Use)\\nAdmin --\x3e (Admin the application)\\n@enduml\\n```\\n\\n```plantuml\\n@startuml\\nAlice -> Bob: Authentication Request\\nBob --\x3e Alice: Authentication Response\\n\\nAlice -> Bob: Another authentication Request\\nAlice <-- Bob: Another authentication Response\\n@enduml\\n```\\n\\n```plantuml\\n@startuml\\n!include <material/common>\\n\' To import the sprite file you DON\'T need to place a prefix!\\n!include <material/folder_move>\\n\\nMA_FOLDER_MOVE(Black, 1, dir, rectangle, \\"A label\\")\\n\\nfile \\"source code\\\\n<$ma_folder_move>\\" as code\\nfile CMakefiles\\n@enduml\\n```\\n\\n```plantuml\\n@startuml\\n!include <material/common>\\n!include <material/code_braces>\\n!include <material/code_array>\\n!include <material/code_brackets>\\n!include <material/code_parentheses>\\n!include <material/code_tags>\\n\\nMA_CODE_BRACES(Black, 1, source, file, \\"Source Code\\")\\nMA_CODE_ARRAY(Black, 1, cmake, file, \\"CMakefiles.txt\\")\\nMA_CODE_ARRAY(Black, 1, make, file, \\"Makefile\\")\\nMA_CODE_ARRAY(Black, 1, msbuild, file, \\"MSBuild\\") {\\n}\\n\\nfile Source[\\nSource Code\\n<$ma_code_braces>\\n]\\n\\nfile \\"Source Code\\" {\\n    file \\"<$ma_code_braces>\\"\\n}\\n@enduml\\n```"},{"id":"/opencv-tips","metadata":{"permalink":"/blog/opencv-tips","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/opencv-tips.md","source":"@site/../../blog/opencv-tips.md","title":"OpenCV tips","description":"Q: Whether the image/frame from VideoCapture is in BGR or YUV pixels format?","date":"2024-04-09T08:36:23.000Z","formattedDate":"April 9, 2024","tags":[],"readingTime":0.19,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"prevItem":{"title":"Your markdown including PlantUML code block","permalink":"/blog/markdown-plantuml"},"nextItem":{"title":"Python Benchmark","permalink":"/blog/python-benchmark"}},"content":"Q: Whether the image/frame from VideoCapture is in `BGR` or `YUV` pixels format?\\nA:\\nVideoCapture will convert the image automatically to BGR colorspace.\\nyou can disable this conversion (and receive YUV) by setting the CAP_PROP_CONVERT_RGB property to false."},{"id":"/python-benchmark","metadata":{"permalink":"/blog/python-benchmark","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/python-benchmark.md","source":"@site/../../blog/python-benchmark.md","title":"Python Benchmark","description":"Ok, here is the cost of acquiring and releasing an uncontended lock","date":"2024-04-09T08:36:23.000Z","formattedDate":"April 9, 2024","tags":[],"readingTime":1.06,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"prevItem":{"title":"OpenCV tips","permalink":"/blog/opencv-tips"},"nextItem":{"title":"Python Module","permalink":"/blog/python-module"}},"content":"Ok, here is the cost of acquiring and releasing an uncontended lock\\nunder Linux, with Python 3.2:\\n\\n```sh\\n$ ./python -m timeit \\\\\\n  -s \\"from threading import Lock; l=Lock(); a=l.acquire; r=l.release\\" \\\\\\n  \\"a(); r()\\"\\n10000000 loops, best of 3: 0.127 usec per loop\\n```\\n\\nAnd here is the cost of calling a dummy Python function:\\n\\n```sh\\n$ ./python -m timeit -s \\"def a(): pass\\" \\"a(); a()\\"\\n1000000 loops, best of 3: 0.221 usec per loop\\n```\\n\\nAnd here is the cost of calling a trivial C function (which returns the\\nFalse singleton):\\n\\n```sh\\n$ ./python -m timeit -s \\"a=bool\\" \\"a(); a()\\"\\n10000000 loops, best of 3: 0.164 usec per loop\\n```\\n\\nAlso, note that using the lock as a context manager is actually slower,\\nnot faster as you might imagine:\\n\\n```sh\\n$ ./python -m timeit -s \\"from threading import Lock; l=Lock()\\" \\\\\\n  \\"with l: pass\\"\\n1000000 loops, best of 3: 0.242 usec per loop\\n```\\n\\nAt least under Linux, there doesn\'t seem to be a lot of room for\\nimprovement in lock performance, to say the least.\\n\\nPS: RLock is now as fast as Lock:\\n\\n```sh\\n$ ./python -m timeit \\\\\\n-s \\"from threading import RLock; l=RLock(); a=l.acquire; r=l.release\\" \\\\\\n\\"a(); r()\\"\\n10000000 loops, best of 3: 0.114 usec per loop\\n```"},{"id":"/python-module","metadata":{"permalink":"/blog/python-module","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/python-module.md","source":"@site/../../blog/python-module.md","title":"Python Module","description":"Python Module Search Path","date":"2024-04-09T08:36:23.000Z","formattedDate":"April 9, 2024","tags":[],"readingTime":0.075,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"prevItem":{"title":"Python Benchmark","permalink":"/blog/python-benchmark"},"nextItem":{"title":"RPC vs MQ","permalink":"/blog/rpc_vs_mq"}},"content":"## Python Module Search Path\\n\\n[The Module Search Path](https://docs.python.org/3/tutorial/modules.html#the-module-search-path)\\n\\n[Introduction to Python module search path](https://www.pythontutorial.net/python-basics/python-module-search-path/)"},{"id":"/rpc_vs_mq","metadata":{"permalink":"/blog/rpc_vs_mq","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/rpc_vs_mq.md","source":"@site/../../blog/rpc_vs_mq.md","title":"RPC vs MQ","description":"RPC: synchronous, client needs to preserve the request until the client receives response.","date":"2024-04-09T08:36:23.000Z","formattedDate":"April 9, 2024","tags":[],"readingTime":0.305,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"prevItem":{"title":"Python Module","permalink":"/blog/python-module"},"nextItem":{"title":"Serialization","permalink":"/blog/serialization"}},"content":"RPC: synchronous, client needs to preserve the request until the client receives response.\\nMQ(Message Queue): asynchronous, there is no need for client to wait for the response.\\n\\n[RPC vs. Messaging \u2013 which is faster?](https://particular.net/blog/rpc-vs-messaging-which-is-faster)\\n\\n\\n[Low-latency communication of micro-services in remote, IPC and threading scenarios](https://stackoverflow.com/questions/54091672/low-latency-communication-of-micro-services-in-remote-ipc-and-threading-scenari)\\n\\n## RPC\\n\\n## IPC\\n\\nIPC: (local)Inter-Process Communication\\n\\n[Using gRPC for (local) inter-process communication](https://www.mpi-hd.mpg.de/personalhomes/fwerner/research/2021/09/grpc-for-ipc/)\\n\\n\\n[IPC Benchmark](https://github.com/goldsborough/ipc-bench)\\n\\n## MQ"},{"id":"/serialization","metadata":{"permalink":"/blog/serialization","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/serialization.md","source":"@site/../../blog/serialization.md","title":"Serialization","description":"Serialization","date":"2024-04-09T08:36:23.000Z","formattedDate":"April 9, 2024","tags":[],"readingTime":0.49,"hasTruncateMarker":false,"authors":[],"frontMatter":{"type":"data-structure","keywords":["MessagePack","msgpack","json","serialization","Protocol Buffers","Protobuf"],"tag":["msgpack","data structure"]},"prevItem":{"title":"RPC vs MQ","permalink":"/blog/rpc_vs_mq"},"nextItem":{"title":"Wiki Skia","permalink":"/blog/wiki-skia"}},"content":"[Serialization](https://en.wikipedia.org/wiki/Serialization)\\n\\n[The need for speed \u2014 Experimenting with message serialization](https://medium.com/@hugovs/the-need-for-speed-experimenting-with-message-serialization-93d7562b16e4)\\n\\n[MessagePack, Json, Protobuf](https://github.com/neuecc/MessagePack-CSharp/issues/819#issuecomment-586125191)\\n\\nIn computing, `serialization` is the process of translating a data structure or object into a format that can be stored(for example, in a file or memory buffer) or transmitted(for example, over a computer network) and reconstructed later (possibly in a different computer environment).\\n\\n## Json\\n\\n## MessagePack\\n\\n[msgpack GitHub](https://github.com/msgpack/msgpack)\\n\\n## Protocol Buffers\\n\\n[Protocol Buffers](https://developers.google.com/protocol-buffers)\\n\\n## Supported Features\\n\\n| Protocol    | Discriminator Property & Polymorphism |\\n| ----------- | :-----------------------------------: |\\n| Json        |                   \u2714\ufe0f                   |\\n| MessagePack |                   \u2714\ufe0f                   |\\n| Protobuf    |                   \u2716\ufe0f                   |"},{"id":"/wiki-skia","metadata":{"permalink":"/blog/wiki-skia","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-skia.md","source":"@site/../../blog/wiki-skia.md","title":"Wiki Skia","description":"What the difference between SkImage/SkPicture/SkCanvas/SkSurface?","date":"2024-04-09T08:36:23.000Z","formattedDate":"April 9, 2024","tags":[],"readingTime":0.54,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"prevItem":{"title":"Serialization","permalink":"/blog/serialization"},"nextItem":{"title":"Wiki VPN","permalink":"/blog/wiki-vpn"}},"content":"[What the difference between SkImage/SkPicture/SkCanvas/SkSurface?](https://groups.google.com/g/skia-discuss/c/rNWV-oYtps)\\n\\n[SkBitmap based SkCanvas very slow... How to improve draw speeds?](https://groups.google.com/g/skia-discuss/c/zatUu89s5_I)\\n\\n[How to move SkImage from CPU to GPU?](https://groups.google.com/g/skia-discuss/c/M6G_bQd8Vf8)\\n\\n[How to control the SkImage GPU back cache size?](https://groups.google.com/g/skia-discuss/c/EqvExXnEUbI)\\n\\nAs far as I understand when I load SkImage from file or SkBitmap the SkImage lives in CPU side memory. Then the moment I draw this SkImage on a GPU backed canvas it will make a copy of the CPU data into a GPU backed texture. So now we technically have two copies available on the SkImage. Then each time I draw that SkImage it will do it quickly cause it\'s already in the GPU side."},{"id":"/wiki-vpn","metadata":{"permalink":"/blog/wiki-vpn","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-vpn.md","source":"@site/../../blog/wiki-vpn.md","title":"Wiki VPN","description":"OpenVPN: how secure virtual private networks really work","date":"2024-04-09T08:36:23.000Z","formattedDate":"April 9, 2024","tags":[{"label":"network","permalink":"/blog/tags/network"},{"label":"network/vpn","permalink":"/blog/tags/network-vpn"},{"label":"network/router","permalink":"/blog/tags/network-router"}],"readingTime":0.8,"hasTruncateMarker":false,"authors":[],"frontMatter":{"keywords":["vpn"],"tags":["network","network/vpn","network/router"],"more_data":["Can be provided",{"as":"objects","or":"arrays"}]},"prevItem":{"title":"Wiki Skia","permalink":"/blog/wiki-skia"},"nextItem":{"title":"Cheatsheet ImageMagick","permalink":"/blog/cheatsheet-imagemagick"}},"content":"[OpenVPN: how secure virtual private networks really work](https://cloudacademy.com/blog/openvpn-how-secure-virtual-private-networks-really-work/)\\n> !!!Favorite explanation\\n\\n[ip - How do VPN\'s forward network traffic? (Layer 3) - Network Engineering Stack Exchange](https://networkengineering.stackexchange.com/questions/51159/how-do-vpns-forward-network-traffic-layer-3)\\n\\n## Routers Support for VPN(OpenVPN) Client\\n\\n[How to set up a router with Surfshark? \u2013 Surfshark Customer Support](https://support.surfshark.com/hc/en-us/articles/360003103833-How-to-set-up-a-router-with-Surfshark-)\\n\\n[Routers Supporting VPN Client - Home Network Community](https://community.tp-link.com/en/home/forum/topic/272492)\\n\\n## Kill Switch\\n\\nKillSwitch could be used to block outgoing traffic when the VPN connection drops and crashes.\\n\\n## PF(packet filter) MacOS\\n\\n[Setting up correctly Packet Filter (pf) firewall on any macOS](https://iyanmv.medium.com/setting-up-correctly-packet-filter-pf-firewall-on-any-macos-from-sierra-to-big-sur-47e70e062a0e)\\n\\n[Prevent outgoing traffic unless OpenVPN connection is active using pf.conf on Mac OS X](https://superuser.com/questions/468919/prevent-outgoing-traffic-unless-openvpn-connection-is-active-using-pf-conf-on-ma)\\n\\n[Quick and easy pf (packet filter) firewall rules on macOS](https://blog.neilsabol.site/post/quickly-easily-adding-pf-packet-filter-firewall-rules-macos-osx/)\\n\\n[A Cheat Sheet For Using pf in OS X Lion and Up](https://krypted.com/mac-security/a-cheat-sheet-for-using-pf-in-os-x-lion-and-up/)\\n\\n[OS X PF Manual](https://murusfirewall.com/Documentation/OS%20X%20PF%20Manual.pdf)\\n\\n## Set Up Firewall to Allow Access Only via VPN(KillSwitch)\\n\\n[ENABLING VPN-ONLY ACCESS TO THE INTERNET WITH WINDOWS FIREWALL](https://zorrovpn.com/articles/windows-firewall-vpn-only?lang=en)\\n\\n[KillSwitch for macOS](https://github.com/vpn-kill-switch/killswitch)\\n\\n[Prevent outgoing traffic unless OpenVPN connection is active using pf.conf on Mac OS X](https://superuser.com/questions/468919/prevent-outgoing-traffic-unless-openvpn-connection-is-active-using-pf-conf-on-ma)"},{"id":"/cheatsheet-imagemagick","metadata":{"permalink":"/blog/cheatsheet-imagemagick","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/cheatsheet-imagemagick.mdx","source":"@site/../../blog/cheatsheet-imagemagick.mdx","title":"Cheatsheet ImageMagick","description":"Cheatsheet ImageMagick","date":"2024-04-02T00:00:00.000Z","formattedDate":"April 2, 2024","tags":[{"label":"cheatsheet","permalink":"/blog/tags/cheatsheet"},{"label":"ImageMagick","permalink":"/blog/tags/image-magick"}],"readingTime":0.46,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["cheatsheet","ImageMagick"],"description":"Cheatsheet ImageMagick","keywords":["Cheatsheet ImageMagick"],"image":"https://i.imgur.com/mErPwqL.png","date":"2024-04-02T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Wiki VPN","permalink":"/blog/wiki-vpn"},"nextItem":{"title":"How to intercept HTTPs traffic from Android Emulator","permalink":"/blog/how-to-intercept-https-traffic-from-android-emulator"}},"content":"\x3c!--truncate--\x3e\\n## Convert a PNG file to a JPG file\\n\\n```sh\\nconvert input.png \\\\\\n    -density 150 \\\\\\n    -define jpeg:extent=500KB \\\\\\n    output.jpg\\n```\\n\\n\\n```sh\\nconvert input.png \\\\\\n    -density 150 \\\\\\n    -quality 50 \\\\\\n    output.jpg\\n```\\n\\n\\n## Convert a PDF to a series of PNG files\\n\\n```sh\\nconvert                  \\\\\\n    <your-PDF-file>.pdf  \\\\\\n   -density 150          \\\\\\n   -trim                 \\\\\\n   -verbose              \\\\\\n    page%d.png\\n```\\n\\n## Convert a PDF to a series of JPG files\\n\\n```sh\\nconvert                  \\\\\\n   -density 150          \\\\\\n   -trim                 \\\\\\n    <your-PDF-file>.pdf  \\\\\\n   -quality 100          \\\\\\n   -flatten              \\\\\\n   -sharpen 0x1.0        \\\\\\n   -verbose              \\\\\\n    page%d.jpg\\n```\\n\\n## Resources"},{"id":"/how-to-intercept-https-traffic-from-android-emulator","metadata":{"permalink":"/blog/how-to-intercept-https-traffic-from-android-emulator","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/how-to-intercept-https-traffic-from-android-emulator.mdx","source":"@site/../../blog/how-to-intercept-https-traffic-from-android-emulator.mdx","title":"How to intercept HTTPs traffic from Android Emulator","description":"How to intercept HTTPs traffic from Android Emulator","date":"2024-03-25T00:00:00.000Z","formattedDate":"March 25, 2024","tags":[{"label":"how-to intercept","permalink":"/blog/tags/how-to-intercept"},{"label":"HTTPs","permalink":"/blog/tags/htt-ps"},{"label":"Android","permalink":"/blog/tags/android"}],"readingTime":1.345,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["how-to intercept","HTTPs","Android"],"description":"How to intercept HTTPs traffic from Android Emulator","keywords":["intercept HTTPs traffic","Android Emulator"],"image":"https://i.imgur.com/mErPwqL.png","date":"2024-03-25T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Cheatsheet ImageMagick","permalink":"/blog/cheatsheet-imagemagick"},"nextItem":{"title":"Python Wiki","permalink":"/blog/wiki-python"}},"content":"Capturing HTTPS traffic from an Android device can be a crucial aspect of testing and debugging applications. Additionally, gaining insight into decrypted HTTPS messages can offer valuable information for troubleshooting or security analysis, albeit with ethical considerations in mind. Here, we explore two methods to achieve this: via an HTTPs proxy or a VPN.\\n\\nMethods:\\n\\n- HTTPs Proxy:\\n    - Using an HTTPS proxy is a common approach to intercepting traffic from an Android device. This method involves setting up a proxy server that acts as an intermediary between the device and the internet, allowing for the capture and analysis of HTTPS requests and responses. \\n    - However, you have to install the Proxy SSL certificate on the Android device to facilitate decryption.\\n\\n- VPN Server:\\n    - Alternatively, leveraging a Virtual Private Network (VPN) can intercept HTTPS traffic from an Android device. By directing traffic through a VPN server, it becomes feasible to capture and analyze HTTPS requests and responses in transit.\\n\\nTools:\\n- MITM (Man In The Middle) Proxy: A versatile tool for intercepting and modifying HTTP and HTTPS traffic.\\n- Proxyman: A user-friendly proxy tool with advanced features tailored for macOS and iOS devices, but also compatible with Android via manual proxy setup.\\n- Fiddler Proxy: A robust proxy tool with powerful debugging capabilities, including support for decrypting HTTPS traffic.\\n- Charles Proxy: A popular proxy tool known for its comprehensive debugging features, including SSL proxying for inspecting encrypted traffic.\\n- HTTP Toolkit: A modern, cross-platform tool designed for intercepting, debugging, and mocking HTTP and HTTPS traffic.\\n\\n\x3c!--truncate--\x3e\\n\\n## Resources\\n\\nhttps://medium.com/hackernoon/intercept-https-traffic-on-a-android-emulator-46023f17f6b3\\n\\nhttps://httptoolkit.com/docs/guides/android/\\n\\nhttps://proxyman.io/posts/2020-09-19-Intercept-https-traffic-on-android-emulator\\n\\nhttps://kpj.github.io/misc/InterceptingHTTPTraffic.html\\n\\nhttps://www.reddit.com/r/androiddev/comments/17nfwyn/easiest_way_to_inspect_network_traffic_coming/\\n\\nhttps://docs.telerik.com/fiddler-everywhere/capture-traffic/capture-from-android\\n\\nhttps://www.linkedin.com/pulse/intercept-sslhttps-traffic-perform-penetration-testing-mayank-grover/\\n\\nhttps://www.reddit.com/r/androiddev/comments/14x8eed/way_or_viewing_network_requests/\\n\\nhttps://beguier.eu/nicolas/articles/android-mitm-intercept-trafic.html"},{"id":"/wiki-python","metadata":{"permalink":"/blog/wiki-python","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-python.mdx","source":"@site/../../blog/wiki-python.mdx","title":"Python Wiki","description":"Wiki Python","date":"2024-03-11T00:00:00.000Z","formattedDate":"March 11, 2024","tags":[{"label":"wiki","permalink":"/blog/tags/wiki"},{"label":"python","permalink":"/blog/tags/python"}],"readingTime":0.045,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["wiki","python"],"description":"Wiki Python","keywords":["Wiki Python"],"image":"https://i.imgur.com/mErPwqL.png","date":"2024-03-11T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"How to intercept HTTPs traffic from Android Emulator","permalink":"/blog/how-to-intercept-https-traffic-from-android-emulator"},"nextItem":{"title":"Algorithms","permalink":"/blog/algorithms"}},"content":"## Typing\\n\\n[Type hints cheat sheet](https://mypy.readthedocs.io/en/stable/cheat_sheet_py3.html)\\n\\n\x3c!--truncate--\x3e\\n\\n## Resources"},{"id":"/algorithms","metadata":{"permalink":"/blog/algorithms","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/algorithms.mdx","source":"@site/../../blog/algorithms.mdx","title":"Algorithms","description":"algorithm","date":"2024-02-27T00:00:00.000Z","formattedDate":"February 27, 2024","tags":[{"label":"algorithm","permalink":"/blog/tags/algorithm"},{"label":"maths","permalink":"/blog/tags/maths"}],"readingTime":0.695,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["algorithm","maths"],"description":"algorithm","keywords":["algorithm"],"image":"https://i.imgur.com/mErPwqL.png","date":"2024-02-27T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Python Wiki","permalink":"/blog/wiki-python"},"nextItem":{"title":"Wiki Compiler","permalink":"/blog/wiki-compiler"}},"content":"As it is known that algorithms and data structures are the prime of computer programming. With algorithms and data structures, the better high-level features in applications we can develop and implement. Outstanding algorithms means faster time and less space. `O(1)` on both of time complexity and space must be the best as taking the constant time and the constant space, but it\'s rarely to achieve in practice. Next, `O(log n)` is mostly desirable for most applications on real occasion.\\n\\nOf course, you\'ll go through algorithms questions in a lot of interviews for programming-related positions.\\n\\nHere are proofs for the correctness of some common algorithms, that I\'d like to understand and prove them in mathematics.\\n\\n\x3c!--truncate--\x3e\\n\\n## Boyer\u2013Moore majority vote algorithm\\n\\nJust run one loop to find the majority in an array.\\n\\nTime complexity: `O(n)`\\nSpace complexity: `O(1)`\\n\\n\\n## Resources"},{"id":"/wiki-compiler","metadata":{"permalink":"/blog/wiki-compiler","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-compiler.mdx","source":"@site/../../blog/wiki-compiler.mdx","title":"Wiki Compiler","description":"Introduction for writing a Compiler in practice","date":"2024-02-19T00:00:00.000Z","formattedDate":"February 19, 2024","tags":[{"label":"Wiki","permalink":"/blog/tags/wiki"},{"label":"Compiler","permalink":"/blog/tags/compiler"}],"readingTime":4.165,"hasTruncateMarker":false,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["Wiki","Compiler"],"description":"Introduction for writing a Compiler in practice","keywords":["Writing Compiler"],"image":"https://i.imgur.com/mErPwqL.png","date":"2024-02-19T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Algorithms","permalink":"/blog/algorithms"},"nextItem":{"title":"Wiki Socket","permalink":"/blog/wiki-socket"}},"content":"# Overview\\n\\nLet\'s have a look at the functions that a compiler should be able to build.\\n\\n1. lexer(Lexical analysis)\\n   - generate tokens from source code\\n2. parser\\n   - construct abstract syntax tree(AST) from tokens\\n3. code generation\\n   - generate low-level code, such as assembly code or machine code\\n\\n## Parser\\n\\n`BNF` syntax is used to for computer to understand the expression, and is a critical concept to be followed to sequently parse the tokens to AST tree. Certainly, only one loop on the tokens is enough, which makes it very efficient.\\n\\n`BNF` syntax for arithmetic operations grammar, including `+`, `-`, `*`, `\\\\`, and `u-`(unary `-`) .\\n\\n```sh\\nexpression  :   term\\n            |   expression `+` expression\\n            |   expression `-` expression\\n\\nterm        :   factor\\n            |   term `*` term\\n            |   term `/` term\\n\\nfactor      :   NUMBER\\n            |   `(` expression `)`\\n            |   `u-`factor\\n            |   `u+`factor\\n\\n```\\n\\n`BNF` syntax for arithmetic operations and variable assignment.\\n\\n```sh\\nexpression  :   term\\n            |   expression `+` expression\\n            |   expression `-` expression\\n\\nterm        :   factor\\n            |   term `*` term\\n            |   term `/` term\\n            |   term `%` term\\n\\nfactor      :   NUMBER\\n            |   ID\\n            |   `(` expression `)`\\n            |   `u-`factor\\n            |   `u+`factor\\n            |   assignment\\n\\nassignment  :   ID `=` expression\\n```\\n\\nIn addition, `BNF` can also be applied to define regular expressions:\\n\\n```sh\\nexpression      :   term\\n                |   term `|` term\\n\\nterm            :   factor\\n                |   term term\\n\\nfactor          :   atom\\n                |   atom `*`\\n\\natom            :   CHAR\\n                | `(` expression `)`\\n\\nCHAR            : any valid character except meta characters (e.g., \\"*\\", \\"|\\", \\"(\\")\\n```\\n\\n## Difference between Compiler and Interpreter\\n\\nan **interpreter** also does `lexer` and `parser` jobs as a compiler does in step 1 and 2, but instead of generating low-level code, the **interpreter** generates the results directly.\\n\\n## Bootstrap a compiler\\n\\nA new programming language and a compiler written also in the new language is supposed to develop from an existing language. The progress is called **bootstrapping**, which can be summarized as,\\n\\n```sh\\nC1  + L1  -> C20\\nC20 + L2u -> C21\\nC21 + L2  -> C22\\nC22 + L2  -> C23\\nC23 + L2  -> C24\\n```\\n\\n`L1` : an existing language \\n`C1` : an existing compiler for language `L1`\\n`C20`: a compiler written in language `L1` for language `L2u`\\n`C21`: a compiler written in language `L2u` for language `L2`\\n`L2u`: is subset of language `L2`\\n\\nBootstrapping stage:\\n\\n1. Write a bootstrap compiler `C20` to understand language `L2u`(a subset of language `L2`) in using existed language `L1` and its corresponding compiler `C1`.\\n2. Use the compiler `C20` and language `L2u` to write the compiler `C21` to understand language `L2`.\\n3. Now `C21` is a fully self-hosted compiler, as well as its descendants `C22`, `C23`, and `C24`.\\n\\n### Where did the existing compiler `C1` come from?\\n\\nThere is no need to use a compiler `C1` + `L1` if you write the bootstrap compiler `C20` in machine code. This solves the chicken-and-egg problem totally for programming languages.\\n\\n1. Bootstrapping initial compiler `C20`:\\n   1. A small and simple compiler is created manually in machine code or written in `assembly` language.\\n   2. [Option*] Translate the `assembly` language into machine code manually if it\'s not written in machine code.\\n   3. The initial compiler is just capable enough to understand a subset of the target language `C` it is supposed to compile.\\n2. Use the initial compiler `C20` to compile the compiler `C21` written in language `C` while the `C21` is also supposed to compile language `C`.\\n3. Now compiler `C21` a fully self-compilation.\\n\\n[Strange Loops: Ken Thompson and the Self-referencing C Compiler | ScienceBlogs](https://scienceblogs.com/goodmath/2007/04/15/strange-loops-dennis-ritchie-a)\\n\\n[Bootstrapping (compilers) - Wikipedia](https://en.wikipedia.org/wiki/Bootstrapping_%28compilers%29)\\n\\n[Compilers: Principles, Techniques, and Tools - Wikipedia](http://en.wikipedia.org/wiki/Compilers:_Principles,_Techniques,_and_Tools)\\n\\n### Implementations\\n\\nInterpreter:\\n\\n- [GitHub - rswier/c4: C in four functions](https://github.com/rswier/c4)\\n- [GitHub - lotabout/write-a-C-interpreter: Write a simple interpreter of C. Inspired by c4 and largely based on it.](https://github.com/lotabout/write-a-C-interpreter)\\n\\nSelf-hosted Compiler:\\n\\n- [GitHub - DoctorWkt/acwj: A Compiler Writing Journey](https://github.com/DoctorWkt/acwj)\\n- [GitHub - certik/bcompile: Bootstrapping a simple compiler from nothing](https://github.com/certik/bcompile)\\n\\nThe basic knowledge of `lexer` and `parser` is critical and necessary for developing a programming language, \\n- `flex/lex`\\n- `yacc/parser`\\n\\n### Compiler for a subset of C language bootstrapping from Python\\n\\nRecently, I am becoming interested in building a `lexer`, `parser` and `code generator` to try to create a mini language and deep insight of how `GCC` or `Clang/LLVM` do their jobs.\\n\\nFor educational purposes, learning in practice is my favorite approach to grasp an overview.\\n\\nLet\'s do it!\\n\\nPrerequisites:\\n\\n- Python for writing the bootstrap compiler \\n\\nI use [ply](https://ply.readthedocs.io/_/downloads/en/latest/pdf/), a pure Python implementation of the `lex` and `yacc` tools to facilitate me to write the bootstrap compiler for the subset of C language.\\n\\n\\n### Compiler for a subset of C language bootstrapping from C\\n\\nPrerequisites:\\n\\n- An existing `GCC` for writing the bootstrap compiler\\n\\nHere are some popular tutorials from [GitHub - DoctorWkt/acwj: A Compiler Writing Journey](https://github.com/DoctorWkt/acwj).\\n\\nYou can also refer [GitHub - lotabout/write-a-C-interpreter](https://github.com/lotabout/write-a-C-interpreter) although I prefer classifying it as **interpreter** not a complete compiler.\\n\\n### Compiler bootstrapping from assembly\\n\\n### Compiler bootstrapping from HEX\\n\\n[GitHub - certik/bcompile: Bootstrapping a simple compiler from nothing](https://github.com/certik/bcompile)"},{"id":"/wiki-socket","metadata":{"permalink":"/blog/wiki-socket","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-socket.mdx","source":"@site/../../blog/wiki-socket.mdx","title":"Wiki Socket","description":"Wiki Socket","date":"2024-01-26T00:00:00.000Z","formattedDate":"January 26, 2024","tags":[{"label":"Wiki Socket","permalink":"/blog/tags/wiki-socket"}],"readingTime":0.74,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["Wiki Socket"],"description":"Wiki Socket","keywords":["Wiki Socket"],"image":"https://i.imgur.com/mErPwqL.png","date":"2024-01-26T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Wiki Compiler","permalink":"/blog/wiki-compiler"},"nextItem":{"title":"Cyber Security Wiki","permalink":"/blog/wiki-cybersecurity"}},"content":"Terms of sockets in socket programming,\\n\\n- On the server side:\\n  - The socket responsible for listening and accepting incoming connections is commonly referred to as the \\"**server socket**\\".\\n  - The individual sockets created for each accepted connection, responsible for data exchange with the connected clients, are often referred to as \\"**client socket**\\" (or simply \\"**socket**\\").\\n- On the client side:\\n  - The socket responsible for initiating a connection to the server and handling data exchange is commonly referred to as the \\"**client socket**\\" or \\"**socket**\\"\\n\\nIn summary:\\n- Server Side:\\n  - Listening Socket: \\"**Server Socket**\\"\\n  - Data Exchange Sockets (for each connection): \\"**Client Socket**\\" or just \\"**Socket**\\"\\n- Client Side:\\n  - Data Exchange Socket: \\"**Client Socket**\\" or just \\"**Socket**\\"\\n\\n\\n\x3c!--truncate--\x3e\\n\\n## Resources\\n\\n[Transports and Protocols \u2014 Python 3.12.1 documentation](https://docs.python.org/3/library/asyncio-protocol.html)\\n\\n[selectors \u2014 High-level I/O multiplexing \u2014 Python 3.12.1 documentation](https://docs.python.org/3/library/selectors.html)\\n\\n[socket \u2014 Low-level networking interface \u2014 Python 3.12.1 documentation](https://docs.python.org/3/library/socket.html)"},{"id":"/wiki-cybersecurity","metadata":{"permalink":"/blog/wiki-cybersecurity","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-cybersecurity.mdx","source":"@site/../../blog/wiki-cybersecurity.mdx","title":"Cyber Security Wiki","description":"Wiki Cybersecurity","date":"2024-01-25T00:00:00.000Z","formattedDate":"January 25, 2024","tags":[{"label":"Wiki Cybersecurity","permalink":"/blog/tags/wiki-cybersecurity"}],"readingTime":0.13,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["Wiki Cybersecurity"],"description":"Wiki Cybersecurity","keywords":["Wiki Cybersecurity"],"image":"https://i.imgur.com/mErPwqL.png","date":"2024-01-25T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Wiki Socket","permalink":"/blog/wiki-socket"},"nextItem":{"title":"Traefik Cheat Sheet","permalink":"/blog/cheatsheet-traefik"}},"content":"Slowloris Attack\\n\\nSlowloris attack is a type of Denial of Service (DoS) that aims to flood a targeted server with **incomplete HTTP requests**.\\n\\n\x3c!--truncate--\x3e\\n\\n## Resources"},{"id":"/cheatsheet-traefik","metadata":{"permalink":"/blog/cheatsheet-traefik","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/cheatsheet-traefik.mdx","source":"@site/../../blog/cheatsheet-traefik.mdx","title":"Traefik Cheat Sheet","description":"Cheatsheet Traefik","date":"2024-01-17T00:00:00.000Z","formattedDate":"January 17, 2024","tags":[{"label":"cheatsheet","permalink":"/blog/tags/cheatsheet"},{"label":"traefik","permalink":"/blog/tags/traefik"},{"label":"docker","permalink":"/blog/tags/docker"}],"readingTime":2.35,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["cheatsheet","traefik","docker"],"description":"Cheatsheet Traefik","keywords":["Cheatsheet Traefik"],"image":"https://i.imgur.com/mErPwqL.png","date":"2024-01-17T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Cyber Security Wiki","permalink":"/blog/wiki-cybersecurity"},"nextItem":{"title":"Network Cheat Sheet","permalink":"/blog/cheatsheet-network"}},"content":"Here are quick references for using `Traefik` on `Docker` containers environment.\\n\\nI use `Traefik` in my docker compose project more frequently than using `Nginx`, as it has such advantages:\\n- Simply to use and fast to spin up\\n  - Configuration relies on platform syntax(like `Docker labels` or `Kubernetes annotations`), while `Nginx` uses its own syntax and directives.\\n  - Configuration can just sit in `docker-compose.yml`, but `Nginx` always uses a dedicate configuration file(`/etc/nginx/nginx.conf`).\\n- Dynamic configuration:\\n  - Changes to the configuration require a restart of the `Nginx` process\\n  - Changes to the configuration require a restart of its corresponding service, not the `Traefik` process\\n\\n![How a Request is processed in Traefik](https://doc.traefik.io/traefik/assets/img/middleware/overview.png)\\n\\nEntrypoint -> Router -> Middleware 1 -> Middleware 2 -> ... -> Service\\n\\n\x3c!--truncate--\x3e\\n\\n## Redirect root path `/` to a subpath\\n\\nThe goal is to redirect root path `/` to sub path `/mtr` that\'s an ingress for a web service:\\n\\n- `http://127.0.0.1` -> `http://127.0.0.1/mtr`\\n- `http://127.0.0.1` -> `http://127.0.0.1/mtr`\\n- `https://127.0.0.1/something` -> no redirect\\n\\nIt works for **Traefik 2.0**\\n\\n```yml\\nservices:\\n  traefik:\\n    image: traefik:v2.10\\n    command:\\n      - --api.insecure=true\\n      - --providers.docker=true\\n      - --providers.docker.exposedbydefault=false\\n      - --entrypoints.web.address=:80\\n    ports:\\n      - 80:80\\n      - 8080:8080 # Web UI Port\\n    volumes:\\n      - /var/run/docker.sock:/var/run/docker.sock:ro\\n    labels:\\n      - traefik.enable=true\\n      # Redirection from `http://xxx.com` to `http://xxx.com/foo`\\n      - traefik.http.routers.domain.entrypoints=web\\n      - traefik.http.routers.domain.rule=Path(`/`)\\n      - traefik.http.routers.domain.service=noop@internal\\n      - traefik.http.routers.domain.middlewares=to-foo@docker\\n      - traefik.http.middlewares.to-foo.redirectregex.permanent=true\\n      - traefik.http.middlewares.to-foo.redirectregex.regex=^http://([^/]+)/?$\\n      - traefik.http.middlewares.to-foo.redirectregex.replacement=http://$${1}/foo\\n\\n  foo:\\n    image:  traefik/whoami:v1.10\\n    hostname: foo.com\\n    labels:\\n      - traefik.enable=true\\n      # just to ingress `http://xxx.com/foo`\\n      - traefik.http.routers.foo.entrypoints=web\\n      - traefik.http.routers.foo.rule=PathPrefix(`/foo`)\\n```\\n\\n## Route a prefix to a service\\n\\nMatch a request with a prefix `/bar`, strip the prefix and route it to the **bar** service,\\n\\n```yml\\nbar:\\n  image:  traefik/whoami:v1.10\\n  hostname: bar.com\\n  labels:\\n    - traefik.enable=true\\n    # ingress `http://xxx.com/bar/xyz` and send `http://xxx.com/xyz` to `bar` service\\n    - traefik.http.routers.bar.entrypoints=web\\n    - traefik.http.routers.bar.rule=PathPrefix(`/bar`)\\n    - traefik.http.routers.bar.middlewares=bar-strip-prefix@docker\\n    - traefik.http.middlewares.bar-strip-prefix.stripprefix.prefixes=/bar\\n```\\n\\n## Specify a custom port for the container\\n\\nBy default, Traefik used the first exposed port of a container, if a container exposes multiple ports, set `traefik.http.services.xxx.loadbalancer.server.port` to override that port.\\n\\n```yml\\nbar12345:\\n  image:  traefik/whoami:v1.10\\n  hostname: bar12345.com\\n  environment:\\n    WHOAMI_PORT_NUMBER: 12345\\n  labels:\\n    - traefik.enable=true\\n    - traefik.http.routers.bar12345.entrypoints=web\\n    - traefik.http.routers.bar12345.rule=PathPrefix(`/bar12345`)\\n    - traefik.http.routers.bar12345.service=bar12345\\n    # Tell Traefik to use the port 12345 to connect to `bar12345` service\\n    - traefik.http.services.bar12345.loadbalancer.server.port=12345\\n```\\n\\n## Specify more than one router and service per container\\n\\nIn this example, requests are forwarded for `http://127.0.0.1/web2ports-a` to `http://<private IP of container>:8001` in addition to `http://127.0.0.1/web2ports-b` forwarding to `http://<private IP of container>:8002`:\\n\\n```yml\\nweb2ports:\\n  image: python:3.10\\n  ports:\\n    - 8001:8001\\n    - 8002:8002\\n  working_dir: /app\\n  volumes:\\n    - ./server_whoami.py:/app/server_whoami.py\\n  command: >\\n    sh -c \\"python3 server_whoami.py --port 8001 \\n    & python3 server_whoami.py --port 8002\\"\\n  labels:\\n    - traefik.enable=true\\n    # Specify more than one router and service per container\\n    - traefik.http.routers.a-router.entrypoints=web\\n    - traefik.http.routers.a-router.rule=PathPrefix(`/web2ports-a`)\\n    - traefik.http.routers.a-router.service=a-service\\n    - traefik.http.services.a-service.loadbalancer.server.port=8001\\n    - traefik.http.routers.b-router.entrypoints=web\\n    - traefik.http.routers.b-router.rule=PathPrefix(`/web2ports-b`)\\n    - traefik.http.routers.b-router.service=b-service\\n    - traefik.http.services.b-service.loadbalancer.server.port=8002\\n```\\n\\n## Resources\\n\\n\\n[URL Redirect abc.com to xyz.com - Traefik v2 (latest) - Traefik Labs Community Forum](https://community.traefik.io/t/url-redirect-abc-com-to-xyz-com/8084)\\n\\n[Traefik redirect / (root) to sub path with Docker labels \xb7 GitHub](https://gist.github.com/kekru/d088be6a3fa844089ae62d80c077bb38)"},{"id":"/cheatsheet-network","metadata":{"permalink":"/blog/cheatsheet-network","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/cheatsheet-network.mdx","source":"@site/../../blog/cheatsheet-network.mdx","title":"Network Cheat Sheet","description":"Network Cheat Sheet","date":"2024-01-16T00:00:00.000Z","formattedDate":"January 16, 2024","tags":[{"label":"network","permalink":"/blog/tags/network"},{"label":"cheat sheet","permalink":"/blog/tags/cheat-sheet"}],"readingTime":5.715,"hasTruncateMarker":false,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["network","cheat sheet"],"description":"Network Cheat Sheet","keywords":["Network Cheat Sheet"],"image":"https://i.imgur.com/mErPwqL.png","date":"2024-01-16T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Traefik Cheat Sheet","permalink":"/blog/cheatsheet-traefik"},"nextItem":{"title":"ARM64/AArch64 Assembly Cheat Sheet","permalink":"/blog/cheatsheet-assembly-arm64"}},"content":"[Understanding Routing Table Entry | Baeldung on Computer Science](https://www.baeldung.com/cs/routing-table-entry)\\n> the packs go through the gateway of interface. the same interface can have multiple gateways and different interfaces can have the same gateway.\\n\\n[route diagnosis](https://forums.developer.nvidia.com/t/ssh-enabled-only-if-connected-through-microusb/192708/12)\\n\\n[3 Ways to Find Which Linux Process Listening on a Port](https://www.tecmint.com/find-out-which-process-listening-on-a-particular-port/)\\n\\n[Monitoring Network Status With the netstat Command - System Administration Guide: IP Services](https://docs.oracle.com/cd/E18752_01/html/816-4554/ipconfig-142.html)\\n> System Administration Guide\\n\\n[How to look up the geographic location of an IP address from the command line](https://www.xmodulo.com/geographic-location-ip-address-command-line.html)\\n> #geolocation-of-ip\\n\\n[A tcpdump Tutorial with Examples \u2014 50 Ways to Isolate Traffic - Daniel Miesslersearchmailmailmail](https://danielmiessler.com/study/tcpdump/)\\n\\n[TCPDump cheatsheet](https://resource.nvidia.com/cheatsheets/linux-networking-cheatsheet-tcpdump)\\n\\n[An introduction to using tcpdump at the Linux command line | Opensource.com](https://opensource.com/article/18/10/introduction-tcpdump)\\n\\nKnowing `simultaneously` these three things for failing and working circumstances would be quite useful.\\n\\n## Get IP address\\n\\n- Linux\\n\\n```sh\\nrms@rms:~$ ip addr\\n```\\n\\n- Windows\\n\\n```powershell\\nPS C:\\\\Users\\\\Frank> ipconfig\\n```\\n\\n```powershell\\nPS C:\\\\Users\\\\Frank> netsh interface ip show address\\n```\\n\\n### Get IP address of a specific network interface\\n\\n- Linux\\n\\n```sh\\nrms@rms:~$ ip addr show enp0s31f6\\n5: enp0s31f6: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000\\n    link/ether 00:4e:01:fc:39:50 brd ff:ff:ff:ff:ff:ff\\n    inet 10.6.64.184/24 brd 10.6.64.255 scope global enp0s31f6\\n       valid_lft forever preferred_lft forever\\n    inet6 fe80::24e:1ff:fefc:3950/64 scope link\\n       valid_lft forever preferred_lft forever\\n```\\n\\n```sh\\nrms@rms:~$ hostname -I | awk \'{print $1}\'\\n10.6.64.184\\n```\\n\\n- Windows\\n\\n```powershell\\nPS C:\\\\Users\\\\Frank> netsh interface ip show address \\"Ethernet\\"\\n\\nConfiguration for interface \\"Ethernet\\"\\n    DHCP enabled:                         Yes\\n    IP Address:                           10.6.64.243\\n    Subnet Prefix:                        10.6.64.0/24 (mask 255.255.255.0)\\n    Default Gateway:                      10.6.64.1\\n    Gateway Metric:                       0\\n    InterfaceMetric:                      25\\n```\\n\\n\\n```powershell\\nPS C:\\\\Users\\\\Frank> netsh interface ip show address \\"Ethernet\\" | findstr \\"IP Address\\"\\n```\\n\\n## Show Routing Table\\n  \\n```sh\\n# linux\\nroute\\n# osx\\nnetstat -rn\\n```\\n\\nThe `-r` flag means to show routes.\\n\\nThe `-n` flag means to not resolve IPs to hostnames.\\n\\n## Find Gateway Used for Routing\\n\\n```sh\\n# linux\\nip route get 8.8.8.8\\n# osx\\nroute get 8.8.8.8\\n```\\n\\n## Show Routes across Network\\n\\n```sh\\ntraceroute\\n# en0 interface\\ntraceroute -i en0\\n```\\n\\n## Ping Through Specific Interface\\n\\n```sh\\n# linux\\nping -I en0 sslvpn.astri.org\\n# osx\\nping -b en0 sslvpn.astri.org\\n```\\n\\n## Find Out Address Used by Which Process\\n\\n```sh\\n# osx\\nnetstat -avn -p tcp\\n```\\n\\n## Add a Route\\n\\n```sh\\n# osx\\nroute -n add 10.0.0.0/24 10.0.0.1\\n# linux\\nroute -n add -net 10.0.0.0/24 gw 10.0.0.1\\n```\\n\\n## FireWall Rule\\n\\nosx:\\n\\n```sh\\n# show all information/stats\\nsudo pfctl -sa\\n# show rules\\nsudo pfctl -sr\\n# sanity check edited configuration file\\nsudo pfctl -v -n -f /etc/pf.conf\\n# load pf with new rules\\nsudo pfctl -f /etc/pf.conf\\n# enable pf\\nsudo pfctl -e\\n# disable pf\\nsudo pfctl -d\\n# add information on the fly\\nsudo pfctl -t localsub -T add 127.0.0.0/24\\n# flush added rules later\\nsudo pfctl -Fa -f /etc/pf.conf\\n\\nsudo pfctl -si\\nsudo pfctl -q\\n```\\n\\n## Get Geolocation of IP Address\\n\\n```sh\\ncurl ipinfo.io/103.216.223.161\\n```\\n\\n## Packet Analyzer\\n\\n### Monitor TCP packet on network interfaces\\n\\n```sh\\n# list which interfaces are available for capture\\ntcpdump --list-interfaces\\n# capture all packets in any interface\\nsudo tcpdump --interface any\\n# limit the number of packets captured then stop `-c number`\\nsudo tcpdump -i any -c 5\\n# disable name resolution with using `-n` and port resolution with `-nn` \\nsudo tcpdump -i any -c 5 -nn\\n# filter packets by protocol, only capture `ICMP` packets\\nsudo tcpdump -i any -c 5 icmp\\n# capture packets related with host `8.8.8.8`\\nsudo tcpdump -i any -c 5 -nn host 8.8.8.8\\n# capture packets related with port `80`\\nsudo tcpdump -i any -c 5 -nn port 80\\n# capture packets with source address 192.168.0.1\\nsudo tcpdump -i any -c 5 -nn src 192.168.0.1\\n# capture packets with destination address 8.8.8.8\\nsudo tcpdump -i any -c 5 -nn dst 8.8.8.8\\n# capture either port `80` or port `443`\\nsudo tcpdump -i enp0s31f6 -nn port 80 or port 443\\n# display payload\\nsudo tcpdump -i enp0s31f6 port 80 -A -s 0\\n```\\n\\nIn the above command:\\n- `-i` specifies the network interface, and `any` means all interfaces.\\n- `-c` specify the number of packets to capture, omitting `-c` to capture packets continuously.\\n- `-nn` display IP address and port as numbers rather than attempting to resolve them to hostname.\\n- `-A` display the packet payload in ASCII format.\\n- `-s 0` means capturing the entire packet.\\n\\n\\n### Monitor HTTP message on network interfaces\\n\\n```sh title=\\"tcpflow\\"\\n# monitor on the interface: `enp0s31f6`\\nsudo tcpflow -p -c -i enp0s31f6 port 80\\n# just show HTTP message of `GET` and `POST` HTTP methods\\nsudo tcpflow -p -c -i enp0s31f6 port 80 | grep -oE \'(GET|POST) .* HTTP/1.[01]|Host: .*\'\\n```\\n\\nIn the above command:\\n- `-p` disables promiscuous mode\\n- `-c` means only print the output to the console and don\u2019t create files\\n- `-i` specifies the network interface\\n- `grep`\\n  - `-o` means show only the matching parts of the lines that match the pattern\\n  - `-E` means the pattern is an extended regular expression (ERE)\\n\\n\\n## USB Virtual Ethernet\\n\\n[An explanation on the USB virtual ethernet](https://forums.developer.nvidia.com/t/provide-internet-through-micro-usb-while-doing-ssh/111326/14)\\n\\n## Access WSL 2 from local area network(LAN)\\n\\nAfter enabling [systemd](https://devblogs.microsoft.com/commandline/systemd-support-is-now-available-in-wsl/) in WSL 2, I have to forward the Windows host port to the WSL 2 distribution.\\n\\n### Find WSL 2 IP address that can be reached from Windows host\\n\\n```sh\\n$ ip addr show eth0\\n2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1420 qdisc mq state UP group default qlen 1000\\n    link/ether 00:15:5d:98:b5:99 brd ff:ff:ff:ff:ff:ff\\n    inet 172.29.6.23/20 brd 172.29.15.255 scope global eth0\\n       valid_lft forever preferred_lft forever\\n    inet6 fe80::215:5dff:fe98:b599/64 scope link\\n       valid_lft forever preferred_lft forever\\n```\\n\\n### Add proxy\\n\\n```powershell\\nnetsh interface portproxy add v4tov4 listenport=8082 connectport=8082 connectaddress=172.29.6.23,127.0.0.1\\n```\\n\\n### [Optional] Add firewall rule\\n\\n```powershell\\nnetsh advfirewall firewall add rule name= \\"Open Port 8082\\" dir=in action=allow protocol=TCP localport=8082\\n```\\n\\n### Check current proxy\\n\\n```powershell\\nnetsh interface portproxy show all\\n```\\n\\n### Clean up\\n\\n```powershell\\nnetsh interface portproxy delete v4tov4 listenport=8082\\n```\\n\\n```powershell\\nnetsh advfirewall firewall delete rule name=\\"Open port 8082\\"\\n```\\n\\n\\n## Configure Static IP Address\\n\\nUbuntu 17.10 and later uses **Netplan** as the default network management tool. The previous Ubuntu versions were using **ifconfig** and its configuration file `/etc/network/interfaces` to configure the network.\\n\\nEdit or create a file under `/etc/netplan`, such as `/etc/netplan/01-netcfg.yaml`.\\n\\n```yaml title=\\"/etc/netplan/01-netcfg.yaml\\"\\nnetwork:\\n version: 2\\n renderer: networkd\\n ethernets:\\n   enp0s31f6:\\n     dhcp4: no\\n     addresses: [10.6.64.12/24]\\n     gateway4: 10.6.64.1\\n     nameservers:\\n         addresses: [8.8.8.8,8.8.8.4]\\n```\\n\\nOptions:\\n- `enp0s31f6`: configure the network interface `enp0s31f6` of the device type `ethernets`.\\n- `dhcp4: no`: don\'t obtain IP address from the **DHCP** server.\\n- `addresses: [10.6.64.12/24]`: use static IP address `10.6.64.12` in subnet `10.6.64.0/24`.\\n\\nOnce done, save the file and apply the changes by running the following command:\\n\\n```console\\n$ sudo netplan apply\\n```\\n\\nVerify the changes by typing:\\n\\n```console\\n$ ip addr show enp0s31f6\\n```\\n\\n:::NOTE\\nFor Ubuntu server which is provisioned with `cloud-init`, you may need to disable it. To do so, create the following file: `/etc/cloud/cloud.cfg.d/99-disable-network-config.cfg` as,\\n\\n```cfg title=\\"/etc/cloud/cloud.cfg.d/99-disable-network-config.cfg\\nnetwork: {config: disabled}\\n```\\n\\n:::"},{"id":"/cheatsheet-assembly-arm64","metadata":{"permalink":"/blog/cheatsheet-assembly-arm64","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/cheatsheet-assembly-arm64.mdx","source":"@site/../../blog/cheatsheet-assembly-arm64.mdx","title":"ARM64/AArch64 Assembly Cheat Sheet","description":"Cheatsheet ARM64","date":"2024-01-14T00:00:00.000Z","formattedDate":"January 14, 2024","tags":[{"label":"arm64","permalink":"/blog/tags/arm-64"},{"label":"aarch64","permalink":"/blog/tags/aarch-64"},{"label":"cheat sheet","permalink":"/blog/tags/cheat-sheet"}],"readingTime":1.86,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["arm64","aarch64","cheat sheet"],"description":"Cheatsheet ARM64","keywords":["AArch64","ARM64","Cheat sheet"],"image":"https://i.imgur.com/mErPwqL.png","date":"2024-01-14T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Network Cheat Sheet","permalink":"/blog/cheatsheet-network"},"nextItem":{"title":"x64 Assembly Cheat Sheet","permalink":"/blog/cheatsheet-assembly-x64"}},"content":"## Registers\\n\\n| Register                   | Low 32-bits | Calling convention |\\n|----------------------------|-------------|--------------------|\\n| General-purpose registers: |\\n| `x0`                       | `w0`        |                    |\\n| `x1`                       | `w1`        |                    |\\n| `x2`                       | `w2`        |                    |\\n| Special-purpose registers: |\\n| `xzr`                      | `wzr`       | Zero register      |\\n| `sp`                       | -           | Stack pointer      |\\n\x3c!--truncate--\x3e\\n\\n## Data type\\n\\n| Definition size | Definition instruction |\\n|-----------------|------------------------|\\n| 8 bit           | `byte`                 |\\n| 16 bit          | `hword`                |\\n| 32 bit          | `word`                 |\\n| 64 bit          | `dword`                |\\n\\n## Load from immediate\\n\\n`movz`/`mov` + `movk`\\n\\nLoad the 64-bit integer `0x1a2b3c4d1a2b3c4d` from the immediate,\\n\\n```asm\\n// Load the 64-bit integer `0x1a2b3c4d1a2b3c4d` from the immediate\\nmovz     x1, #0x3c4d\\nmovk    x1, #0x1a2b, lsl #16\\nmovk    x1, #0x3c4d, lsl #32\\nmovk    x1, #0x1a2b, lsl #48\\n```\\n\\n## Load from label\\n \\n| Load instruction   | Purpose     |\\n|--------------------|-------------|\\n| `ldr    x0, [x1]`  | load 64-bit |\\n| `ldr    w0, [x1]`  | load 32-bit |\\n| `ldrh    w0, [x1]` | load 16-bit |\\n| `ldrb    w0, [x1]` | load 8-bit  |\\n\\nAssume the 32-bit data in `.data` section,\\n\\n```asm\\n.data\\n    int32_var:  .word   0x1a2b3c4d\\n```\\n\\n`adr`: shift by byte(\xb11M, one instruction), the assembler will do:\\n- calculate the PC-relative offset from the current `adr` instruction to the label `int32_var` in bytes.\\n- encode the offset in the `adr` instruction.\\n\\n```asm\\nadr\\t    x20, int32_var\\nldr     x2, [x20]\\n```\\n\\n`adrp` + `add`: shift by 4KB page(\xb14G, two instructions), the assembler will do:\\n- calculate the PC-relative offset from the current `adr` instruction to the label `int32_var` in page.\\n  - calculate the PC-relative offset in bytes.\\n  - divide the byte offset using 4096(or right shift 12 bits), now the quotient is page offset\\n- encode the page offset in the `adrp` instruction.\\n- encode the lower 12 bits in the `add` instruction.\\n\\n\\n```asm\\nadrp\\tx20, int32_var\\nadd     x20, x20, :lo12:int32_var\\nldr    x2, [x20]\\n```\\n\\nor more simply,\\n\\n```asm\\nadrp\\tx20, int32_var\\nldr    x2, [x20, :lo12:int32_var]\\n```\\n\\nin macOS m1,\\n\\n```asm\\nadrp\\tx20, int32_var@PAGE\\nadd     x20, x20, int32_var@PAGEOFF\\nldr    x2, [x20]\\n```\\n\\n## Store\\n\\n## Resources\\n\\n[ios-resources/bits/arm64.md at master \xb7 Siguza/ios-resources \xb7 GitHub](https://github.com/Siguza/ios-resources/blob/master/bits/arm64.md)\\n\\n[asm_book/section_1/regs/ldr.md at main \xb7 pkivolowitz/asm_book \xb7 GitHub](https://github.com/pkivolowitz/asm_book/blob/main/section_1/regs/ldr.md)\\n\\n[Exploring AArch64 assembler \u2013 Chapter 5](https://thinkingeek.com/2016/11/13/exploring-aarch64-assembler-chapter-5/)\\n\\nhttps://peterdn.com/post/2020/08/22/hello-world-in-arm64-assembly/\\n\\nhttps://gpanders.com/blog/exploring-mach-o-part-1/\\n\\nhttps://iitd-plos.github.io/col718/ref/arm-instructionset.pdf\\n\\nhttps://modexp.wordpress.com/2018/10/30/arm64-assembly/#registers\\n\\nhttps://stackoverflow.com/questions/41906688/what-are-the-semantics-of-adrp-and-adrl-instructions-in-arm-assembly"},{"id":"/cheatsheet-assembly-x64","metadata":{"permalink":"/blog/cheatsheet-assembly-x64","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/cheatsheet-assembly-x64.mdx","source":"@site/../../blog/cheatsheet-assembly-x64.mdx","title":"x64 Assembly Cheat Sheet","description":"x64 NASM Cheat Sheet","date":"2024-01-14T00:00:00.000Z","formattedDate":"January 14, 2024","tags":[{"label":"cheat sheet","permalink":"/blog/tags/cheat-sheet"},{"label":"x64","permalink":"/blog/tags/x-64"},{"label":"nasm","permalink":"/blog/tags/nasm"},{"label":"gas","permalink":"/blog/tags/gas"}],"readingTime":5.695,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["cheat sheet","x64","nasm","gas"],"description":"x64 NASM Cheat Sheet","keywords":["x64 NASM cheat sheet"],"image":"https://i.imgur.com/mErPwqL.png","date":"2024-01-14T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"ARM64/AArch64 Assembly Cheat Sheet","permalink":"/blog/cheatsheet-assembly-arm64"},"nextItem":{"title":"Database Migration Using Alembic in Python","permalink":"/blog/python-alembic"}},"content":"Including two main assembler:\\n\\n- GNU Assembler(GAS): AT&T syntax\\n- NASM: Intel syntax\\n\\n## Registers\\n\\n| Register         | Low 32-bits | Low 16-bits | Low 8-bit | High 8-bits | Calling convention        | Callee-saved? |\\n|------------------|-------------|-------------|-----------|-------------|---------------------------|---------------|\\n| General-purpose: |\\n| `%rax`           | `%eax`      | `%ax`       | `%al`     | `%ah`       | Return value              | No            |\\n| `%rbx`           | `%ebx`      | `%bx`       | `%bl`     | `%bh`       | -                         | Yes           |\\n| `%rcx`           | `%ecx`      | `%cx`       | `%cl`     | `%ch`       | 4th argument              | Yes           |\\n| `%rdx`           | `%edx`      | `%dx`       | `%dl`     | `%dh`       | 3th argument              | Yes           |\\n| `%rsi`           | `%esi`      | `%si`       | `%sil`    | -           | 2st argument              | No            |\\n| `%rdi`           | `%edi`      | `%di`       | `%dil`    | -           | 1st argument              | No            |\\n| `%r8`            | `%r8d`      | `%r8w`      | `%r8b`    | -           | 5th argument              | No            |\\n| `%r9`            | `%r9d`      | `%r9w`      | `%r9b`    | -           | 6th argument              | No            |\\n| `%r10`           | `%r10d`     | `%r10w`     | `%r10b`   | -           | -                         | No            |\\n| `%r11`           | `%r11d`     | `%r11w`     | `%r11b`   | -           | -                         | No            |\\n| `%r12`           | `%r12d`     | `%r12w`     | `%r12b`   | -           | -                         | Yes           |\\n| `%r13`           | `%r13d`     | `%r13w`     | `%r13b`   | -           | -                         | Yes           |\\n| `%r14`           | `%r14d`     | `%r14w`     | `%r14b`   | -           | -                         | Yes           |\\n| `%r15`           | `%r15d`     | `%r15w`     | `%r15b`   | -           | -                         | Yes           |\\n| Special-purpose: |\\n| `%rsp`           | `%esp`      | `%sp`       | `%spl`    | \u2013           | Stack pointer             | Yes           |\\n| `%rbp`           | `%ebp`      | `%bp`       | `%bpl`    | \u2013           | Base pointer              | Yes           |\\n| `%rip`           | `%eip`      | `%ip`       | -         | \u2013           | Instruction pointer       | -             |\\n| `%rflags`        | `%eflags`   | `%flags`    | -         | \u2013           | Flags and condition codes | No            |\\n\\n## Data Type\\n\\n| Definition size    | NASM       | -       | GAS                    | suffix |\\n|--------------------|------------|---------|------------------------|--------|\\n| 8 bit              | `db`       | `BYTE`  | `byte`                 | `b`    |\\n| 16 bit             | `dw`       | `WORD`  | `short`/`word`/`2byte` | `w`    |\\n| 32 bit             | `dd`       | `DWORD` | `long`/`int`/`4byte`   | `l`    |\\n| 64 bit             | `ddq`/`do` | `QWORD` | `quad`/`8byte`         | `q`    |\\n| float              | `dd`       | -       | -                      |\\n| double             | `dq`       | -       | -                      |\\n| extended precision | `dt`       | -       | -                      |\\n| string             | -          | -       | `ascii`/`asciz`        | -      |\\n\\n```asm\\n.data\\n  int8 .db 0x7f\\n  msg .db 0x7f, \'E\', \'L\', \'F\', 1, 1, 1, 0\\n```\\n\\n```asm\\n.data\\n  int8 .byte 0x7f\\n  msg .byte 0x7f, \'E\', \'L\', \'F\', 1, 1, 1, 0\\n  ms  .asciz \\"ELF\\"\\n  ms  .ascii \\"ELF\\", 0x0\\n```\\n\\n## Memory and Addressing Modes\\n\\n```asm\\nmov eax, [ebx]\\t; Move the 4 bytes in memory at the address contained in EBX into EAX\\nmov [var], ebx\\t; Move the contents of EBX into the 4 bytes at memory address var. (Note, var is a 32-bit constant).\\nmov eax, [esi-4]\\t; Move 4 bytes at memory address ESI + (-4) into EAX\\nmov [esi+eax], cl\\t; Move the contents of CL into the byte at address ESI+EAX\\nmov edx, [esi+4*ebx]    \\t; Move the 4 bytes of data at address ESI+4*EBX into EDX\\n```\\n\\n```asm\\nmov (%ebx), %eax\\t/* Load 4 bytes from the memory address in EBX into EAX. */\\nmov %ebx, var(,1)\\t/* Move the contents of EBX into the 4 bytes at memory address var.\\n(Note, var is a 32-bit constant). */\\nmov -4(%esi), %eax\\t/* Move 4 bytes at memory address ESI + (-4) into EAX. */\\nmov %cl, (%esi,%eax,1)   \\t/* Move the contents of CL into the byte at address ESI+EAX. */\\nmov (%esi,%ebx,4), %edx     \\t/* Move the 4 bytes of data at address ESI+4*EBX into EDX. */\\n```\\n\\n## Size Directives in `mov`\\n\\n```asm\\nmov BYTE [ebx], 2\\t; Move 2 into the single byte at the address stored in EBX.\\nmov WORD [ebx], 2\\t; Move the 16-bit integer representation of 2 into the 2 bytes starting at the address in EBX.\\nmov DWORD [ebx], 2    \\t; Move the 32-bit integer representation of 2 into the 4 bytes starting at the address in EBX.\\n```\\n\\n```asm\\nmovb $2, (%ebx)\\t/* Move 2 into the single byte at the address stored in EBX. */\\nmovw $2, (%ebx)\\t/* Move the 16-bit integer representation of 2 into the 2 bytes starting at the address in EBX. */\\nmovl $2, (%ebx)     \\t/* Move the 32-bit integer representation of 2 into the 4 bytes starting at the address in EBX. */\\n```\\n\\n```asm\\nmovsbl %al, %edx    # copy 1-byte %al, sign-extend into 4-byte %edx\\nmovzbl %al, %edx    # copy 1-byte %al, zero-extend into 4-byte %edx\\n```\\n\\n## Common instructions\\n\\n### Mov and lea\\n\\n```asm\\nmov src, dst              # general form of instruction dst = src\\nmov $0, %eax              # %eax = 0\\nmovb %al, 0x409892        # write to address 0x409892 low-byte of %eax\\nmov 8(%rsp), %eax         # %eax = value read from address %rsp + 8\\n\\nlea 0x20(%rsp), %rdi      # %rdi = %rsp + 0x20 (no dereference!)\\nlea (%rdi,%rdx,1), %rax   # %rax = %rdi + %rdx\\n```\\n\\n## Stack operation\\n\\n```asm\\npush %rbx         # push value of %rbx onto stack\\npushq $0x3        # push immediate value 3 onto stack\\nsub $0x10, %rsp   # adjust stack pointer to set aside 16 more bytes\\n\\npop %rax          # pop topmost value from stack into register %rax\\nadd $0x10, %rsp   # adjust stack point to remove topmost 16 bytes\\n```\\n\\n## Calling Convention\\n\\n```asm\\nmov $0x3, %rdi    # first arg is passed in %rdi\\nmov $0x7, %rsi    # second arg is passed in %rsi\\ncallq binky       # transfers control to function binky\\n```\\n\\n\x3c!--truncate--\x3e\\n## Program structure\\n\\n- `global <entry>` -> exposes entry point\\n- `extern <function>` -> declares a function in another linked .o file (e.g. C\\n  function, other asm file)\\n- `section <sectiontype>` -> sets section, usually:\\n  - `.text` -> program code\\n  - `.data` -> data\\n\\nThe program entry point of a standalone program is the label `_start`.  When\\ncompiled with gcc, C provides `_start`, which inits and then jumps to `main`,\\nwhich should then be implemented by the program.\\n\\n\\n## Syscalls\\n\\n- put syscall number in EAX (e.g. on Linux: 60 for exit, 1 for write to stdout)\\n- put arguments in the registers (see above) like when calling a C function\\n- execute the `syscall` instruction\\n\\n## Calling C functions\\n\\n## Assemble\\n\\n- Assemble: `nasm -felf64 -o <object> <filename>`\\n- Link with ld: `ld -o <output> <object>`\\n- Link with gcc: `gcc -o <output> <object>`\\n\\n\\n## Resources\\n\\n[Assembly 1: Basics \u2013 CS 61 2018](https://cs61.seas.harvard.edu/site/2018/Asm1/)\\n\\n[CS107 Guide to x86-64](https://web.stanford.edu/class/cs107/guide/x86-64.html)\\n\\n[x64 NASM Cheat Sheet \xb7 GitHub](https://gist.github.com/justinian/385c70347db8aca7ba93e87db90fc9a6)\\n\\n[nasmtutorial](https://cs.lmu.edu/~ray/notes/nasmtutorial/)\\n\\n[gasexamples](https://cs.lmu.edu/~ray/notes/gasexamples/)\\n\\n[Guide to x86 Assembly](https://flint.cs.yale.edu/cs421/papers/x86-asm/asm.html)"},{"id":"/python-alembic","metadata":{"permalink":"/blog/python-alembic","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/python-alembic.mdx","source":"@site/../../blog/python-alembic.mdx","title":"Database Migration Using Alembic in Python","description":"Database migration using Alembic in Python","date":"2024-01-02T00:00:00.000Z","formattedDate":"January 2, 2024","tags":[{"label":"python","permalink":"/blog/tags/python"},{"label":"alembic","permalink":"/blog/tags/alembic"}],"readingTime":0.365,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["python","alembic"],"description":"Database migration using Alembic in Python","keywords":["database migration with alembic"],"image":"https://i.imgur.com/mErPwqL.png","date":"2024-01-02T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"x64 Assembly Cheat Sheet","permalink":"/blog/cheatsheet-assembly-x64"},"nextItem":{"title":"Python Celery","permalink":"/blog/python-celery-workflow"}},"content":"Foam includes note templates!\\nThis allows you to easily create notes that have similar structure without having to use copy/paste :)\\n\\nTemplates support the [VS Code\'s Snippet Syntax](https://code.visualstudio.com/docs/editor/userdefinedsnippets#_snippet-syntax), which means you can:\\n\\n- add variables to the newly created note\\n- add tabstop to automatically navigate to the key parts of the note, just like a form\\nBelow you can see an example showing a todo list and a timestamp.\\n\\n\x3c!--truncate--\x3e\\n\\n## Resources"},{"id":"/python-celery-workflow","metadata":{"permalink":"/blog/python-celery-workflow","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/python-celery-workflow.mdx","source":"@site/../../blog/python-celery-workflow.mdx","title":"Python Celery","description":"Python Celery","date":"2023-12-20T00:00:00.000Z","formattedDate":"December 20, 2023","tags":[{"label":"Python Celery","permalink":"/blog/tags/python-celery"}],"readingTime":0.86,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["Python Celery"],"description":"Python Celery","keywords":["Python Celery"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-12-20T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Database Migration Using Alembic in Python","permalink":"/blog/python-alembic"},"nextItem":{"title":"Python C Library","permalink":"/blog/python-c-library"}},"content":"What\'s **workflow** in Celery?\\n\\nIn **Celery**, **workflow** is composed of multiple **tasks**, and a **task** is deemed to be a universal unit of the **workflow**, as a function in the program. In **Celery**, it\'s recommended to divide a long-running task into multiple short-running tasks. **workflow** comes out to help ease the orchestrations of the work, such as `chain()` three tasks.\\n\\n[A demo workflow](https://github.com/liviaerxin/fastapi-celery-ml/blob/main/app/examples/celery_workflow.py)\\n\\n\x3c!--truncate--\x3e\\n\\n## Construct a workflow\\n\\n## Avoid running synchronous subtasks within a task\\n\\n## Asynchronous tasks with a task\\n\\n```py\\n@app.task(bind=True)\\ndef update_page_info(self, url):\\n    # fetch_page -> parse_page -> store_page\\n    chain = fetch_page.s(url) | parse_page.s() | store_page_info.s(url)\\n    # chain()\\n    self.replace(chain)\\n\\n@app.task()\\ndef fetch_page(url):\\n    return myhttplib.get(url)\\n\\n@app.task()\\ndef parse_page(page):\\n    return myparser.parse_document(page)\\n\\n@app.task(ignore_result=True)\\ndef store_page_info(info, url):\\n    PageInfo.objects.create(url=url, info=info)\\n```\\n\\n## Monitor the workflow\\n\\n\\n## Resources\\n\\n[Designing Dynamic Workflows with Celery and Python | by Marin Agli\u0107 | Data Engineer Things](https://blog.det.life/replacing-celery-tasks-inside-a-chain-b1328923fb02)\\n\\n[The Curious Case of Celery Work-flows](https://dev.to/akarshan/the-curious-case-of-celery-work-flows-39f7)\\n\\n[Celery ETA Tasks Demystified. At Instawork, we use Celery to queue\u2026 | by Oleg Pesok | Instawork Engineering](https://engineering.instawork.com/celery-eta-tasks-demystified-424b836e4e94)\\n\\n[Canvas: Designing Work-flows \u2014 Celery 5.3.6 documentation](https://docs.celeryq.dev/en/stable/userguide/canvas.html)"},{"id":"/python-c-library","metadata":{"permalink":"/blog/python-c-library","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/python-c-library.mdx","source":"@site/../../blog/python-c-library.mdx","title":"Python C Library","description":"Python C","date":"2023-12-18T00:00:00.000Z","formattedDate":"December 18, 2023","tags":[{"label":"Python","permalink":"/blog/tags/python"},{"label":"C","permalink":"/blog/tags/c"},{"label":"Shared library","permalink":"/blog/tags/shared-library"},{"label":"Dynamic library","permalink":"/blog/tags/dynamic-library"}],"readingTime":1.51,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["Python","C","C++","Shared library","Dynamic library"],"description":"Python C","keywords":["Python C"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-12-18T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Python Celery","permalink":"/blog/python-celery-workflow"},"nextItem":{"title":"Python Unicode String","permalink":"/blog/python-unicode-string"}},"content":"How many ways Python can interact with C libraries?\\n\\nTwo. There are two different modes totally.\\n\\n1. `ctypes` to load any dynamic library from a C libraries\\n2. `import module` to import a dynamic library written using the Python C API\\n\\n\\nLet\'s clarify the terminology a bit:\\n\\n1. `ctypes` to Load Dynamic Libraries (including any C library):\\n  - `ctypes` is a foreign function interface (FFI) library in Python that allows you to call functions from dynamic/shared libraries written in languages like C.\\n  - It can be used to load and call functions from C libraries (or any dynamic/shared libraries), and it\'s a more manual, low-level approach to interfacing with C code.\\n  - Example with `ctypes`:\\n  ```py\\n  ```\\n2. `import module` for Dynamic Libraries written in Python C API:\\n   - If a C library is written using the Python C API and compiled as a Python extension module (`.pyd` on Windows or `.so` on Unix-like systems), you can use the import statement to `import` and use it in Python.\\n   - This `Pythonic` approach typically provides a more seamless integration as it allows the C code to be treated as a native Python module.\\n   - Example with `import module`:\\n\\n\x3c!--truncate--\x3e\\nWhat\'s the file\'s name that Python look for when using `import module` to import C API libraries?\\n\\nPython will look for a shared library with a suitable name, as determined by the platform conventions.\\nThe shared library could be named something like `libexample.so` on Unix-like systems or `example.dll` on Windows. The `PyInit_example` function initializes the module.\\n\\n## Python `int` object\\n\\nPython uses a variable-size integer representation,\\n- `Overhead size`: 24 bytes, including Python header object\\n- `Data size`: 4 or 8 bytes, storing smaller `int` using 4 bytes and bigger `int` using 8 bytes.\\n\\n```py\\n>>> sys.getsizeof(0x560f7ab1e1c0)\\n32\\n>>> sys.getsizeof(0xc0)\\n28\\n```\\n\\n## Resources"},{"id":"/python-unicode-string","metadata":{"permalink":"/blog/python-unicode-string","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/python-unicode-string.mdx","source":"@site/../../blog/python-unicode-string.mdx","title":"Python Unicode String","description":"Python Unicode","date":"2023-12-13T00:00:00.000Z","formattedDate":"December 13, 2023","tags":[{"label":"Python","permalink":"/blog/tags/python"},{"label":"Unicode","permalink":"/blog/tags/unicode"},{"label":"ctypes","permalink":"/blog/tags/ctypes"}],"readingTime":10.205,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["Python","Unicode","ctypes"],"description":"Python Unicode","keywords":["Python Unicode","memory layout"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-12-13T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Python C Library","permalink":"/blog/python-c-library"},"nextItem":{"title":"Wiki Cryptography","permalink":"/blog/wiki-cryptography"}},"content":"Python string use `unicodeobject` which is implemented in `C` in CPython:\\n\\n- [unicodeobject.c](https://github.com/python/cpython/blob/main/Objects/unicodeobject.c)\\n- [unicodeobject.h](https://github.com/python/cpython/blob/main/Include/cpython/unicodeobject.h)\\n\\nPython chooses one of these three kinds of data type to internally represent for a Unicode-characters string, so every Unicode character of the string has the same fixed-length: 1, 2 or 4,\\n\\n- **UCS-1**(1 byte), for ASCII characters between U+0000 and U+00FF\\n- **UCS-2**(2 bytes), for Unicode characters between U+00FF and U+FFFF\\n- **UCS-4**(4 bytes), for Unicode characters between U+00FFFF and U+10FFFF\\n\\nThere are 4 forms of Unicode strings:\\n- compact ascii\\n- compact\\n- legacy string\\n- legacy string ready\\n\\nThe `legacy string` as I see is already deprecated after Python3 and the official says: \\"it will be removed after Python 4\\".\\n\\nThe `compact` make the `characters` data start just after the `PyASCIIObject` or `PyCompactUnicodeObject` structure, using just one block, whereas `legacy strings` use one block for the structure and one block for `characters`.\\n\\nThe `characters` data are 1-byte, 2-byte or 4-byte `code point`. The UnicodeObject will use the maximum length in fixed-size for each.\\n\\n\x3c!--truncate--\x3e\\n\\n## FAQ\\n\\n### Why Python doesn\'t use UTF-8 encoding variable-length bytes in memory directly, why it will convert them to **UCS-2** or **UCS-4** data?\\n\\nKeep each character in a string in the same width in the data memory.\\n\\nWhat\'s the purpose?\\n\\n1. Indexing into strings in Python is operated in a constant time, as it\'s based on the fixed-length encodings.\\n\\n### How do other programming languages access character in a string by index?\\n\\n- Go\\n  - Iterating yields Unicode code point\\n  - Indexing yields a byte\\n- Rust\\n  - Iteration yields Unicode code point(`method.chars()`) or byte(`method.bytes`)\\n  - Indexing not supported\\n- Python\\n  - Iterating yields Unicode code point\\n  - Indexing yields Unicode code point\\n\\n### How a string in Python is printed on the screen?\\n\\nYou may wonder why they have the same result on the terminal from Python output, assuming that the terminal is using the UTF-8 encoding.\\n\\n```py\\n>>> \\"\\\\xe9\\"\\n\'\xe9\'\\n>>> \\"\\\\u00e9\\"\\n\'\xe9\'\\n>>> \'\xe9\'\\n\'\xe9\'\\n```\\nWhen Python prints string, here the `print()` is used in default in Python IDE.\\n\\n1. create `PyObject`. When the string is `\\\\xe9` or `\\\\u00e9`, the Python interpret they as the **code point** of which `0xe9` is `233` in decimal. And convert it in `PyUnicodeObject` of which  stores data use `UCS-1` as `0xe9` is one byte.  \\n2. print the `PyUnicodeObject`. As the system locale uses UTF-8 Encoding, Python will convert `UCS-1` data to utf-8 encoding bytes, which is `b\'\\\\xc3\\\\xa9\'`.\\n    ```py\\n    >>> \'\xe9\'.encode()\\n    b\'\\\\xc3\\\\xa9\'\\n    ```\\n3. send bytes to the terminal emulator. `b\'\\\\xc3\\\\xa9\'` is sent to the terminal which uses the UTF-8 encoding. `b\'\\\\xc3\\\\xa9\'` in utf-8 is decode as code point `\\\\u00e9` which represent the character `\xe9`. \\n4. draw character. The terminal emulator draw the glyph `\xe9` on the screen as you see.\\n\\nIf the terminal using `latin-1`, `\\"\\\\xe9\\"` will be show as `\xc3\xa9` in the terminal.\\n\\n### How to write raw bytes to the terminal from Python?\\n\\nAs you see above, Python print strings:\\n\\n1. firstly strings are encoded to utf-8 bytes.\\n2. secondly these bytes are sent to the terminal.\\n\\nSometimes, you may want to write raw bytes in the terminal directly to see how the terminal represents these bytes on the screen.\\n\\n```sh\\n\u279c  ~ python3 -c \'import sys; sys.stdout.buffer.write(b\\"\\\\xc3\\\\xa9\\")\'\\n\xe9\\n```\\n\\nUTF-8 terminal represent bytes `b\\"\\\\xc3\\\\xa9\\"` to character `\xe9`.\\n\\n```sh\\n\u279c  ~ python3 -c \'import sys; sys.stdout.buffer.write(b\\"\\\\xe9\\")\'\\n\ufffd\\n```\\n\\nUTF-8 terminal can not represent bytes `b\\"\\\\xe9\\"` to any known character, as `b\\"\\\\xe9\\"` is not a valid utf-8 encoding bytes.\\n\\n[python - Python3 print raw byte - Stack Overflow](https://stackoverflow.com/questions/42179786/python3-print-raw-byte)\\n\\n## An outline of the `PyUnicodeObject`\\n\\nReferences are mainly from:\\n\\n- [ctypes \u2014 A foreign function library for Python \u2014 Python 3.12.1 documentation](https://docs.python.org/3/library/ctypes.html)\\n- [unicodeobject.h](https://github.com/python/cpython/blob/3.10/Include/cpython/unicodeobject.h#L85-L244)\\n- [unicodeobject.c](https://github.com/python/cpython/blob/3.10/Objects/unicodeobject.c)\\n\\nA brief `PyUnicodeObject` structure defined from [unicodeobject.h](https://github.com/python/cpython/blob/3.10/Include/cpython/unicodeobject.h#L85-L244):\\n\\n```c title=\\"cpython/Include/cpython/unicodeobject.h\\"\\ntypedef struct {\\n    Py_ssize_t ob_refcnt;\\n    PyTypeObject *ob_type;\\n} PyObject\\n/* --- Unicode Type ------------------------------------------------------- */\\ntypedef struct {\\n    /* There are 4 forms of Unicode strings:\\n\\n       - compact ascii:\\n\\n         * structure = PyASCIIObject\\n         * test: PyUnicode_IS_COMPACT_ASCII(op)\\n         * kind = PyUnicode_1BYTE_KIND\\n         * compact = 1\\n         * ascii = 1\\n         * ready = 1\\n         * (length is the length of the utf8 and wstr strings)\\n         * (data starts just after the structure)\\n         * (since ASCII is decoded from UTF-8, the utf8 string are the data)\\n\\n       - compact:\\n\\n         * structure = PyCompactUnicodeObject\\n         * test: PyUnicode_IS_COMPACT(op) && !PyUnicode_IS_ASCII(op)\\n         * kind = PyUnicode_1BYTE_KIND, PyUnicode_2BYTE_KIND or\\n           PyUnicode_4BYTE_KIND\\n         * compact = 1\\n         * ready = 1\\n         * ascii = 0\\n         * utf8 is not shared with data\\n         * utf8_length = 0 if utf8 is NULL\\n         * wstr is shared with data and wstr_length=length\\n           if kind=PyUnicode_2BYTE_KIND and sizeof(wchar_t)=2\\n           or if kind=PyUnicode_4BYTE_KIND and sizeof(wchar_t)=4\\n         * wstr_length = 0 if wstr is NULL\\n         * (data starts just after the structure)\\n\\n       - legacy string, not ready:\\n\\n         * structure = PyUnicodeObject\\n         * test: kind == PyUnicode_WCHAR_KIND\\n         * length = 0 (use wstr_length)\\n         * hash = -1\\n         * kind = PyUnicode_WCHAR_KIND\\n         * compact = 0\\n         * ascii = 0\\n         * ready = 0\\n         * interned = SSTATE_NOT_INTERNED\\n         * wstr is not NULL\\n         * data.any is NULL\\n         * utf8 is NULL\\n         * utf8_length = 0\\n\\n       - legacy string, ready:\\n\\n         * structure = PyUnicodeObject structure\\n         * test: !PyUnicode_IS_COMPACT(op) && kind != PyUnicode_WCHAR_KIND\\n         * kind = PyUnicode_1BYTE_KIND, PyUnicode_2BYTE_KIND or\\n           PyUnicode_4BYTE_KIND\\n         * compact = 0\\n         * ready = 1\\n         * data.any is not NULL\\n         * utf8 is shared and utf8_length = length with data.any if ascii = 1\\n         * utf8_length = 0 if utf8 is NULL\\n         * wstr is shared with data.any and wstr_length = length\\n           if kind=PyUnicode_2BYTE_KIND and sizeof(wchar_t)=2\\n           or if kind=PyUnicode_4BYTE_KIND and sizeof(wchar_4)=4\\n         * wstr_length = 0 if wstr is NULL\\n\\n       Compact strings use only one memory block (structure + characters),\\n       whereas legacy strings use one block for the structure and one block\\n       for characters.\\n\\n       Legacy strings are created by PyUnicode_FromUnicode() and\\n       PyUnicode_FromStringAndSize(NULL, size) functions. They become ready\\n       when PyUnicode_READY() is called.\\n\\n       See also _PyUnicode_CheckConsistency().\\n    */\\n    PyObject_HEAD\\n    Py_ssize_t length;          /* Number of code points in the string */\\n    Py_hash_t hash;             /* Hash value; -1 if not set */\\n    struct {\\n        /*\\n           SSTATE_NOT_INTERNED (0)\\n           SSTATE_INTERNED_MORTAL (1)\\n           SSTATE_INTERNED_IMMORTAL (2)\\n\\n           If interned != SSTATE_NOT_INTERNED, the two references from the\\n           dictionary to this object are *not* counted in ob_refcnt.\\n         */\\n        unsigned int interned:2;\\n        /* Character size:\\n\\n           - PyUnicode_WCHAR_KIND (0):\\n\\n             * character type = wchar_t (16 or 32 bits, depending on the\\n               platform)\\n\\n           - PyUnicode_1BYTE_KIND (1):\\n\\n             * character type = Py_UCS1 (8 bits, unsigned)\\n             * all characters are in the range U+0000-U+00FF (latin1)\\n             * if ascii is set, all characters are in the range U+0000-U+007F\\n               (ASCII), otherwise at least one character is in the range\\n               U+0080-U+00FF\\n\\n           - PyUnicode_2BYTE_KIND (2):\\n\\n             * character type = Py_UCS2 (16 bits, unsigned)\\n             * all characters are in the range U+0000-U+FFFF (BMP)\\n             * at least one character is in the range U+0100-U+FFFF\\n\\n           - PyUnicode_4BYTE_KIND (4):\\n\\n             * character type = Py_UCS4 (32 bits, unsigned)\\n             * all characters are in the range U+0000-U+10FFFF\\n             * at least one character is in the range U+10000-U+10FFFF\\n         */\\n        unsigned int kind:3;\\n        /* Compact is with respect to the allocation scheme. Compact unicode\\n           objects only require one memory block while non-compact objects use\\n           one block for the PyUnicodeObject struct and another for its data\\n           buffer. */\\n        unsigned int compact:1;\\n        /* The string only contains characters in the range U+0000-U+007F (ASCII)\\n           and the kind is PyUnicode_1BYTE_KIND. If ascii is set and compact is\\n           set, use the PyASCIIObject structure. */\\n        unsigned int ascii:1;\\n        /* The ready flag indicates whether the object layout is initialized\\n           completely. This means that this is either a compact object, or\\n           the data pointer is filled out. The bit is redundant, and helps\\n           to minimize the test in PyUnicode_IS_READY(). */\\n        unsigned int ready:1;\\n        /* Padding to ensure that PyUnicode_DATA() is always aligned to\\n           4 bytes (see issue #19537 on m68k). */\\n        unsigned int :24;\\n    } state;\\n    wchar_t *wstr;              /* wchar_t representation (null-terminated) */\\n} PyASCIIObject;\\n\\n/* Non-ASCII strings allocated through PyUnicode_New use the\\n   PyCompactUnicodeObject structure. state.compact is set, and the data\\n   immediately follow the structure. */\\ntypedef struct {\\n    PyASCIIObject _base;\\n    Py_ssize_t utf8_length;     /* Number of bytes in utf8, excluding the\\n                                 * terminating \\\\0. */\\n    char *utf8;                 /* UTF-8 representation (null-terminated) */\\n    Py_ssize_t wstr_length;     /* Number of code points in wstr, possible\\n                                 * surrogates count as two code points. */\\n} PyCompactUnicodeObject;\\n\\n/* Strings allocated through PyUnicode_FromUnicode(NULL, len) use the\\n   PyUnicodeObject structure. The actual string data is initially in the wstr\\n   block, and copied into the data block using _PyUnicode_Ready. */\\ntypedef struct {\\n    PyCompactUnicodeObject _base;\\n    union {\\n        void *any;\\n        Py_UCS1 *latin1;\\n        Py_UCS2 *ucs2;\\n        Py_UCS4 *ucs4;\\n    } data;                     /* Canonical, smallest-form Unicode buffer */\\n} PyUnicodeObject;\\n```\\n\\nAs it\'s known that each Unicode character in string is represented by a Unicode code point. In `PyUnicodeObject`, these code points are the encoding saved in the `data`, so `PyUnicodeObject` does not use the `UTF-8` encoding in the `data`.\\n\\n## How a Unicode string object is created?\\n\\nInvokes several internal C functions in such a sequence generally,\\n\\n```c\\nPyObject *PyUnicode_FromStringAndSize(const char *str, Py_ssize_t size)\\n\\nPyObject *PyUnicode_DecodeUTF8Stateful(const char *str, Py_ssize_t size, const char *errors, Py_ssize_t *consumed)\\n\\nstatic PyObject *unicode_decode_utf8(const char *s, Py_ssize_t size, _Py_error_handler error_handler, const char *errors, Py_ssize_t *consumed)\\n\\nPyObject *PyUnicode_New(Py_ssize_t size, Py_UCS4 maxchar)\\n\\nstatic Py_ssize_t ascii_decode(const char *start, const char *end, Py_UCS1 *dest)\\n\\nch = ucs2lib_utf8_decode(&s, end, writer.data, &writer.pos);\\n\\n// ucs2lib.h\\n#define STRINGLIB(F)             ucs2lib_##F\\nSTRINGLIB(utf8_decode)(const char **inptr, const char *end,\\n                       STRINGLIB_CHAR *dest,\\n                       Py_ssize_t *outpos)\\n\\n```\\n\\n## Inspect Unicode string object in Python 3\\n\\nLet\'s examine the internal data struct of a string object in modern Python 3.\\n\\n:::NOTE\\nYou keep the character being referred otherwise the `GC` may release that memory,\\n\\nDefine the layout mapping `unicodeobject`,\\n\\n```py\\nimport ctypes\\n\\n# It\'s recommended to go to see [python 3.10 unicodeobject.h](https://github.com/python/cpython/blob/3.10/Include/cpython/unicodeobject.h#L85-L244)\\nclass PyASCIIObject(ctypes.Structure):\\n    # internal fields of the string object\\n    _fields_ = [\\n        (\\"ob_refcnt\\", ctypes.c_long),\\n        (\\"ob_type\\", ctypes.c_void_p),\\n        (\\"length\\", ctypes.c_ssize_t),\\n        (\\"hash\\", ctypes.c_ssize_t),\\n        (\\"interned\\", ctypes.c_uint, 2),\\n        (\\"kind\\", ctypes.c_uint, 3),\\n        (\\"compact\\", ctypes.c_uint, 1),\\n        (\\"ascii\\", ctypes.c_uint, 1),\\n        (\\"ready\\", ctypes.c_uint, 1),\\n        (\\"_padding\\", ctypes.c_uint, 24),\\n        (\\"wstr\\", ctypes.POINTER(ctypes.c_wchar))\\n    ]\\n\\n    def __repr__(self) -> str:\\n        return f\\"ob_refcnt[{self.ob_refcnt}], length[{self.length}], interned[{self.interned}], kind[{self.kind}], compact[{self.compact}], ascii[{self.ascii}], ready[{self.ready}]\\"\\n    \\nclass PyCompactUnicodeObject(PyASCIIObject):\\n    # internal fields of the string object\\n    _fields_ = [\\n        (\\"utf8_length\\", ctypes.c_ssize_t),\\n        (\\"utf8\\", ctypes.POINTER(ctypes.c_char)),\\n        (\\"wstr_length\\", ctypes.c_ssize_t),\\n    ]\\n\\n    def __repr__(self) -> str:\\n        return super().__repr__() + f\\" utf8_length[{self.utf8_length}], utf8[{self.utf8}], wstr_length[{self.wstr_length}]\\"\\n    \\nclass PyUnicodeObject(PyCompactUnicodeObject):\\n    class _Data(ctypes.Union):\\n        _fields_ = [\\n            (\\"any\\", ctypes.c_void_p),\\n            (\\"latin1\\", ctypes.POINTER(ctypes.c_uint8)),\\n            (\\"ucs2\\", ctypes.POINTER(ctypes.c_uint16)),\\n            (\\"ucs4\\", ctypes.POINTER(ctypes.c_uint32)),\\n        ]\\n    \\n    _fields_ = [\\n        (\\"data\\", _Data),\\n    ]\\n```\\n\\n1. Type: compact ascii. Key fields: kind[1], compact[1], ascii[1], ready[1]\\n\\n```py\\n>>> string_obj = \\"Hello, ctypes!\\"\\n>>> addr = id(string_obj)\\n>>> ascii_obj = PyASCIIObject.from_address(addr)\\n>>> print(ascii_obj)\\nob_refcnt[1], length[14], interned[0], kind[1], compact[1], ascii[1], ready[1]\\n>>>\\n>>> # compact ascii: data starts just after the structure\\n>>> data_addr = addr + ctypes.sizeof(PyASCIIObject)\\n>>> data = ctypes.cast(data_addr, ctypes.c_char_p)\\n>>> print(f\\"data: {data.value}\\")\\ndata: b\'Hello, ctypes!\'\\n```\\n\\n2. Type: compact `UCS-2`. Key fields: kind[1], compact[1], ascii[1], ready[1]\\n\\n```py\\n>>> string_obj = \\"\u4f60\u597d!\\"\\n>>> addr = id(string_obj)\\n>>> ascii_obj = PyASCIIObject.from_address(addr)\\n>>> print(ascii_obj)\\nob_refcnt[1], length[3], interned[0], kind[2], compact[1], ascii[0], ready[1]\\n>>>\\n>>> compact_obj = PyCompactUnicodeObject.from_address(addr)\\n>>> print(compact_obj)\\nob_refcnt[1], length[3], interned[0], kind[2], compact[1], ascii[0], ready[1] utf8_length[0], utf8[<ctypes.LP_c_char object at 0x7f0c29297ac\\n0>], wstr_length[0]\\n>>>\\n>>> # compact: data starts just after the structure\\n>>> data_addr = addr + ctypes.sizeof(PyCompactUnicodeObject)\\n>>> data = ctypes.cast(data_addr, ctypes.POINTER(ctypes.c_uint16))\\n>>> print(f\\"data: {data[0]}, {data[0]:#06x}, {chr(data[0])}\\")\\ndata: 20320, 0x4f60, \u4f60\\n>>> print(f\\"data: {data[1]}, {data[1]:#06x}, {chr(data[1])}\\")\\ndata: 22909, 0x597d, \u597d\\n>>> print(f\\"data: {data[2]}, {data[2]:#06x}, {chr(data[2])}\\")\\ndata: 33, 0x0021, !\\n>>> print(f\\"data: {data[3]}, {data[3]:#06x}, {chr(data[3])}\\")\\ndata: 0, 0x0000,\\n```\\n\\n3. Type: compact `UCS-4`. Key fields: kind[4], compact[1], ascii[1], ready[1]\\n\\n```py\\n>>> string_obj = \\"\u4f60\u597d\ud83e\udd28\\"\\n>>> addr = id(string_obj)\\n>>> ascii_obj = PyASCIIObject.from_address(addr)\\n>>> print(ascii_obj)\\nob_refcnt[1], length[3], interned[0], kind[4], compact[1], ascii[0], ready[1]\\n>>>\\n>>> compact_obj = PyCompactUnicodeObject.from_address(addr)\\n>>> print(compact_obj)\\nob_refcnt[1], length[3], interned[0], kind[4], compact[1], ascii[0], ready[1] utf8_length[0], utf8[<ctypes.LP_c_char object at 0x7f0c292b1ac\\n0>], wstr_length[3]\\n>>>\\n>>> # compact: data starts just after the structure\\n>>> data_addr = addr + ctypes.sizeof(PyCompactUnicodeObject)\\n>>> data = ctypes.cast(data_addr, ctypes.POINTER(ctypes.c_uint32))\\n>>> print(f\\"data: {data[0]}, {data[0]:#010x}, {chr(data[0])}\\")\\ndata: 20320, 0x00004f60, \u4f60\\n>>> print(f\\"data: {data[1]}, {data[1]:#010x}, {chr(data[1])}\\")\\ndata: 22909, 0x0000597d, \u597d\\n>>> print(f\\"data: {data[2]}, {data[2]:#010x}, {chr(data[2])}\\")\\ndata: 129320, 0x0001f928, \ud83e\udd28\\n>>> print(f\\"data: {data[3]}, {data[3]:#010x}, {chr(data[3])}\\")\\ndata: 0, 0x00000000,\\n```\\n\\n\\n4. Type: legacy string. Key fields: kind[2], compact[0], ascii[0]\\n\\nI can\'t produce it in Python3.10, maybe you can try python2.7. \\n\\n\\nAll codes are at [object layout](../code-snippets/python/c-types/UnicodeObject.py)\\n\\n## Resources\\n\\n[How Python saves memory when storing strings | Artem Golubin](https://rushter.com/blog/python-strings-and-memory/)\\n\\n[Python behind the scenes #9: how Python strings work](https://tenthousandmeters.com/blog/python-behind-the-scenes-9-how-python-strings-work/)\\n\\nhttps://nedbatchelder.com/text/unipain.html\\n\\nhttps://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/"},{"id":"/wiki-cryptography","metadata":{"permalink":"/blog/wiki-cryptography","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-cryptography.mdx","source":"@site/../../blog/wiki-cryptography.mdx","title":"Wiki Cryptography","description":"Wiki Cryptography","date":"2023-12-08T00:00:00.000Z","formattedDate":"December 8, 2023","tags":[{"label":"wiki","permalink":"/blog/tags/wiki"},{"label":"cryptography","permalink":"/blog/tags/cryptography"},{"label":"aes","permalink":"/blog/tags/aes"},{"label":"symmetric","permalink":"/blog/tags/symmetric"},{"label":"asymmetric","permalink":"/blog/tags/asymmetric"}],"readingTime":0.08,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["wiki","cryptography","aes","symmetric","asymmetric"],"description":"Wiki Cryptography","keywords":["Wiki Cryptography"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-12-08T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Python Unicode String","permalink":"/blog/python-unicode-string"},"nextItem":{"title":"Wiki Unicode","permalink":"/blog/wiki-unicode"}},"content":"\x3c!--truncate--\x3e\\n\\n## Asymmetric cryptography\\n\\nAlso known as public-key cryptography\\n\\n## Symmetric cryptography\\n\\n### AES-128\\n\\n## Resources"},{"id":"/wiki-unicode","metadata":{"permalink":"/blog/wiki-unicode","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-unicode.mdx","source":"@site/../../blog/wiki-unicode.mdx","title":"Wiki Unicode","description":"Wiki UTF8","date":"2023-12-08T00:00:00.000Z","formattedDate":"December 8, 2023","tags":[{"label":"wiki","permalink":"/blog/tags/wiki"},{"label":"utf-8","permalink":"/blog/tags/utf-8"},{"label":"encode","permalink":"/blog/tags/encode"}],"readingTime":5.685,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["wiki","utf-8","encode"],"description":"Wiki UTF8","keywords":["Wiki UTF8"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-12-08T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Wiki Cryptography","permalink":"/blog/wiki-cryptography"},"nextItem":{"title":"Wiki Development Environment","permalink":"/blog/wiki-dev-environment"}},"content":"The smallest unit of all texts we see on the screen is one character. But you may wonder about:\\n\\n1. How one character is displayed on the screen?\\n2. How one character is kept in memory or disk in binary format(0 or 1)?\\n\\nLet\'s dive into the **Unicode** to solve these questions.\\n\\nIn Unicode, a character maps to something called code point which is a magic number written as hex like: `U+20AC` and is still just a abstract layer.\\n\\n| Layer       | Representation                      |\\n|-------------|-------------------------------------|\\n| screen      | glyph                               |\\n| abstraction | unicode character                   |\\n| abstraction | unicode code point                  |\\n| disk        | variable-length bytes(1 to 4 bytes) |\\n\\nHow that code point is represented in memory or on disk?\\n\\n`UTF-8`, `UTF-16`, and `UTF-32` help translate unicode code point into binary data in 8-bit bytes which can be saved in disk or be transported in network.\\n\\n`UTF-8` is character-to-bytes(1 to 4 bytes) encoding standard across almost all system and application.\\n\\n\x3c!--truncate--\x3e\\n\\n## FAQ\\n\\n### How a character is displayed on the screen?\\n\\nsoftware maps each character to its glyph(a grid of pixels), draw these pixels onto the screen.\\n\\n### How to find out whether the file uses UTF-8 or ASCII or other encoding schemas?\\n\\nIt\'s not always foolproof because there is no universal mandate or requirement that all files must specify their encoding. But it\'s a good practice to add BOM(Byte Order Mark) at the beginning of a UTF-8 encoded file.\\n\\n### Can I set UTF-16 as locale in Linux?\\n\\nNo, you cannot. Linux use `UTF-8` encoding which is compatible with `ASCII`.\\n\\n### What happens when printing a UTF-16 file in Linux?\\n\\n```sh\\n# >>> \'\u20ac\'.encode(\\"utf16\\") -> b\'\\\\xff\\\\xfe\\\\xac \'\\n$ echo -n -e \\\\\\\\xff\\\\\\\\xfe\\\\\\\\xac\\\\\\\\x20 > a.txt\\n$ hexdump -C a.txt\\n00000000  ff fe ac 20                                       |... |\\n00000004\\n$ file a.txt\\na.txt: Unicode text, UTF-16, little-endian text, with no line terminators\\n$ cat a.txt\\n\ufffd\ufffd\ufffd\\n$ iconv -f UTF-16LE -t UTF-8 a.txt\\n\u20ac\\n```\\n\\n### How can I check a UTF-8 file has a `BOM`?\\n\\nCreate a file without `BOM`,\\n\\n```py\\n>>> f.flush()\\n>>> b\'\\\\xe2\\\\x82\\\\xac\'.decode()\\n\'\u20ac\'\\n>>> \'\u20ac\'.encode()\\nb\'\\\\xe2\\\\x82\\\\xac\'\\n>>> bom=b\\"\\\\xef\\\\xbb\\\\xbf\\"\\n>>> f=open(\\"a.txt\\", \\"wb+\\")\\n>>> f.write(b\'\\\\xe2\\\\x82\\\\xac\')\\n3\\n>>> f.flush()\\n```\\n\\n```sh\\n$ file a.txt\\na.txt: Unicode text, UTF-8 text, with no line terminators\\n```\\n\\nCreate a `BOM` adhere file,\\n\\n```py\\n>>> f.seek(0)\\n0\\n>>> f.truncate(0)\\n0\\n>>> f.write(b\'\\\\xef\\\\xbb\\\\xbf\\\\xe2\\\\x82\\\\xac\')\\n6\\n>>> f.flush()\\n```\\n\\n```sh\\n$ file a.txt\\na.txt: Unicode text, UTF-8 (with BOM) text, with no line terminators\\n$ hexdump -C a.txt\\n00000000  ef bb bf e2 82 ac                                 |......|\\n00000006\\n```\\n\\n### Why we can copy and paste the unicode characters into a shell?\\n\\nWhen we do copying on the screen, we\'re copying the character\'s UTF8 encoded **bytes** which is in the memory, not the **code point**.\\n\\n```sh\\n# b\'\\\\xe2\\\\x82\\\\xac\'.decode() -> \'\u20ac\'\\n$ echo -e \\\\\\\\xe2\\\\\\\\x82\\\\\\\\xac | xclip -selection clipboard\\n```\\n\\nThen you can use your mouse right click to copy to the shell and you will see `\u20ac`.\\n\\n### How a string is stored in memory when Python running?\\n\\n## Unicode in JSON\\n\\nJSON(natively a text format) support the unicode character to be escaped or not. When **being escaped**, the character will be replaced with the unicode code point, then which will be represented in 6 or 8 ascii characters occupying 6 or 8 bytes. When **not being escaped**, the character will be represented as just one unicode character as itself occupying 1 to 4 bytes if using UTF-8.\\n\\nEscaping will cost more storage but will be compatible in ASCII-only environments, as escaping force all characters to be ASCII characters.\\n\\nCase 1: Characters escaped,\\n\\n```py\\n>>> import json\\n>>> b=b\'{\\"text\\": \\"\\\\u4f60\\\\u597d\\"}\'\\n>>> json.loads(b)\\n{\'text\': \'\u4f60\u597d\'}jsn\\n>>> json.dumps(json.loads(b))\\n\'{\\"text\\": \\"\\\\\\\\u4f60\\\\\\\\u597d\\"}\'\\n>>> json.dumps(json.loads(b), ensure_ascii=False)\\n\'{\\"text\\": \\"\u4f60\u597d\\"}\'\\n```\\n\\n```py\\n>>> f=open(\\"a.txt\\", \\"w+\\")\\n>>> f.write(json.dumps(json.loads(b)))\\n24\\n>>> f.flush()\\n```\\n\\n```sh\\n$ cat a.txt\\n{\\"text\\": \\"\\\\u4f60\\\\u597d\\"}#\\n$  hexdump -C a.txt\\n00000000  7b 22 74 65 78 74 22 3a  20 22 5c 75 34 66 36 30  |{\\"text\\": \\"\\\\u4f60|\\n00000010  5c 75 35 39 37 64 22 7d                           |\\\\u597d\\"}|\\n00000018\\n```\\n\\nCase 2: Characters not escaped,\\n\\n```py\\n>>> f.seek(0)\\n0\\n>>> f.truncate(0)\\n0\\n>>> f.write(json.dumps(json.loads(b), ensure_ascii=False))\\n14\\n>>> f.flush()\\n```\\n\\n```sh\\n$ cat a.txt\\n{\\"text\\": \\"\u4f60\u597d\\"}#\\n$ hexdump -C a.txt\\n00000000  7b 22 74 65 78 74 22 3a  20 22 e4 bd a0 e5 a5 bd  |{\\"text\\": \\"......|\\n00000010  22 7d                                             |\\"}|\\n00000012\\n```\\n\\n## Base64\\n\\nBase64 is binary-to-text encoding schema which make bytes data to be represented in ASCII characters to be human readable.\\n\\n## Python \\n\\n## C application\\n\\nLet\'s have a look at how the **Unicode** is represented in a `C` executable file.\\n\\n1. `char`\\n\\n```sh\\ncat > unicode.c << EOL\\n#include <stdio.h>\\n\\nint main(){\\n    printf(\\"Hello, World \u4f60\u597d\ud83e\udd28!\\\\n\\");\\n    return 0;\\n}\\nEOL\\n```\\n\\n```sh\\ngcc unicode.c -o unicode.out\\n```\\n\\n```sh\\nroot@112b172acfff:/workspaces/liviaerxin.github.io/# hexdump -C unicode.out | grep -A3 \\"Hello, World\\"\\n00002000  01 00 02 00 48 65 6c 6c  6f 2c 20 57 6f 72 6c 64  |....Hello, World|\\n00002010  20 e4 bd a0 e5 a5 bd f0  9f a4 a8 21 00 00 00 00  | ..........!....|\\n00002020  01 1b 03 3b 34 00 00 00  05 00 00 00 00 f0 ff ff  |...;4...........|\\n00002030  68 00 00 00 20 f0 ff ff  90 00 00 00 30 f0 ff ff  |h... .......0...|\\n```\\n\\nView each character\'s **UTF8** encoding respectively,\\n```py\\n# utf-8 encoding bytes\\n>>> \\"\u4f60\\".encode()\\nb\'\\\\xe4\\\\xbd\\\\xa0\'\\n>>> \\"\u597d\\".encode()\\nb\'\\\\xe5\\\\xa5\\\\xbd\'\\n>>> \\"\ud83e\udd28\\".encode()\\nb\'\\\\xf0\\\\x9f\\\\xa4\\\\xa8\'\\n```\\n\\nSo  `char` in the C output file stores the UTF8 encoding **bytes**, not the code points.\\n\\n2. `wide char`,\\n\\n```sh\\ncat > unicode.c << EOL\\n#include <stdio.h>\\n#include <wchar.h>\\n#include <locale.h>\\n\\nint main(int argc, char *argv[])\\n{\\n    setlocale(LC_ALL, \\"C.UTF-8\\");\\n    wchar_t* msg = L\\"Hello, World \u4f60\u597d\ud83e\udd28!\\";\\n    printf(\\"%ls\\\\n\\", msg);\\n    return 0;\\n}\\nEOL\\n```\\n\\n```sh\\nroot@112b172acfff:/workspaces/liviaerxin.github.io/# hexdump -C unicode.out\\n00002000  01 00 02 00 00 00 00 00  43 2e 55 54 46 2d 38 00  |........C.UTF-8.|\\n00002010  48 00 00 00 65 00 00 00  6c 00 00 00 6c 00 00 00  |H...e...l...l...|\\n00002020  6f 00 00 00 2c 00 00 00  20 00 00 00 57 00 00 00  |o...,... ...W...|\\n00002030  6f 00 00 00 72 00 00 00  6c 00 00 00 64 00 00 00  |o...r...l...d...|\\n00002040  20 00 00 00 60 4f 00 00  7d 59 00 00 28 f9 01 00  | ...`O..}Y..(...|\\n```\\n\\n```py\\n# unicode code point\\n>>> hex(ord(\\"H\\"))\\n\'0x48\'\\n>>> hex(ord(\\"\u4f60\\"))\\n\'0x4f60\'\\n>>> hex(ord(\\"\u597d\\"))\\n\'0x597d\'\\n>>> hex(ord(\\"\ud83e\udd28\\"))\\n\'0x1f928\'\\n```\\n\\n`wchar` in the C output file stores the **code point**(also in **little endian**), not the UTF8 encoding **bytes**.\\n\\nIn conclusion, `char` and `wchar` lead different encoding in **C**.\\n\\n## Resources\\n\\n[The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!) \u2013 Joel on Software](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/)\\n\\n[Pragmatic Unicode | Ned Batchelder](https://nedbatchelder.com/text/unipain.html)"},{"id":"/wiki-dev-environment","metadata":{"permalink":"/blog/wiki-dev-environment","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-dev-environment.mdx","source":"@site/../../blog/wiki-dev-environment.mdx","title":"Wiki Development Environment","description":"Wiki Dev Environment","date":"2023-12-04T00:00:00.000Z","formattedDate":"December 4, 2023","tags":[{"label":"wiki","permalink":"/blog/tags/wiki"},{"label":"dev-environment","permalink":"/blog/tags/dev-environment"}],"readingTime":1.58,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["wiki","dev-environment"],"description":"Wiki Dev Environment","keywords":["Wiki Dev Environment"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-12-04T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Wiki Unicode","permalink":"/blog/wiki-unicode"},"nextItem":{"title":"Wiki Network","permalink":"/blog/wiki-network"}},"content":"Here are some experiences that I have gotten to prepare a best-practice development environment for projects. I would like to update to keep up with the latest tech stacks.\\r\\n\\r\\n## VS Code\\r\\n\\r\\nAs of now, the `VS Code` is the most popular IDE among developers. Absolutely, for me, it\'s my first choice and favorite developing tool.\\r\\n\\r\\n### Dev Container\\r\\n\\r\\n[Developing inside a Container using Visual Studio Code Remote Development](https://code.visualstudio.com/docs/devcontainers/containers)\\r\\n\\r\\nWhat is Dev Container?\\r\\n\\r\\nA \\"Dev Container\\" typically refers to a development environment that is containerized. Containers are lightweight, portable, and consistent environments that encapsulate an application and its dependencies. They provide a standardized way to package and run software across different environments, ensuring that the application behaves consistently regardless of where it is deployed.\\r\\n\\r\\nThe benefits of using Dev Containers include:\\r\\n\\r\\n1. Consistency: Developers work in the same environment, reducing the chances of environment-related issues.\\r\\n2. Isolation: Dev Containers are isolated from the host system, preventing conflicts with other software installed on the developer\'s machine.\\r\\n3. Reproducibility: The development environment can be easily recreated by anyone using the container specifications.\\r\\n4. Portability: Dev Containers can be easily shared, allowing developers to work on the same project with minimal setup.\\r\\n\\r\\nBest ways to customize the environment in Dev containers?\\r\\n\\r\\n- [Using Images, Dockerfile, and Docker Compose](https://containers.dev/guide/dockerfile):love_you_gesture:\\r\\n- [Using Features](https://containers.dev/features)\\r\\n- [Using lifecycle scripts](https://containers.dev/implementors/json_reference/#lifecycle-scripts)\\r\\n\\r\\nHow to Write Dockerfile for Dev containers?\\r\\n\\r\\nYou can refer to this repo [GitHub - devcontainers/images: Repository for pre-built dev container images published under mcr.microsoft.com/devcontainers](https://github.com/devcontainers/images)\\r\\n\\r\\nWhat magics does the `Dev Containers` extension do when starting?\\r\\n\\r\\n1. Hook a default startup command `while sleep 1000; do :; done` to keep the container not exit. Disable this behavior by setting `overrideCommand: false`.\\r\\n\\r\\nHow to run a container inside of Dev containers?\\r\\n\\r\\n- [Docker-in-Docker](https://github.com/microsoft/vscode-dev-containers/tree/main/containers/docker-in-docker)\\r\\n- [Docker-from-Docker](https://github.com/microsoft/vscode-dev-containers/tree/main/containers/docker-from-docker)\\r\\n\\r\\nFor instance, I use the **Docker-in-Docker** method to always test/run Docker containers inside of Dev containers.  \\r\\n\\r\\n### C/C++\\r\\n\\r\\n\\r\\n\x3c!--truncate--\x3e\\r\\n\\r\\n## Resources"},{"id":"/wiki-network","metadata":{"permalink":"/blog/wiki-network","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-network.mdx","source":"@site/../../blog/wiki-network.mdx","title":"Wiki Network","description":"Wiki Proxy","date":"2023-11-29T00:00:00.000Z","formattedDate":"November 29, 2023","tags":[{"label":"wiki","permalink":"/blog/tags/wiki"},{"label":"network","permalink":"/blog/tags/network"},{"label":"proxy","permalink":"/blog/tags/proxy"}],"readingTime":0.3,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/wiki-proxy.mdx"},"authors":["frank"],"tags":["wiki","network","proxy"],"description":"Wiki Proxy","keywords":["Wiki Proxy"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-11-29T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Wiki Development Environment","permalink":"/blog/wiki-dev-environment"},"nextItem":{"title":"Wiki Assembly","permalink":"/blog/wiki-assembly"}},"content":"How does **Wireshark** sniff the network traffic on OSX?\\n\\nOn OSX, **Wireshark** use `/dev/bpf*` which is the OSX system\'s packet capture devices.\\nOn Linux, **Wireshark** use `socket` to capture the network interface such as `eth0`.\\n\\n## TCP handshake\\n\\n## TLS handshake\\n\\nhttps://www.cloudflare.com/learning/ssl/what-happens-in-a-tls-handshake/\\n\\n\x3c!--truncate--\x3e\\n\\n## Man-in-the-middle(MitM) or Proxy\\n\\nhttps://httptoolkit.com/docs/guides/android/\\n\\nhttps://docs.mitmproxy.org/stable/concepts-howmitmproxyworks/\\n\\n## HTTPS proxy\\n\\n## HTTP proxy\\n\\n## SOCKS proxy\\n\\n## Resources"},{"id":"/wiki-assembly","metadata":{"permalink":"/blog/wiki-assembly","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-assembly.mdx","source":"@site/../../blog/wiki-assembly.mdx","title":"Wiki Assembly","description":"Wiki Assembly","date":"2023-11-22T00:00:00.000Z","formattedDate":"November 22, 2023","tags":[{"label":"Wiki Assembly","permalink":"/blog/tags/wiki-assembly"}],"readingTime":6.39,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/wiki-assembly.mdx"},"authors":["frank"],"tags":["Wiki Assembly"],"description":"Wiki Assembly","keywords":["Wiki Assembly"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-11-22T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Wiki Network","permalink":"/blog/wiki-network"},"nextItem":{"title":"Diagram Wiki","permalink":"/blog/wiki-diagram"}},"content":"Why `Assembly` language is important to to learn?\\n\\n1. The most low-level language that is closely tied to the hardware such as `CPU`.\\n   - `Assembly` code implements a symbolic (human-readable) representation of the binary machine code.\\n   - `Assembly` language is written to follow the `CPU` execution logic directly.\\n2. `Assembly` language facilities a deeper understanding how `CPU` actually do its job.\\n\\nWhy `Assembly` language is critical elementary foundation to other higher-level language, E.g. `C`?\\n\\n`Assembly` code is the important medium for compiling `C` code to machine code.\\nWhen `C` program being compiled to an binary object file, the `GCC` compiler will do following:\\n\\n1. `C` code will be compiled into `Assembly` code\\n2. `Assembly` code will be translated into machine code\\n\\nIs `Assembly` language cross-platform?\\n\\nNo, `Assembly` language is specific in the specific platform. E.g. `X86` CPU-architecture has its own `Assembly` instruction sets as well as the `arm` CPU.\\n\\n`Assembly` is CPU-dependent as machine code is CPU-dependent, while `C` language is CPU-independent for cross-platform.\\n\\nIs the first version of `GCC` written in `Assembly`?\\n\\nNo, `C` started with the `BCPL` language, [](https://stackoverflow.com/questions/18125490/how-was-the-first-c-compiler-written)\\n\x3c!--truncate--\x3e\\n\\n## Assembler\\n\\n- GNU assembler (GAS) \\n  - x86-64 GNU assembler \\n    * AT&T syntax\\n  - aarch64 GNU assembler\\n    * aarch64/arm64 syntax\\n- Clang Assembler\\n  - external Assembler\\n    - GNU Assembler\\n  - LLVM\u2019s integrated assembler\\n  - [](https://clang.llvm.org/docs/Toolchain.html#assembler)  \\n- Netwide assembler (NASM)\\n  * Intel syntax\\n  * x86-64\\n    * macOS\\n    * linux\\n    * windows\\n- MASM\\n  * Intel syntax\\n\\n### XXX\\n\\n```asm title=\\"print.asm\\"\\n; print.asm\\n; nasm -f elf64 print.asm && ld print.o && ./a.out ; echo $?\\n; objdump -d a.out\\nsection .data\\nmessage db, \\"Welcome,   to, Segmentation, Faults!, \\"\\n\\nsection .text\\n\\nglobal _start\\n\\n_printMessage:\\n    mov rax, 4       ; System call number for sys_write\\n    mov rbx, 1       ; File descriptor 1 is stdout\\n    mov rcx, message ; Pointer to the message string\\n    mov rdx, 32      ; Length of the message\\n    int 0x80         ; Call kernel\\n\\n    ret ; Return from the function\\n\\n_exit:\\n    mov rax, 1 ; System call number for sys_exit\\n    mov rbx, 0 ; Exit code 0\\n    int 0x80   ; Call kernel\\n\\n_start:\\n    call _printMessage ; Call the print message function\\n    mov  rax, 1        ; System call number for sys_exit\\n    mov  rbx, 1        ; Exit code 0\\n    int  0x80          ; Call kernel\\n```\\n\\n```asm title=\\"sum.asm\\"\\n; sum.asm\\n; nasm -f elf64 sum.asm && ld sum.o && ./a.out ; echo $?\\n; objdump -d a.out\\nsection .text\\nglobal _start\\n\\n; Function to calculate the sum of two integers\\nsum:\\n    mov rax, rdi   ; Move the first argument (a) to rax\\n    add rax, rsi   ; Add the second argument (b) to rax\\n    ret            ; Return with the result in rax\\n\\n_start:\\n    ; Example usage of the sum function\\n    mov rdi, 5     ; First argument: a = 5\\n    mov rsi, 7     ; Second argument: b = 7\\n\\n    call sum       ; Call the sum function\\n\\n    ; The result is now in rax\\n    ; It can be used or printed, depending on the context\\n    mov rdi, rax   ; Exit code 0\\n\\n    ; Exit the program\\n    mov rax, 60    ; System call number for sys_exit\\n    syscall        ; Make the system call\\n```\\n\\n## Memory Layout\\n\\nThe structure of an assembly file generally consists of serval section:\\n\\n- `.text` section:\\n   - `.text` section is generally read-only. It is typically used for storing executable code, and it is not intended to be modified during program execution.\\n   - `.text` section contains the machine code instructions that the processor will execute.\\n   - `.text` section contains global constant data.\\n- `.data` section:\\n   - `.data` section is writable. It is used for storing initialized data that can be modified during the execution of the program.\\n   - `.data` section contains global variable data.\\n- `.bss` section: \\n  - It\'s mostly the same with `.data` section except it\'s used for storing uninitialized data \\n- `.rodata` section:\\n  - It is used for read-only data, such as constant strings.\\n\\nHere\'s a simple example illustrating the use of these sections:\\n\\n\\n```asm\\n.section .text\\n.global _start\\n\\n_start:\\n    // Code goes here\\n\\n.section .data\\nmy_data:\\n    .word 42   // Initialized data\\n\\n.section .bss\\nmy_uninitialized_data:\\n    .skip 4    // Uninitialized data, occupies 4 bytes\\n\\n.section .rodata\\nmy_string:\\n    .asciz \\"Hello, World!\\"  // Read-only data\\n```\\n\\nA compiled program\'s memory layout consists of these segments.\\nA running program\'s memory layout consists of these segments, and also `heap` and `stack` memory.\\n\\n## Memory Layout of a Running Program\\n\\nA running program typically consists of serval segments or sections, each serving a specific purpose but common sections include:\\n\\n- `Stack`:\\n  - Stores local variables and function call information.\\n  - Memory is automatically allocated and de-allocated as functions are called and return.\\n  - Register(`sp` in `arm64`, stack pointer) is used to manage and point to the stack memory.\\n  - Size is limited(may lead to **stack overflow**).\\n    - set via `ulimit -s` in linux.\\n- `Heap`:\\n  - Dynamic memory managed by programmer at runtime.\\n  - Memory is allocated and deallocated explicitly using functions like `malloc`/`free` in `C`, and `new`/`delete` in `C++`, `brk` system call in `assembly` etc.\\n  - Store dynamic data that can be shared across functions. Data lifecycle is not bound to functions.\\n  - Size is much larger than the stack,\\n- `Data`(`.data`, `.bss`):\\n  - Stores global variables/constants, separated into initialized and uninitialized\\n- `Text`(`.text`): \\n  - Stores the code being executed\\n\\n[CS 225 | Stack and Heap Memory](https://courses.engr.illinois.edu/cs225/fa2022/resources/stack-heap/)\\n\\n## Label\\n\\n## Instruction\\n\\nAssembly instructions are human readable representation of the machine code as CPU can only understand the machine code.\\n\\nInstruction: Opcode + Oprand \\n\\n\\n### Opcode\\n\\n[Intel x86 Assembler Instruction Set Opcode Table](http://sparksandflames.com/files/x86InstructionChart.html)\\n\\n### Oprand\\n\\nData area\\n\\n#### Register Operand\\n\\n```asm\\nmov   rdi, rsi\\n```\\n\\n#### Immediate Operand\\n\\n```asm\\nmov   rdi, 0x21\\nmov   rdi, 5\\nmov   edi, 0x21314151\\n```\\n\\nin `aarch64`, the immediate value is subject to:\\n- Arithmetic instructions (add{s}, sub{s}, cmp, cmn) take a 12-bit unsigned immediate with an optional 12-bit left shift.\\n- Move instructions (movz, movn, movk) take a 16-bit immediate optionally shifted to any 16-bit-aligned position within the register.\\n- Address calculations (adr, adrp) take a 21-bit signed immediate, although there\'s no actual syntax to specify it directly - to do so you\'d have to resort to assembler expression trickery to generate an appropriate \\"label\\".\\n- Logical instructions (and{s}, orr, eor, tst) take a \\"bitmask immediate\\".\\n\\n#### Memory Operand\\n\\n```asm\\nmov   rdi, [sdi]\\n```\\n\\n### Instruction Encoding\\n\\nAssembler will encode the human-readable instruction into machine code.\\n\\n- In `aarch64`, the encoding instruction is **fixed-size**(4 bytes) machine code.\\n- In `x86_64`, the encoding instruction is **non-fixed-size**(up to 16 bytes) machine code.\\n\\n[Encoding Real x86 Instructions](http://www.c-jump.com/CIS77/CPU/x86/lecture.html)\\n\\nLet\'s have a glimpse on the impact of the **fixed/non-fixed** encoding.\\n\\nIn order to load 32-bit integer, `x86_64` need only **one** instruction while more instructions are needed for `aarch64` to do that.\\n\\nLoad a 32-bit integer `0x1a2b3c4d` in `x86_64`,\\n\\n```asm\\nmov     rid, 0x1a2b3c4d\\n```\\n\\nLoad a 32-bit integer 32-bit `0x1a2b3c4d` in `aarch64`(the immediate value in `mov` must be in the range of `16-bit`, so it needs **two** instructions),\\n\\n```asm\\nmovz    x1, 0x3c4d\\nmovk    x1, 0x1a2b, lsl 16\\n```\\n\\n## NASM x86_64 cheat sheet\\n\\n## GAS aarch64 cheat sheet\\n\\n## Assembly\'s Role in Compiler\\n\\nIn the compiling process, a compiler such as **GCC** will translate `C` code into `Assembly` code for different CPU architectures, then use its corresponding **Assembler** to translate the `Assembly` code to the machine code which is CPU dependent.\\n\\nThe `Assembly` plays intermediate role in the compiler, while higher language like `C` sits upfront and machine code runs at the bottom.\\n\\nI have another writing to introduce my understanding of the compiler from the practice more than the theoretical point of view, and how to write a compiler.\\n\\n[wiki compiler](./wiki-compiler.mdx)\\n\\n## Resources\\n\\nhttps://gist.github.com/mikesmullin/6259449\\n\\nhttps://cs.lmu.edu/~ray/notes/nasmtasutorial/\\n\\nhttps://cs.brown.edu/courses/cs033/docs/guides/x64_cheatsheet.pdf\\n\\nhttp://6.s081.scripts.mit.edu/sp18/x86-64-architecture-guide.html\\n\\nhttps://cs61.seas.harvard.edu/site/2018/Asm1/\\n\\nhttps://web.stanford.edu/class/cs107/guide/x86-64.html\\n\\nhttps://www.cs.virginia.edu/~evans/cs216/guides/x86.html\\n\\nhttps://www.cs.uaf.edu/2016/fall/cs301/lecture/09_28_machinecode.html\\n\\nhttps://p403n1x87.github.io/getting-started-with-x86-64-assembly-on-linux.html\\n\\nhttps://flint.cs.yale.edu/cs421/papers/x86-asm/asm.html\\n\\nhttps://nickdesaulniers.github.io/blog/2014/04/18/lets-write-some-x86-64/\\n\\nhttps://pacman128.github.io/static/pcasm-book.pdf\\n\\nhttps://redirect.cs.umbc.edu/portal/help/nasm/sample_64.shtml"},{"id":"/wiki-diagram","metadata":{"permalink":"/blog/wiki-diagram","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-diagram.mdx","source":"@site/../../blog/wiki-diagram.mdx","title":"Diagram Wiki","description":"Wiki Diagram","date":"2023-11-22T00:00:00.000Z","formattedDate":"November 22, 2023","tags":[{"label":"wiki","permalink":"/blog/tags/wiki"},{"label":"diagram","permalink":"/blog/tags/diagram"}],"readingTime":0.84,"hasTruncateMarker":false,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/wiki-diagram.mdx"},"authors":["frank"],"tags":["wiki","diagram"],"description":"Wiki Diagram","keywords":["Wiki Diagram"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-11-22T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Wiki Assembly","permalink":"/blog/wiki-assembly"},"nextItem":{"title":"Celery","permalink":"/blog/python-celery"}},"content":"## Diagram tools\\n\\n### Graphic-based diagram tools\\n\\nFeatures:\\n- Drag-and-drop functionality.\\n- A large library of shapes and icons.\\n- Complex diagram.\\n\\n\\nIncluding:\\n\\n- [Drawio](https://github.com/jgraph/drawio)\\n\\n- [Lucidchart](https://www.lucidchart.com)\\n\\n- [Miro](https://miro.com)\\n\\n### Text-based diagram tools\\n\\nFeatures:\\n\\n- Integration with text editors.\\n- Version control.\\n- Less flexible in terms of user interface and graphical capabilities.\\n\\nIncluding:\\n\\n- [Mermaid](https://github.com/mermaid-js/mermaid)\\n  - Embedded in Markdown or web pages easily.\\n  - Client-side rendering, based on JavaScript.\\n\\n- [Plantuml](https://github.com/plantuml/plantuml)\\n  - Client-side rendering, which needs Java runtime and `plantuml.jar`, and `graphviz` optionally for some diagram.\\n  - Or Server-side rendering, also needs the above libraries.\\n\\n- [Asciiflow](https://github.com/lewish/asciiflow)\\n  - Represent diagrams in pure ASCII TEXT, without any rendering.\\n\\n### Database schema-based diagram tools\\n\\nFeatures:\\n- Generate diagrams directly from database schema.\\n\\nIncluding:\\n- [ERD Editor | VSCode Extension](https://github.com/dineug/erd-editor)\\n\\n- [bigER Modeling Tool | VSCode Extension](https://github.com/borkdominik/bigER)\\n\\n- [MySQL Workbench](https://www.mysql.com/products/workbench/)\\n\\n- [DbVisualizer](https://www.dbvis.com/)\\n\\n- [ER/Studio](https://www.idera.com/er-studio-enterprise-architecture-solutions/)\\n\\n### Creating diagrams on GitHub\\n\\nYou can create diagrams in Markdown using three different syntaxes: `mermaid`, `geoJSON` and `topoJSON`, and `ASCII STL`, said by [GitHub official](https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-diagrams)."},{"id":"/python-celery","metadata":{"permalink":"/blog/python-celery","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/python-celery.mdx","source":"@site/../../blog/python-celery.mdx","title":"Celery","description":"wiki celery","date":"2023-10-30T00:00:00.000Z","formattedDate":"October 30, 2023","tags":[{"label":"wiki","permalink":"/blog/tags/wiki"},{"label":"celery","permalink":"/blog/tags/celery"},{"label":"best practice","permalink":"/blog/tags/best-practice"}],"readingTime":7.545,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/wiki-celery.mdx"},"authors":["frank"],"tags":["wiki","celery","best practice"],"description":"wiki celery","keywords":["celery"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-10-30T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Diagram Wiki","permalink":"/blog/wiki-diagram"},"nextItem":{"title":"Generate self-signed SSL/TLS certificate for local IP address or local domain","permalink":"/blog/certificate-sign"}},"content":"What is the **Celery**? **Celery** is a simple, flexible, and reliable distributed system to process vast amounts of tasks. In practice,\\n\\n1. **Celery** can be used to execute long-running jobs behind web servers to let your servers handle requests/responses in non-blocking ways.\\n2. **Celery** can do scheduled jobs.\\n\\nHere are some production-ready use cases for **Celery** I have encountered.\\n\\n\x3c!--truncate--\x3e\\n\\n## Celery worker\\n\\nCelery worker Mechanism:\\n\\nTo start a Celery worker will start a main process that will spawn child processes or threads(based on the `--pool` option): the main process will handle receiving task/sending task result the and these child processes/threads(a.k.a `execution pool`) execute the actual tasks.\\n\\nTo increase the number of child processes/threads(via `--concurrency` option) will increase the number of tasks the Celery worker can process in parallel. More processes are usually better.\\n\\nHowever, in reality, there are some situations in following modes:\\n\\n1. Run N workers with M child processes each.\\n2. Run 1 worker with N*M child processes.\\n3. Run N workers with only 1 main process each.\\n4. Run N workers with M child threads each.\\n5. Run 1 worker with N*M child threads.\\n\\nWhether to use `processes` or `threads` depends on what your tasks will actually do and whether they are GPU bound or IO bound.\\n\\n### Worker procedure\\n\\n```py\\nfrom celery import Celery\\n\\napp = Celery(...)\\n\\n@app.task()\\ndef add(x, y):\\n  return x + y\\n\\n@app.task()\\ndef mul(x, y):\\n  return x * y\\n```\\n\\nThe `@app.task` decoration will use `Task` class in default if you don\'t specify explicitly.\\n\\nWhen a worker start by `celery -A tasks worker`,\\n\\n1. Worker will spawn child Processes, the number of child Processes is based on CPU cores in default.\\n2. Each child Process will initialize a `Task` instance for every decorated function. Here `add()` has its own `Task` instance and `mul()` also has its own `Task` instance respectively.\\n\\nWhen a client call `add.delay(1, 2)`,\\n  \\n1. Worker receive a Task in Queue.\\n2. Worker assign the Task to a child Process, which will determine to use which `Task` instance to execute. A `Task` instance is initialized in each decorated function and registered with a task name using function name in default(such as `add`, `mul`). Here is the `Task` instance with name `add()` should be picked up to run the task.\\n3. When be decorated in `add()`, the `Task` instance `run()` method will be `add()` original function body. The child Process will use the `Task` instance\'s `__call__()` method to run task, and `__call__()` will invoke the `run()` within itself.  \\n\\n### Option --pool=prefork\\n\\nIt spawns multiple processes.\\n\\nWhen start a Celery worker via `celery -A tasks worker --loglevel INFO --concurrency 3 --pool=prefork`, what will happen underneath?\\n\\n1. Celery start a main process.\\n2. The main process will then spawn 3 child processes. The default `concurrency` is based on the number of `CPU` available on the machine. The default `pool` is `prefork` which uses `multiprocessing` library from Python.\\n3. These child processes will execute the tasks assigned from the main process.\\n\\n### Option --pool=eventlet or --pool=gevent\\n\\nIt creates multiple threads.\\n\\nWhen start a Celery worker via `celery -A tasks worker --loglevel INFO --concurrency 3 --pool=eventlet`\\n\\n### Option --pool=solo\\n\\nIt will not create any child process or thread to run task. The tasks will be executed in main process, which causes the main process to be blocked.\\n\\nIt seems as: Run 1 worker with 1 process, however `--concurrency` will not take any effect when `--pool=solo`!\\n\\nWhen coming to a microservices environment, this option becomes useful and practical especially running CPU intensive tasks. The container manager such as `Docker` can increase the task processing capabilities through managing the number of worker containers instead of managing the number of pool processes per worker.\\n\\nWhen start a Celery worker via `celery -A tasks worker --loglevel INFO --pool=solo`\\n\\n## Celery Task\\n\\nWhat\'s the lifecycle of a Celery task from the time it\'s created to the it\'s done?\\n\\nHere we analyze a simple task with all **Celery** configuration in default and use **Redis** as **broker** and **backend**\\n\\n```py\\n@app.task(acks_late=True)\\ndef wait(secs: float) -> str:\\n    print(f\\"wait() - Start, secs[{secs}]s\\")\\n    time.sleep(secs)\\n    print(f\\"wait() - Done, secs[{secs}]s\\")\\n    return f\\"wait() - Done, secs[{secs}]s\\"\\n```\\n\\n1. When a client call `wait.delay(60)`, this task is added to a default queue named `celery` in **Redis**.\\n2. **Celery** worker polls the queue and pulls the task, then it removes the task from the queue and moves it a special queue named `unacked` in **Redis**.\\n3. The worker holds on to the task(`prefetch`), until it has abilities to process the task.\\n4. Once after The worker successfully processes the task, it `acks` now (`acks_late=True`) that it removes the task from the `unacked` queue in **Redis**.\\n   - If `acks_late=False`, the worker `acks` before processing the task.\\n\\nLet\'s get more concrete understanding in practices.\\n\\n1. First, let\'s enter a `redis-cli` interactive mode with the newly launched application,\\n\\n```sh\\n127.0.0.1:6379> KEYS *\\n1) \\"_kombu.binding.email_service\\"\\n2) \\"_kombu.binding.ml_service\\"\\n3) \\"_kombu.binding.celery.pidbox\\"\\n4) \\"_kombu.binding.celeryev\\"\\n5) \\"_kombu.binding.celery\\"\\n```\\n\\nAt the beginning, you can see that the `celery` key and the `unacked` key do not exist in **Redis**.\\n\\n2. Then, let\'s call `wait.delay(60)` multiple times at the same time,\\n\\n```sh\\n127.0.0.1:6379> KEYS *\\n 1) \\"unacked_index\\"\\n 2) \\"_kombu.binding.email_service\\"\\n 3) \\"_kombu.binding.celery.pidbox\\"\\n 4) \\"celery-task-meta-3d6b2028-6ee6-4e2c-85f1-cbeba644aca5\\"\\n 5) \\"celery\\"\\n 6) \\"_kombu.binding.celeryev\\"\\n 7) \\"_kombu.binding.celery\\"\\n 8) \\"_kombu.binding.ml_service\\"\\n 9) \\"celery-task-meta-e5a1b7db-f1ad-4d3e-b2b9-3b7de8f8c87e\\"\\n10) \\"unacked\\"\\n127.0.0.1:6379> TYPE unacked\\nhash\\n127.0.0.1:6379> TYPE celery\\nlist\\n```\\n\\nAfter we create tasks, the `celery` key of `list` type and the `unacked` key of `hash` type are both created in **Redis**.\\n\\n```sh\\n127.0.0.1:6379> LRANGE celery 0 -1\\n1) \\"{\\\\\\"body\\\\\\": \\\\\\"W1s2MC4wXSwge30sIHsiY2FsbGJhY2tzIjogbnVsbCwgImVycmJhY2tzIjogbnVsbCwgImNoYWluIjogbnVsbCwgImNob3JkIjogbnVsbH1d\\\\\\", \\\\\\"content-encoding\\\\\\": \\\\\\"utf-8\\\\\\", \\\\\\"content-type\\\\\\": \\\\\\"application/json\\\\\\", \\\\\\"headers\\\\\\": {\\\\\\"lang\\\\\\": \\\\\\"py\\\\\\", \\\\\\"task\\\\\\": \\\\\\"app.celery_app.tasks.wait\\\\\\", \\\\\\"id\\\\\\": \\\\\\"da959152-1f45-4846-99e4-5205d30c1be7\\\\\\", \\\\\\"shadow\\\\\\": null, \\\\\\"eta\\\\\\": null, \\\\\\"expires\\\\\\": null, \\\\\\"group\\\\\\": null, \\\\\\"group_index\\\\\\": null, \\\\\\"retries\\\\\\": 0, \\\\\\"timelimit\\\\\\": [null, null], \\\\\\"root_id\\\\\\": \\\\\\"da959152-1f45-4846-99e4-5205d30c1be7\\\\\\", \\\\\\"parent_id\\\\\\": null, \\\\\\"argsrepr\\\\\\": \\\\\\"(60.0,)\\\\\\", \\\\\\"kwargsrepr\\\\\\": \\\\\\"{}\\\\\\", \\\\\\"origin\\\\\\": \\\\\\"gen11@a840cdd15b13\\\\\\", \\\\\\"ignore_result\\\\\\": false}, \\\\\\"properties\\\\\\": {\\\\\\"correlation_id\\\\\\": \\\\\\"da959152-1f45-4846-99e4-5205d30c1be7\\\\\\", \\\\\\"reply_to\\\\\\": \\\\\\"4b0f2f2d-aee2-3349-81ab-e95a1f0e9f02\\\\\\", \\\\\\"delivery_mode\\\\\\": 2, \\\\\\"delivery_info\\\\\\": {\\\\\\"exchange\\\\\\": \\\\\\"\\\\\\", \\\\\\"routing_key\\\\\\": \\\\\\"celery\\\\\\"}, \\\\\\"priority\\\\\\": 0, \\\\\\"body_encoding\\\\\\": \\\\\\"base64\\\\\\", \\\\\\"delivery_tag\\\\\\": \\\\\\"d657c66d-4e4b-483d-9fbe-fe4b5b9541e7\\\\\\"}}\\"\\n2) \\"{\\\\\\"body\\\\\\": \\\\\\"W1s2MC4wXSwge30sIHsiY2FsbGJhY2tzIjogbnVsbCwgImVycmJhY2tzIjogbnVsbCwgImNoYWluIjogbnVsbCwgImNob3JkIjogbnVsbH1d\\\\\\", \\\\\\"content-encoding\\\\\\": \\\\\\"utf-8\\\\\\", \\\\\\"content-type\\\\\\": \\\\\\"application/json\\\\\\", \\\\\\"headers\\\\\\": {\\\\\\"lang\\\\\\": \\\\\\"py\\\\\\", \\\\\\"task\\\\\\": \\\\\\"app.celery_app.tasks.wait\\\\\\", \\\\\\"id\\\\\\": \\\\\\"1ddc3c5e-fa33-4d12-aa3f-c3d13581a4c8\\\\\\", \\\\\\"shadow\\\\\\": null, \\\\\\"eta\\\\\\": null, \\\\\\"expires\\\\\\": null, \\\\\\"group\\\\\\": null, \\\\\\"group_index\\\\\\": null, \\\\\\"retries\\\\\\": 0, \\\\\\"timelimit\\\\\\": [null, null], \\\\\\"root_id\\\\\\": \\\\\\"1ddc3c5e-fa33-4d12-aa3f-c3d13581a4c8\\\\\\", \\\\\\"parent_id\\\\\\": null, \\\\\\"argsrepr\\\\\\": \\\\\\"(60.0,)\\\\\\", \\\\\\"kwargsrepr\\\\\\": \\\\\\"{}\\\\\\", \\\\\\"origin\\\\\\": \\\\\\"gen11@a840cdd15b13\\\\\\", \\\\\\"ignore_result\\\\\\": false}, \\\\\\"properties\\\\\\": {\\\\\\"correlation_id\\\\\\": \\\\\\"1ddc3c5e-fa33-4d12-aa3f-c3d13581a4c8\\\\\\", \\\\\\"reply_to\\\\\\": \\\\\\"4b0f2f2d-aee2-3349-81ab-e95a1f0e9f02\\\\\\", \\\\\\"delivery_mode\\\\\\": 2, \\\\\\"delivery_info\\\\\\": {\\\\\\"exchange\\\\\\": \\\\\\"\\\\\\", \\\\\\"routing_key\\\\\\": \\\\\\"celery\\\\\\"}, \\\\\\"priority\\\\\\": 0, \\\\\\"body_encoding\\\\\\": \\\\\\"base64\\\\\\", \\\\\\"delivery_tag\\\\\\": \\\\\\"927d1ac0-3709-4e23-8c0f-037713c55217\\\\\\"}}\\"\\n```\\n\\n```sh\\n127.0.0.1:6379> HGETALL unacked\\n1) \\"927d1ac0-3709-4e23-8c0f-037713c55217\\"\\n2) \\"[{\\\\\\"body\\\\\\": \\\\\\"W1s2MC4wXSwge30sIHsiY2FsbGJhY2tzIjogbnVsbCwgImVycmJhY2tzIjogbnVsbCwgImNoYWluIjogbnVsbCwgImNob3JkIjogbnVsbH1d\\\\\\", \\\\\\"content-encoding\\\\\\": \\\\\\"utf-8\\\\\\", \\\\\\"content-type\\\\\\": \\\\\\"application/json\\\\\\", \\\\\\"headers\\\\\\": {\\\\\\"lang\\\\\\": \\\\\\"py\\\\\\", \\\\\\"task\\\\\\": \\\\\\"app.celery_app.tasks.wait\\\\\\", \\\\\\"id\\\\\\": \\\\\\"1ddc3c5e-fa33-4d12-aa3f-c3d13581a4c8\\\\\\", \\\\\\"shadow\\\\\\": null, \\\\\\"eta\\\\\\": null, \\\\\\"expires\\\\\\": null, \\\\\\"group\\\\\\": null, \\\\\\"group_index\\\\\\": null, \\\\\\"retries\\\\\\": 0, \\\\\\"timelimit\\\\\\": [null, null], \\\\\\"root_id\\\\\\": \\\\\\"1ddc3c5e-fa33-4d12-aa3f-c3d13581a4c8\\\\\\", \\\\\\"parent_id\\\\\\": null, \\\\\\"argsrepr\\\\\\": \\\\\\"(60.0,)\\\\\\", \\\\\\"kwargsrepr\\\\\\": \\\\\\"{}\\\\\\", \\\\\\"origin\\\\\\": \\\\\\"gen11@a840cdd15b13\\\\\\", \\\\\\"ignore_result\\\\\\": false}, \\\\\\"properties\\\\\\": {\\\\\\"correlation_id\\\\\\": \\\\\\"1ddc3c5e-fa33-4d12-aa3f-c3d13581a4c8\\\\\\", \\\\\\"reply_to\\\\\\": \\\\\\"4b0f2f2d-aee2-3349-81ab-e95a1f0e9f02\\\\\\", \\\\\\"delivery_mode\\\\\\": 2, \\\\\\"delivery_info\\\\\\": {\\\\\\"exchange\\\\\\": \\\\\\"\\\\\\", \\\\\\"routing_key\\\\\\": \\\\\\"celery\\\\\\"}, \\\\\\"priority\\\\\\": 0, \\\\\\"body_encoding\\\\\\": \\\\\\"base64\\\\\\", \\\\\\"delivery_tag\\\\\\": \\\\\\"927d1ac0-3709-4e23-8c0f-037713c55217\\\\\\"}}, \\\\\\"\\\\\\", \\\\\\"celery\\\\\\"]\\"\\n```\\n\\n3. Wait for all these tasks to be done\\n\\n```sh\\n127.0.0.1:6379> KEYS *\\n 1) \\"_kombu.binding.email_service\\"\\n 2) \\"celery-task-meta-da959152-1f45-4846-99e4-5205d30c1be7\\"\\n 3) \\"celery-task-meta-815587f5-782d-454a-8498-b4ebbb91abd8\\"\\n 4) \\"_kombu.binding.celery.pidbox\\"\\n 5) \\"celery-task-meta-3d6b2028-6ee6-4e2c-85f1-cbeba644aca5\\"\\n 6) \\"_kombu.binding.celeryev\\"\\n 7) \\"_kombu.binding.celery\\"\\n 8) \\"_kombu.binding.ml_service\\"\\n 9) \\"celery-task-meta-1ddc3c5e-fa33-4d12-aa3f-c3d13581a4c8\\"\\n10) \\"celery-task-meta-e5a1b7db-f1ad-4d3e-b2b9-3b7de8f8c87e\\"\\n```\\n\\nAfter all tasks are done successfully, both keys: `celery` and `unacked` are removed from **Redis**.\\n\\nThe result of a task is stored in `celery-task-meta-{{uuid}}` key.\\n\\n```sh\\n127.0.0.1:6379> TYPE celery-task-meta-da959152-1f45-4846-99e4-5205d30c1be7\\nstring\\n127.0.0.1:6379> GET celery-task-meta-da959152-1f45-4846-99e4-5205d30c1be7\\n\\"{\\\\\\"status\\\\\\": \\\\\\"SUCCESS\\\\\\", \\\\\\"result\\\\\\": \\\\\\"wait() - Done, secs[60.0]s\\\\\\", \\\\\\"traceback\\\\\\": null, \\\\\\"children\\\\\\": [], \\\\\\"date_done\\\\\\": \\\\\\"2023-11-07T07:54:16.954872\\\\\\", \\\\\\"task_id\\\\\\": \\\\\\"da959152-1f45-4846-99e4-5205d30c1be7\\\\\\"}\\"\\n```\\n\\n## Serve machine learning model\\n\\nProperly running a machine learning model in task is different with running other jobs as we need avoiding loading ML model every time we run tasks. So it is stateful that we should keep something in worker.\\n\\n## Different workers for different tasks\\n\\nAssuming a such situation:\\nThere is a worker `x` to only handle email tasks and a worker `y` to only handle machine learning related tasks.\\n\\nThese are configurations for project `x`:\\n\\n```sh\\n#Celery routing.\\napp.conf.task_routes = {\\n    \'celery_app.email_tasks.*\': {\\n        \'queue\': \'email_service\',\\n    },\\n}\\n\\n#Run celery.\\ncelery -A celery_app.email_tasks:app worker -l info -E -Q email_service\\n```\\n\\nThese are configurations for project `y`:\\n\\n```sh\\n#Celery routing.\\napp.conf.task_routes = {\\n    \'celery_app.ml_tasks.*\': {\\n        \'queue\': \'ml_service\',\\n    },\\n}\\n\\n#Run celery.\\ncelery -A celery_app.ml_tasks:app worker -l info -E -Q ml_service\\n```\\n\\nDetails in explanation:\\n\\n1. Different workers handle their own queues for separate tasks.\\n\\nLook at [https://github.com/liviaerxin/fastapi-celery-ml](https://github.com/liviaerxin/fastapi-celery-ml) for see a complete **Celery** project.\\n\\n\\n## Code Analysis\\n\\n```py\\nfrom celery import signature\\nsig = add.s(2, 2)\\nsig.freeze()\\n```\\n\\n## Known issues\\n\\n[Result state is always PENDING in windows](https://github.com/celery/celery/issues/2146)\\n\\n> FIX: use `--pool=solo` instead of `--pool=prefork` in default. `multiprocessing` may cause this problem as its some defect in windows!\\n\\n[Long running jobs redelivering after broker visibility timeout with celery and redis \xb7 Issue #5935 \xb7 celery/celery \xb7 GitHub](https://github.com/celery/celery/issues/5935)\\n[Long tasks are executed multiple times \xb7 Issue #3430 \xb7 celery/celery \xb7 GitHub](https://github.com/celery/celery/issues/3430)\\n\\n[No Worker Heartbeat With Solo Pool \xb7 Issue #3768 \xb7 celery/celery \xb7 GitHub](https://github.com/celery/celery/issues/3768)\\n\\n## Resources\\n\\n[Celery - Distributed Task Queue \u2014 Celery 5.3.4 documentation](https://docs.celeryq.dev/en/latest/index.html#)\\n\\n[Celery Execution Pools: What is it all about?](https://celery.school/post/2023-10-20_execution-pools/)\\n\\n[Celery Execution Pool: The worker and the pool - separation of concerns](https://celery.school/posts/celery-pool-types-1-introduction/)\\n\\n[Serving ML Models in Production with FastAPI and Celery | by Jonathan Readshaw | Towards Data Science](https://towardsdatascience.com/deploying-ml-models-in-production-with-fastapi-and-celery-7063e539a5db)\\n\\n[GitHub - liviaerxin/FastAPISpamDetection: Code for my Medium article: \\"How you can quickly deploy your ML models with\xa0FastAPI\\"](https://github.com/liviaerxin/FastAPISpamDetection)\\n\\n[Celery ETA Tasks Demystified. At Instawork, we use Celery to queue\u2026 | by Oleg Pesok | Instawork Engineering](https://engineering.instawork.com/celery-eta-tasks-demystified-424b836e4e94)"},{"id":"/certificate-sign","metadata":{"permalink":"/blog/certificate-sign","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/certificate-sign.mdx","source":"@site/../../blog/certificate-sign.mdx","title":"Generate self-signed SSL/TLS certificate for local IP address or local domain","description":"Self Signed Certificate","date":"2023-10-04T00:00:00.000Z","formattedDate":"October 4, 2023","tags":[{"label":"openssl","permalink":"/blog/tags/openssl"},{"label":"certificate","permalink":"/blog/tags/certificate"},{"label":"best-practice","permalink":"/blog/tags/best-practice"}],"readingTime":3.745,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/self-signed-certificate.mdx"},"authors":["frank"],"tags":["openssl","certificate","best-practice"],"description":"Self Signed Certificate","keywords":["Self Signed Certificate"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-10-04T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Celery","permalink":"/blog/python-celery"},"nextItem":{"title":"QEMU Direct Linux Kernel Boot","permalink":"/blog/qemu-linux-kernel-boot"}},"content":"In real life, when we build our website and make it public, some paid or free CA(Certificate Authority) will help us sign a certificate for our website domain and enable SSL/TLS connections from user browser to our server.\\n\\nFor secure reasons, the browser will only admit those servers\'s certificates signed from authorized CA, of which certificate is kept in your host system trust store.\\n\\n:::note\\nOne of the most popular Certificate Authorities is [Let\'s Encrypt](https://letsencrypt.org/), which is a free and non-profit CA.\\n:::\\n\\nHere is an example, we will generate a local server certificate that is signed by a local CA. Finally, let Chrome can visit our local website without security warning.\\n\\nIn brief, these steps we need to sign local sever certificate actually simulate how those CA sign certificates for public servers, as following:\\n\\n1. Create a local **Root CA**.\\n2. Create a **CSR**(Certificate Signing Request) file for local server `127.0.0.1`.\\n3. The local **Root CA** use the **CSR** to generate a **certificate** for local server `127.0.0.1`.\\n4. Install the local **Root CA** into our system(Windows, Ubuntu or macOS) trust store.\\n5. Run a simple **https** server to test local server **certificate**.\\n\\nFor those official CA, they have to validate the domain is owned by the server before the `step 3`, and we can ignore `step 4` as they are already installed into the system or the browser trust store.\\n\\nAnd there is nice picture from [How to create your own self-signed root Certificate Authority(CA)](https://www.linkedin.com/pulse/how-create-your-own-self-signed-root-certificate-shankar-gomare/) to show the relationship between `CA`, `server` and `browser`.\\n\\n![](https://media.licdn.com/dms/image/C4E12AQGJ5hl3wTAyFg/article-inline_image-shrink_400_744/0/1589170084171?e=1701907200&v=beta&t=FaVSM-fIy4dc-SIftGYEuUc7GONcMLphssfteUKoWuA)\\n\\n\x3c!--truncate--\x3e\\n\\n\\n## Create root Certificate Authority(CA)\\n\\nGenerate `RootCA.key` and `RootCA.crt`:\\n\\n```sh\\nopenssl req -x509 -nodes -new -sha256 -days 1024 -newkey rsa:2048 -keyout RootCA.key -out RootCA.crt -subj \\"/C=US/CN=Example-Root-CA\\"\\n```\\n\\nYou can change `Example-Root-CA` to others or add more fields to CA.\\n\\n## Create local server certificate\\n\\nNext, we should apply the local CA to sign a certificate for our local server, which will be accessed through the `localhost` or `127.0.0.1` from our local machine.\\n\\n### Generate Certificate Signing Request(CSR)\\n\\nSet up custom DNS in `/etc/hosts`,\\n\\n```conf title=\\"/etc/hosts\\"\\n127.0.0.1   localhost\\n127.0.0.1   fake1.local\\n127.0.0.1   fake2.local\\n```\\n\\nPrepare a `localhost.conf`,\\n\\n```conf title=\\"localhost.conf\\"\\n[req]\\ndefault_bits  = 2048\\ndistinguished_name = req_distinguished_name\\nreq_extensions = req_ext\\nx509_extensions = v3_req\\nprompt = no\\n\\n[req_distinguished_name]\\ncountryName = XX\\nstateOrProvinceName = N/A\\nlocalityName = N/A\\norganizationName = Self-signed certificate\\ncommonName = 127.0.0.1: Self-signed certificate\\n\\n[req_ext]\\nsubjectAltName = @alt_names\\n\\n[v3_req]\\nsubjectAltName = @alt_names\\n\\n[alt_names]\\nIP.1 = 127.0.0.1\\nDNS.1 = localhost\\nDNS.2 = fake1.local\\nDNS.3 = fake2.local\\n```\\n\\nGenerates `localhost.key` and `localhost.csr`:\\n\\n```sh\\nopenssl req -new -nodes -newkey rsa:2048 -keyout localhost.key -out localhost.csr -config localhost.conf\\n# Or input from line\\n# openssl req -new -nodes -newkey rsa:2048 -keyout localhost.key -out localhost.csr -subj \\"/C=US/ST=YourState/L=YourCity/O=Example-Certificates/CN=localhost.local\\"\\n```\\n\\nVerify the Certificate Signing Request(CSR) `localhost.csr`:\\n\\n```sh\\nopenssl req -text -noout -verify -in localhost.csr\\n```\\n\\n### Get local server certificate signed by root CA\\n\\nSubmit **CSR** to the **root CA** to let the **root CA** to sign a certificate for our `locahost` server.\\n\\nGenerates `localhost.crt` by using CSR `localhost.csr` with extensions,\\n\\n```sh\\nopenssl x509 -req -sha256 -days 1024 -in localhost.csr -CA RootCA.crt -CAkey RootCA.key -CAcreateserial -extensions req_ext -extfile localhost.conf -out localhost.crt\\n```\\n\\nView the `localhost.crt`:\\n\\n```sh\\nopenssl x509 -text -noout -in localhost.crt\\n```\\n\\nVerify the `localhost.crt`:\\n\\n```sh\\nopenssl verify -verbose -CAfile RootCA.crt localhost.crt\\n```\\n\\n:::warning\\nIf `X509` extensions(`subjectAltName`) are missing from the certificate, the browser will still report security issues.\\n:::\\n\\n:::note\\nUsing the CA and Subject as the same one, the step of creating the local CA can be skipped.\\n\\n```sh\\nopenssl req -x509 -nodes -days 730 -newkey rsa:2048 -keyout localhost.key -out localhost.crt -config localhost.conf\\n```\\n\\n:::\\n\\n## Use the server certificate\\n\\nRun up a node https server to use the generated local server certificate.\\n\\n```sh\\nnpx http-server -p 8082 --ssl --cert localhost.crt --key localhost.key\\n```\\n\\nThen visit:\\n\\n- https://127.0.0.1:8082/\\n- https://localhost:8082/\\n\\nThe browser will give you security warning as the local **root CA** is not trusted in default.\\n\\n## Trust the root CA\\n\\nInstall CA certificate `RootCA.crt` into each system trust store or each browser.\\n\\n- Windows system trust store\\n- Ubuntu system trust store\\n- macOS system trust store\\n\\nThen visit again, the browser will show green!\\n\\n## Troubleshooting\\n\\n### Chrome **red** security warning\\n\\n1. Go to `Developer Tools`.\\n2. Click `Security` tab.\\n3. Check `Security overview` issues.\\n\\n## Resources\\n\\n[How to create an HTTPS certificate for localhost domains \xb7 GitHub](https://gist.github.com/cecilemuller/9492b848eb8fe46d462abeb26656c4f8)\\n\\n[How to add X.509 extensions to certificate OpenSSL | GoLinuxCloud](https://www.golinuxcloud.com/add-x509-extensions-to-certificate-openssl/)\\n\\n[GitHub - FiloSottile/mkcert: A simple zero-config tool to make locally trusted development certificates with any names you\'d like.](https://github.com/FiloSottile/mkcert)"},{"id":"/qemu-linux-kernel-boot","metadata":{"permalink":"/blog/qemu-linux-kernel-boot","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/qemu-linux-kernel-boot.mdx","source":"@site/../../blog/qemu-linux-kernel-boot.mdx","title":"QEMU Direct Linux Kernel Boot","description":"QEMU Linux Kernel Boot","date":"2023-09-26T00:00:00.000Z","formattedDate":"September 26, 2023","tags":[{"label":"qemu","permalink":"/blog/tags/qemu"},{"label":"kernel","permalink":"/blog/tags/kernel"},{"label":"initramfs","permalink":"/blog/tags/initramfs"}],"readingTime":2.735,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["qemu","kernel","initramfs"],"description":"QEMU Linux Kernel Boot","keywords":["QEMU Linux Kernel Boot"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-09-26T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Generate self-signed SSL/TLS certificate for local IP address or local domain","permalink":"/blog/certificate-sign"},"nextItem":{"title":"QEMU Emulate Raspberry Pi 3 and 4","permalink":"/blog/qemu-raspberry-pi"}},"content":"Here, I will employ QEMU to emulate a minimal **Linux x86_64** platform with a minimal root filesystem from scratch, as well as debugging with `GDB`:\\n\\n- Build **Linux x86_64** kernel\\n- Build **Linux x86_64** rootfs(root filesystem)\\n- Run QEMU\\n- Debug with `GDB`\\n\\nWhy do I use QEMU to boot Linux kernel directly with skipping BIOS/UEFI boot procedures?\\n\\nUse QEMU to launch a Linux kernel directly without having to make a fully bootable disk image. This is very useful for:\\n\\n- Linux kernel testing\\n- root filesystem testing\\n- arm system emulation\\n\\n\x3c!--truncate--\x3e\\n\\n## Prerequisites\\n\\nOn Ubuntu,\\n\\n```sh\\nsudo apt-get install git fakeroot build-essential ncurses-dev xz-utils libssl-dev bc flex libelf-dev bison\\n```\\n\\nOn macOS, you need create a **Case Sensitive** filesystem and use **GNU GCC** instead of `Clang` the following ways:\\n\\n```sh\\nhdiutil create -size 20g -type SPARSE -fs \\"Case-sensitive HFS+\\" -volname brosx brosx.sparseimage\\nhdiutil attach brosx.sparseimage\\n```\\n\\n```sh\\nhdiutil detach /Volumes/brosx -force\\n```\\n\\n```sh\\nbrew install gpatch gcc flock attr libtool libart\\n```\\n\\n```sh\\nln -s /opt/homebrew/bin/gcc-13 /opt/homebrew/bin/gcc\\nn -s /opt/homebrew/bin/gcc-13 /opt/homebrew/bin/cc\\nln -s /opt/homebrew/bin/g++-13 /opt/homebrew/bin/g++\\nln -s /opt/homebrew/bin/g++-13 /opt/homebrew/bin/c++\\n```\\n\\n```sh\\nrm /opt/homebrew/bin/gcc /opt/homebrew/bin/cc /opt/homebrew/bin/g++ /opt/homebrew/bin/c++\\n```\\n\\n## Build Linux kernel\\n\\n```sh\\nwget https://cdn.kernel.org/pub/linux/kernel/v6.x/linux-6.1.55.tar.xz\\n```\\n\\n\\n```sh\\ntar xvf linux-6.1.55.tar.xz\\ncd linux-6.1.55\\n```\\n\\n```sh\\n# Use the default `x86_64` configuration file form `/x86/configs/x86_64_defconfig`\\nmake ARCH=x86_64 x86_64_defconfig \\n```\\n\\n```sh\\n# Tweak some options for GDB and initramfs\\nmake menuconfig\\n```\\n\\n```sh\\nmake -j8\\n```\\n\\nGenerate kernel file `./arch/x86/boot/bzImage`.\\n\\n:::note\\nTo extract `vmlinux` from `bzImage`,\\n\\n```sh\\n./scripts/extract-vmlinux ./arch/x86_64/boot/bzImage >./arch/x86_64/boot/vmlinux\\n```\\n\\n:::\\n\\n## Build root filesystem\\n\\n```sh\\ngit clone https://github.com/buildroot/buildroot.git\\ncd buildroot\\n```\\n\\n```sh\\nmake menuconfig\\n```\\n\\nChoose `x86_64` as Target Architecture and `ext4` root file system.\\n\\n```sh\\nmake -j8\\n```\\n\\nGenerate root filesystem disk `./output/images/rootfs.ext4`.\\n\\n## Run QEMU\\n\\nCopy `bzImage` and `rootfs.ext4` to any host machine with QEMU available.\\n\\n```sh\\nrsync -l ./linux-6.1.55/arch/x86/boot/bzImage destination_directory/\\nrsync -l ./buildroot/output/images/rootfs.ext4 destination_directory/\\n```\\n\\n```sh\\nkernel=\\"$PWD/linux_qemu/x86_64/bzImage\\"\\nvmlinuz=\\"$PWD/linux_qemu/x86_64/vmlinux\\"\\ninitrd=\\"$PWD/linux_qemu/x86_64/rootfs.ext4\\"\\nimg=\\"$PWD/linux_qemu/x86_64/rootfs.ext4\\"\\n```\\n\\n```sh\\nqemu-system-x86_64 \\\\\\n    -nographic \\\\\\n    -m 4G \\\\\\n    -kernel $kernel \\\\\\n    -append \\"earlyprintk loglevel=8 root=/dev/zero console=ttyS0\\"\\n```\\n\\n```sh\\nqemu-system-x86_64 \\\\\\n    -nographic \\\\\\n    -m 4G \\\\\\n    -kernel $kernel \\\\\\n    -hda $img \\\\\\n    -append \\"earlyprintk loglevel=8 root=/dev/sda rootfstype=ext4 console=ttyS0\\" \\\\\\n    -netdev user,id=mynet,hostfwd=tcp::2222-:22 \\\\\\n    -device virtio-net-pci,netdev=mynet\\n```\\n\\nDefault password: `root`\\n\\n## Debug Linux kernel\\n\\n```sh\\nqemu-system-x86_64 \\\\\\n    -s -S \\\\\\n    -nographic \\\\\\n    -m 4G \\\\\\n    -kernel $kernel \\\\\\n    -append \\"earlyprintk loglevel=8 root=/dev/zero console=ttyS0 nokaslr\\"\\n```\\n\\nOptions in details,\\n\\n- `-s`: allows port `tcp::1234` for remote debug\\n- `-S`: stop CPU until continue from GDB what is connected to tcp `1234` port\\n- `-append`\\n  - `nokaslr`: turn off **KASLR**\\n\\nOr with root filesystem,\\n\\n```sh\\nqemu-system-x86_64 \\\\\\n    -nographic \\\\\\n    -m 4G \\\\\\n    -s -S \\\\\\n    -kernel $kernel \\\\\\n    -hda $img \\\\\\n    -append \\"earlyprintk loglevel=8 root=/dev/sda rootfstype=ext4 console=ttyS0 nokaslr\\" \\\\\\n    -netdev user,id=mynet,hostfwd=tcp::2222-:22 \\\\\\n    -device virtio-net-pci,netdev=mynet\\n```\\n\\nEnter `gdb`,\\n\\n```sh\\n$ gdb ./vmlinux\\n```\\n\\nIn `gdb` shell,\\n\\n```sh\\n(gdb) target remote 10.6.64.243:1234\\nRemote debugging using 10.6.64.243:1234\\nwarning: No executable has been specified and target does not support\\ndetermining executable automatically.  Try using the \\"file\\" command.\\n0x000000000000fff0 in ?? ()\\n(gdb) continue\\nContinuing.\\n```\\n\\n## Resources\\n\\n[Daniel P. Berrang\xe9  \xbb Blog Archive   \xbb make-tiny-image.py: creating tiny initrds for testing QEMU or Linux kernel/userspace behaviour](https://www.berrange.com/posts/2023/03/09/make-tiny-image-py-creating-tiny-initrds-for-testing-qemu-or-linux-kernel-userspace-behaviour/)\\n\\n[GitHub - dhruvvyas90/qemu-rpi-kernel: Qemu kernel for emulating Rpi on QEMU](https://github.com/dhruvvyas90/qemu-rpi-kernel)\\nhttps://medicineyeh.wordpress.com/2016/03/29/buildup-your-arm-image-for-qemu/\\n\\n[Prepare the environment for developing Linux kernel with qemu. | by DaeSeok Youn | Medium](https://medium.com/@daeseok.youn/prepare-the-environment-for-developing-linux-kernel-with-qemu-c55e37ba8ade)\\n\\n[](https://bootlin.com/pub/conferences/2013/kernel-recipes/rootfs-kernel-developer/rootfs-kernel-developer.pdf)"},{"id":"/qemu-raspberry-pi","metadata":{"permalink":"/blog/qemu-raspberry-pi","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/qemu-raspberry-pi.mdx","source":"@site/../../blog/qemu-raspberry-pi.mdx","title":"QEMU Emulate Raspberry Pi 3 and 4","description":"QEMU emulate Raspberry Pi 3/4","date":"2023-09-23T00:00:00.000Z","formattedDate":"September 23, 2023","tags":[{"label":"qemu","permalink":"/blog/tags/qemu"},{"label":"raspberry-pi","permalink":"/blog/tags/raspberry-pi"},{"label":"osx","permalink":"/blog/tags/osx"}],"readingTime":8.345,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["qemu","raspberry-pi","osx"],"description":"QEMU emulate Raspberry Pi 3/4","keywords":["QEMU Raspberry Pi 3/4"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-09-23T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"QEMU Direct Linux Kernel Boot","permalink":"/blog/qemu-linux-kernel-boot"},"nextItem":{"title":"How to mount ISO image file","permalink":"/blog/how-to-mount-iso-file"}},"content":"In this blog, **QEMU** is employed to emulate **Raspberry Pi 3/4** in **mac M1** host(it\'s also supposed to work in **Windows/Linux** with a little tweak). I will demonstrate **two** different ways to emulate **Raspberry Pi 3** and **Raspberry Pi 4** in respect. These two ways are different by using different **QEMU machines** as you would like to use:\\n\\n1. `-machine raspi3b`: raspberry pi 3b machine to emulate **Raspberry Pi 3**.\\n2. `-machine virt`: general arm machine to emulate **Raspberry Pi 4**.\\n\\n:::note\\nIn mac M1 with setting `-machine virt`, I use the hardware acceleration by `-accel hvf`. In Windows(x86_64), the hardware acceleration for `aarch64` is not available, so removing the hardware acceleration will work as well in Windows.\\n:::\\n\\nFor both of these two, we still need prepare some common steps before running **QEMU**:\\n\\n- Extract the appropriate kernel, device tree or root filesystem\\n\\n\x3c!--truncate--\x3e\\n\\nThis blog will emulate Raspberry Pi using QEMU in mac M1 host using the new image `2023-05-03-raspios-bullseye-arm64-lite.img`.\\n\\nThe default `user:pi` and `password:raspberry` have been removed from this image. In order to log in, we have to write `user` and `password` to the image before booting. These steps can be skipped when booting previous images.\\n\\n## Prerequisites\\n\\n- **Docker**\\n  - be required in macOS\\n  - can be skipped in Linux\\n  - can use `wsl` as an alternative in Windows\\n- **QEMU**\\n  - `homebrew` install in macOS\\n- **Raspberry Pi image**: `2023-05-03-raspios-bullseye-arm64-lite.img`\\n\\nSince I am in mac M1, and the `raspberry pi` image which contains a `fat` filesystem as boot and a `ext4` filesystem as OS, we need write some configuration into it. So I will use a **Docker Ubuntu** container to do the operation on the the filesystem. There some other tools to do the like of these operations:\\n\\n- `ext4fuse` is free and easy to install via `homebrew`, but it has limit as read-only access.\\n- `ExtFS` from `Paragon` supports read-write access while you need pay for it.\\n- `virtual machine`\\n  - `Docker` in OSX make use of `virtual machine` while it is quick and flexible to use.\\n\\n## Raspberry Pi image\\n\\n```sh\\ncd ~\\nwget https://downloads.raspberrypi.org/raspios_arm64/images/raspios_arm64-2023-05-03/2023-05-03-raspios-bullseye-arm64-lite.img.xz\\nxz -d 2023-05-03-raspios-bullseye-arm64-lite.img.xz\\n```\\n\\n## Docker Ubuntu container\\n\\nMount the **folder** including `2023-05-03-raspios-bullseye-arm64-lite.img`\\n\\n```sh\\ndocker run -it -d --privileged -v $PWD:/qemu --name ubuntu ubuntu\\ndocekr exec -it ubuntu bash\\n```\\n\\n## Extracting Kernel and device tree\\n\\nOperations all in Ubuntu container.\\n\\n```sh\\nroot@f36a3251391d:/qemu# fdisk -l 2023-05-03-raspios-bullseye-arm64-lite.img \\nDisk 2023-05-03-raspios-bullseye-arm64-lite.img: 1.96 GiB, 2101346304 bytes, 4104192 sectors\\nUnits: sectors of 1 * 512 = 512 bytes\\nSector size (logical/physical): 512 bytes / 512 bytes\\nI/O size (minimum/optimal): 512 bytes / 512 bytes\\nDisklabel type: dos\\nDisk identifier: 0x544c6228\\n\\nDevice                                      Boot  Start     End Sectors  Size Id Type\\n2023-05-03-raspios-bullseye-arm64-lite.img1        8192  532479  524288  256M  c W95 FAT32 (LBA)\\n2023-05-03-raspios-bullseye-arm64-lite.img2      532480 4104191 3571712  1.7G 83 Linux\\n```\\n\\n- The first partition is boot filesystem.\\n- The second partition is real root filesystem.\\n\\nAll the data we need is in the first partition, to do the operation is mounting it.\\n\\nThe offset of the first partition: 8192 * 512 = 4194304,\\n\\n```sh\\nroot@f36a3251391d:/qemu# mount -o loop,offset=4194304 2023-05-03-raspios-bullseye-arm64-lite.img /mnt/rpi-boot/\\n```\\n\\n\\n```sh\\nroot@f36a3251391d:/qemu# ls -ls /mnt/rpi-boot/\\ntotal 30244\\n  20 -rwxr-xr-x 1 root root   18693 Apr  5 11:32 COPYING.linux\\n   2 -rwxr-xr-x 1 root root    1594 Apr  5 11:32 LICENCE.broadcom\\n  30 -rwxr-xr-x 1 root root   30390 Apr  5 11:32 bcm2710-rpi-2-b.dtb\\n  32 -rwxr-xr-x 1 root root   32753 Apr  5 11:32 bcm2710-rpi-3-b-plus.dtb\\n  32 -rwxr-xr-x 1 root root   32142 Apr  5 11:32 bcm2710-rpi-3-b.dtb\\n  30 -rwxr-xr-x 1 root root   30285 Apr  5 11:32 bcm2710-rpi-cm3.dtb\\n  32 -rwxr-xr-x 1 root root   31318 Apr  5 11:32 bcm2710-rpi-zero-2-w.dtb\\n  32 -rwxr-xr-x 1 root root   31318 Apr  5 11:32 bcm2710-rpi-zero-2.dtb\\n  52 -rwxr-xr-x 1 root root   52593 Apr  5 11:32 bcm2711-rpi-4-b.dtb\\n  52 -rwxr-xr-x 1 root root   52682 Apr  5 11:32 bcm2711-rpi-400.dtb\\n  38 -rwxr-xr-x 1 root root   38182 Apr  5 11:32 bcm2711-rpi-cm4-io.dtb\\n  52 -rwxr-xr-x 1 root root   53202 Apr  5 11:32 bcm2711-rpi-cm4.dtb\\n  50 -rwxr-xr-x 1 root root   50504 Apr  5 11:32 bcm2711-rpi-cm4s.dtb\\n  52 -rwxr-xr-x 1 root root   52476 Apr  5 11:32 bootcode.bin\\n   2 -rwxr-xr-x 1 root root     154 May  3 03:11 cmdline.txt\\n   4 -rwxr-xr-x 1 root root    2109 May  3 02:53 config.txt\\n  ...\\n   2 -rwxr-xr-x 1 root root     145 May  3 03:11 issue.txt\\n8028 -rwxr-xr-x 1 root root 8219600 Apr  5 11:32 kernel8.img\\n  ...\\n```\\n\\n\\nTo run QEMU we will need the **kernel** and **device tree**, so let\u2019s copy them out:\\n\\n```sh\\nroot@f36a3251391d:/qemu# cp /mnt/rpi-boot/kernel8.img .\\nroot@f36a3251391d:/qemu# cp /mnt/rpi-boot/bcm2710-rpi-3-b.dtb .\\n```\\n\\n## Setting up default user\\n\\nOperations all in docker container.\\n\\nNow in order to set up user and enable ssh in default, we need write files into `/userconf` and `/ssh` under the boot filesystem mounted as `/mnt/rpi-boot/`.\\n\\nSet up a default `user:pi` and `password:raspberry`.\\n\\nHash password `raspberry` using `openssl`,\\n\\n```sh\\nroot@f36a3251391d:/qemu# openssl passwd\\nPassword: \\nVerifying - Password: \\n$1$d...AvcL$wqfUqTIauUP1TVJ/uU1td0\\n```\\n\\n```sh\\nroot@f36a3251391d:/qemu# echo \'pi:$1$d...AvcL$wqfUqTIauUP1TVJ/uU1td0\' | tee /mnt/rpi-boot/userconf\\n```\\n\\nEnable `ssh`,\\n\\n```sh\\nroot@f36a3251391d:/qemu# touch /mnt/rpi-boot/ssh\\n```\\n\\n```sh\\nroot@f36a3251391d:/qemu# umount /mnt/rpi-boot\\n```\\n\\n## Running QEMU\\n\\n### Emulate Raspberry Pi 3\\n\\nNow switch back to the host macOS to run `QEMU`,\\n\\nResize the image to the next power of 2 size,\\n\\nThe original size,\\n\\n```sh\\n\u276f stat -f%z 2023-05-03-raspios-bullseye-arm64-lite.img\\n2101346304\\n```\\n\\nTo resize to `4GB`,\\n\\n```sh\\nqemu-img resize ./2023-05-03-raspios-bullseye-arm64-lite.img 4G\\n```\\n\\n```sh\\nqemu-system-aarch64 \\\\\\n    -machine raspi3b \\\\\\n    -cpu cortex-a72 \\\\\\n    -nographic \\\\\\n    -m 1G \\\\\\n    -smp 4 \\\\\\n    -dtb bcm2710-rpi-3-b.dtb \\\\\\n    -kernel kernel8.img \\\\\\n    -append \\"rw earlyprintk loglevel=8 console=ttyAMA0,115200 dwc_otg.lpm_enable=0 root=/dev/mmcblk0p2 rootdelay=1\\" \\\\\\n    -netdev user,id=net0,hostfwd=tcp::2222-:22 \\\\\\n    -device usb-net,netdev=net0 \\\\\\n    -sd 2023-05-03-raspios-bullseye-arm64-lite.img\\n```\\n\\nOptions in detail:\\n\\n- `-machine raspi3b`: use raspberry pi 3 machine.\\n- `-append`:\\n  - `console=ttyAMA0`: output the **VM** std to **QEMU** console.\\n  - `root=/dev/mmcblk0p2`: mount **real root filesystem** to `/dev/mmcblk0p2`(the second partition of `mmcblk0`) as we `-sd xx` will be mounted to `/dev/mmcblk0`.\\n- `-netdev user,id=net0,hostfwd=tcp::2222-:22`: network mapping host port `2222` to the **VM** `22`\\n- `-device usb-net,netdev=net0`: expose `netdev=net0` as `usb-net` in the raspberry pi 3 machine.\\n- `-sd 2023-05-03-raspios-bullseye-arm64-lite.img`: `sd` drive is available in the raspberry pi 3 machine.\\n\\n### Emulate Raspberry Pi 4 with `virt`\\n\\nWe will use generic virtual machine `virt` to act as `raspi4`, since there is no `raspi4` machine defined in QEMU official machines. However you can still use `raspi3` to act as `raspi4` as they are same!\\n\\n**Hardware Acceleration** can be enable in `virt` machine by using `-accel hvf` option in my **mac M1** host as it\'s **arm-based**.\\n\\nSo `virt` will bring high performance and increase efficiency!\\n\\nAfter tuning options and searching from many resources, the operational setting for QEMU to emulate is,\\n\\n1. Use `ubuntu-22.04.3-preinstalled-server-arm64+raspi.img`, of which the default user is `ubuntu` and password is `ubuntu`.\\n\\n```sh\\nkernel=\\"$PWD/ubuntu-22.04.3-preinstalled-server-arm64+raspi-boot/vmlinuz\\"\\ninitrd=\\"$PWD/ubuntu-22.04.3-preinstalled-server-arm64+raspi-boot/initrd.img\\"\\nimg=\\"$PWD/ubuntu-22.04.3-preinstalled-server-arm64+raspi.img\\"\\n```\\n\\n\\n#### For `SCSI hard disk`\\n\\nThis storage device file will be named `/dev/sdX`,\\n\\n```sh\\nqemu-system-aarch64 \\\\\\n    -machine virt \\\\\\n    -accel hvf \\\\\\n    -cpu host \\\\\\n    -smp 4 \\\\\\n    -m 4G \\\\\\n    -nographic \\\\\\n    -kernel $kernel \\\\\\n    -initrd $initrd \\\\\\n    -append \\"earlyprintk loglevel=8 root=/dev/sda2 rootfstype=ext4 rw console=ttyAMA0\\" \\\\\\n    -drive file=$img,format=raw,if=none,id=drive0 \\\\\\n    -device virtio-scsi-pci,id=scsi \\\\\\n    -device scsi-hd,drive=drive0,bus=scsi.0 \\\\\\n    -netdev user,id=mynet,hostfwd=tcp::2222-:22 \\\\\\n    -device virtio-net-pci,netdev=mynet\\n```\\n\\nOptions in detail:\\n\\n- `-accel hvf`: **hardware acceleration** in mac M1. Don\'t use in **x86_64** host.\\n- `-cpu host`: change to `-cpu cortex-a72` when no **hardware acceleration** available such as in **x86_64** host.\\n- `-append`\\n  - `root=/dev/sda2`: the second partition of the `ubuntu-22.04.3-preinstalled-server-arm64+raspi.img` disk image hold the real root filesystem.\\n- `-initrd $initrd`\\n  - the boot loader works using configuration like `vmlinuz initrd=initrd.img root=/dev/sda2`.\\n\\n#### For `virtual disk` storage device\\n\\nThis storage device file will be named `/dev/vdX`,\\n\\n```sh\\nqemu-system-aarch64 \\\\\\n    -machine virt \\\\\\n    -accel hvf \\\\\\n    -cpu host \\\\\\n    -smp 4 \\\\\\n    -m 4G \\\\\\n    -nographic \\\\\\n    -kernel $kernel \\\\\\n    -initrd $initrd \\\\\\n    -append \\"earlyprintk loglevel=8 root=/dev/vda2 rootfstype=ext4 rw console=ttyAMA0\\" \\\\\\n    -drive file=$img,format=raw,if=none,id=drive0 \\\\\\n    -device virtio-blk-pci,drive=drive0 \\\\\\n    -netdev user,id=mynet,hostfwd=tcp::2222-:22 \\\\\\n    -device virtio-net-pci,netdev=mynet\\n```\\n\\n#### For `NVMe` storage device\\n\\nThis storage device file will be named `/dev/nvmeX`,\\n\\n```sh\\nqemu-system-aarch64 \\\\\\n    -machine virt \\\\\\n    -accel hvf \\\\\\n    -cpu host \\\\\\n    -smp 4 \\\\\\n    -m 4G \\\\\\n    -nographic \\\\\\n    -kernel $kernel \\\\\\n    -append \\"earlyprintk loglevel=8 root=/dev/nvme0n1p2 rootfstype=ext4 rw console=ttyAMA0\\" \\\\\\n    -drive file=$img,format=raw,if=none,id=drive0 \\\\\\n    -device nvme,drive=drive0,serial=deadbeaf1 \\\\\\n    -netdev user,id=mynet,hostfwd=tcp::2222-:22 \\\\\\n    -device virtio-net-pci,netdev=mynet\\n```\\n\\nOptions in detail:\\n\\n- no `-initrd $initrd`\\n  - the boot loader works using configuration like `vmlinuz root=/dev/nvme0n1p2`.\\n  - we directly mount the real filesystem `/dev/nvme0n1p2`, skipping to mount the **initial RAM disk**.\\n  - I test other type storage device must binding `-initrd $initrd` while there is no need for `NVME`. In my assumption, those `storage devices` need to be configured in the `initramfs`.\\n\\n#### For `usb storage`\\n\\nThis storage device file will be named `/dev/sdX`,\\n\\n```sh\\nqemu-system-aarch64 \\\\\\n    -machine virt \\\\\\n    -cpu cortex-a57 \\\\\\n    -smp 4 \\\\\\n    -m 4G \\\\\\n    -no-reboot \\\\\\n    -nographic \\\\\\n    -kernel $kernel \\\\\\n    -initrd $initrd \\\\\\n    -append \\"earlyprintk loglevel=8 root=/dev/sda2 rootfstype=ext4 console=ttyAMA0 raid=noautodetect\\" \\\\\\n    -device usb-ehci \\\\\\n    -device usb-storage,drive=disk0 \\\\\\n    -drive file=$img,format=raw,if=none,id=disk0 \\\\\\n    -device virtio-net-pci,netdev=mynet \\\\\\n    -netdev user,id=mynet,hostfwd=tcp::2222-:22\\n```\\n\\nOptions in detail:\\n\\n- `-device usb-ehci`: usb bus -> PCI bus\\n- `-device usb-storage`: usb storage device -> usb bus\\n\\n## Test Raspberry Pi VM\\n\\nLog into the **Raspberry Pi** via `ssh` from the macOS host,\\n\\n```sh\\n\u276f ssh -p 2222 pi@localhost\\nThe authenticity of host \'[localhost]:2222 ([127.0.0.1]:2222)\' can\'t be established.\\nED25519 key fingerprint is SHA256:6igL6iaigBCszv8m6nyNl+tsB2siV/tL+TRQANC6nBw.\\nThis key is not known by any other names\\nAre you sure you want to continue connecting (yes/no/[fingerprint])? yes\\nWarning: Permanently added \'[localhost]:2222\' (ED25519) to the list of known hosts.\\npi@localhost\'s password: \\nLinux raspberrypi 6.1.21-v8+ #1642 SMP PREEMPT Mon Apr  3 17:24:16 BST 2023 aarch64\\n\\nThe programs included with the Debian GNU/Linux system are free software;\\nthe exact distribution terms for each program are described in the\\nindividual files in /usr/share/doc/*/copyright.\\n\\nDebian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent\\npermitted by applicable law.\\nLast login: Fri Sep 22 16:30:58 2023\\n\\nSSH is enabled and the default password for the \'pi\' user has not been changed.\\nThis is a security risk - please login as the \'pi\' user and type \'passwd\' to set a new password.\\n\\npi@raspberrypi:~ $ \\n```\\n\\n## Resources\\n\\n[Emulating a Raspberry Pi in QEMU | InterruptEmulating a Raspberry Pi in QEMU](https://interrupt.memfault.com/blog/emulating-raspberry-pi-in-qemu)\\n\\n[How to emulate block devices with QEMU](https://blogs.oracle.com/linux/post/how-to-emulate-block-devices-with-qemu)\\n\\n[Emulation of block devices \u2014 Das U-Boot unknown version documentation](https://u-boot.readthedocs.io/en/latest/board/emulation/blkdev.html)"},{"id":"/how-to-mount-iso-file","metadata":{"permalink":"/blog/how-to-mount-iso-file","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/how-to-mount-iso-file.mdx","source":"@site/../../blog/how-to-mount-iso-file.mdx","title":"How to mount ISO image file","description":"How to mount ISO file","date":"2023-09-21T00:00:00.000Z","formattedDate":"September 21, 2023","tags":[{"label":"how-to","permalink":"/blog/tags/how-to"},{"label":"iso","permalink":"/blog/tags/iso"},{"label":"osx","permalink":"/blog/tags/osx"},{"label":"linux","permalink":"/blog/tags/linux"}],"readingTime":1.61,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/how-to-mount-iso-file.mdx"},"authors":["frank"],"tags":["how-to","iso","osx","linux"],"description":"How to mount ISO file","keywords":["How to mount ISO file"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-09-21T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"QEMU Emulate Raspberry Pi 3 and 4","permalink":"/blog/qemu-raspberry-pi"},"nextItem":{"title":"Wiki Emulator","permalink":"/blog/wiki-emulator"}},"content":"For viewing the content of the **ISO** image file like `*.iso`, we can mount it to filesystem and loop up its contained files.\\n\\nMounting the **ISO** image file in linux is much easier than doing in macOS. Because **ISO** use `ISO9660` file system while the `hdiutil` in macOS does not support it originally. That will require more steps to implement in comparison with one command like `mount ` in Linux.\\n\\n[How to mount iso image in Linux](https://www.cyberciti.biz/tips/how-to-mount-iso-image-under-linux.html)\\n\\n[osx - Can a Mac mount a Debian install CD? - Unix & Linux Stack Exchange](https://unix.stackexchange.com/questions/298685/can-a-mac-mount-a-debian-install-cd)\\n\\n\x3c!--truncate--\x3e\\n\\n## Mount ISO file on Linux\\n\\n\\n## Mount ISO file on macOS\\n\\n1. Attaching as a block device\\n\\n```sh\\n# the \'-nomount\' option avoids the \'mount failed\' error\\n\u276f hdiutil attach -nomount mantic-mini-iso-amd64.iso\\n/dev/disk6          \\tGUID_partition_scheme          \\t\\n/dev/disk6s1        \\tMicrosoft Basic Data           \\t\\n/dev/disk6s2        \\tEFI                            \\t\\n/dev/disk6s3        \\tMicrosoft Basic Data  \\n```\\n\\n```sh\\n\u276f diskutil info /dev/disk6s2\\n   Device Identifier:         disk6s2\\n   Device Node:               /dev/disk6s2\\n   Whole:                     No\\n   Part of Whole:             disk6\\n\\n   Volume Name:               ESP\\n   Mounted:                   No\\n\\n   Partition Type:            EFI\\n   File System Personality:   MS-DOS FAT12\\n   Type (Bundle):             msdos\\n   Name (User Visible):       MS-DOS (FAT12)\\n```\\n\\n2. [Optional] Load CD9660\\n\\n```sh\\n# Load the kext module\\n\u276f sudo kmutil load -p /System/Library/Extensions/cd9660.kext\\n```\\n\\n3. Mount the disk with cd9660 (aka ISO9660) file system\\n\\n```sh\\n# create mount point\\n\u276f mkdir -p /tmp/ubuntu-mantic-iso\\n\\n# mount the disk\\n\u276f mount -t cd9660 /dev/disk6 /tmp/ubuntu-mantic-iso\\n```\\n\\nView the `iso` files,\\n\\n```sh\\n\u276f tree -h -L 3 /tmp/ubuntu-mantic-iso\\n[2.0K]  /tmp/ubuntu-mantic-iso\\n\u251c\u2500\u2500 [2.0K]  EFI\\n\u2502\xa0\xa0 \u2514\u2500\u2500 [2.0K]  boot\\n\u2502\xa0\xa0     \u251c\u2500\u2500 [938K]  bootx64.efi\\n\u2502\xa0\xa0     \u251c\u2500\u2500 [2.2M]  grubx64.efi\\n\u2502\xa0\xa0     \u2514\u2500\u2500 [841K]  mmx64.efi\\n\u251c\u2500\u2500 [2.0K]  boot\\n\u2502\xa0\xa0 \u2514\u2500\u2500 [2.0K]  grub\\n\u2502\xa0\xa0     \u251c\u2500\u2500 [2.0K]  fonts\\n\u2502\xa0\xa0     \u251c\u2500\u2500 [ 169]  grub.cfg\\n\u2502\xa0\xa0     \u251c\u2500\u2500 [ 38K]  i386-pc\\n\u2502\xa0\xa0     \u2514\u2500\u2500 [ 36K]  x86_64-efi\\n\u251c\u2500\u2500 [2.0K]  boot.catalog\\n\u2514\u2500\u2500 [2.0K]  casper\\n    \u251c\u2500\u2500 [ 56M]  initrd\\n    \u2514\u2500\u2500 [ 13M]  vmlinuz\\n\\n9 directories, 7 files\\n```\\n\\n4. Umount the disk\\n\\n```sh\\n\u276f umount /dev/disk6\\n```\\n\\n5. Detach the disk\\n\\n```sh\\n\u276f hdiutil detach /dev/disk6\\n```"},{"id":"/wiki-emulator","metadata":{"permalink":"/blog/wiki-emulator","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-emulator.mdx","source":"@site/../../blog/wiki-emulator.mdx","title":"Wiki Emulator","description":"Wiki Emulator","date":"2023-09-20T00:00:00.000Z","formattedDate":"September 20, 2023","tags":[{"label":"wiki","permalink":"/blog/tags/wiki"},{"label":"emulator","permalink":"/blog/tags/emulator"}],"readingTime":0.47,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/wiki-emulator.mdx"},"authors":["frank"],"tags":["wiki","emulator"],"description":"Wiki Emulator","keywords":["Wiki Emulator"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-09-20T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"How to mount ISO image file","permalink":"/blog/how-to-mount-iso-file"},"nextItem":{"title":"Wiki QEMU","permalink":"/blog/wiki-qemu"}},"content":"[Configure hardware acceleration for the Android Emulator](https://developer.android.com/studio/run/emulator-acceleration)\\n\\nHardware acceleration:\\n\\n- Graphics acceleration: Improve screen rendering, especially in games\\n- VM acceleration(a.k.a, CPU acceleration): Improve execution speed\\n\\nGraphics acceleration can be enabled with `-gpu` option.\\nWindows: It may need you add the `emulator.exe` to the `Graphics settings`, such as `\\"C:\\\\Users\\\\xx\\\\AppData\\\\Local\\\\Android\\\\Sdk\\\\emulator\\\\emulator.exe\\"`\\n\\nVM acceleration is enabled in default.\\nFor instance, if `WHPX` is configured in windows, it will be used automatically. \\n\\n```sh\\nemulator.exe -avd Pixel_3a_API_34_extension_level_7_x86_64 -gpu host -no-snapshot\\n```\\n\\n\x3c!--truncate--\x3e\\n\\n\\n[QEMU ELI5 \u2014 Part 6, UEFI, BIOS & OVMF | by Tuna Cici | Medium](https://medium.com/@tunacici7/qemu-eli5-part-6-uefi-bios-ovmf-7919facf7e31)\\n\\n## Background"},{"id":"/wiki-qemu","metadata":{"permalink":"/blog/wiki-qemu","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-qemu.mdx","source":"@site/../../blog/wiki-qemu.mdx","title":"Wiki QEMU","description":"Wiki QEMU","date":"2023-09-19T00:00:00.000Z","formattedDate":"September 19, 2023","tags":[{"label":"wiki","permalink":"/blog/tags/wiki"},{"label":"qemu","permalink":"/blog/tags/qemu"}],"readingTime":3.67,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["wiki","qemu"],"description":"Wiki QEMU","keywords":["Wiki QEMU"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-09-19T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Wiki Emulator","permalink":"/blog/wiki-emulator"},"nextItem":{"title":"Wiki Coral","permalink":"/blog/wiki-coral"}},"content":"Learning and using the QEMU help me understand how the linux operating system works including fields:\\n\\n1. Linux boot process.\\n2. Cross compile for target system(such as arm64) on host system(such as x86_64), and test the binary.\\n\\n\x3c!--truncate--\x3e\\n\\n## OS image Resources\\n\\n- [Ubuntu OS Images](https://cdimage.ubuntu.com/)\\n- [Debian OS Images](https://cdimage.debian.org/)\\n- [Raspberry PI OS Images](https://downloads.raspberrypi.org/)\\n\\n### QEMU Keyboard shortcuts\\n\\n- Switch between QEMU monitor console and the guest non-graphic OS\\n  - `CTRL+a c`\\n- Exit the guest non-graphic OS\\n  - `CTRL+a x`\\n- Switch between QEMU monitor console and the guest graphic OS\\n  - `CTRL+ALT+1`, `CTRL+ALT+2`\\n\\n### Discover the VM device tree\\n\\nEnter the QEMU monitor console, using `info qtree` command,\\n\\n```sh\\n$ info qtree\\n\\n dev: gpex-pcihost, id \\"\\"\\n    ...\\n    bus: pcie.0\\n      type PCIE\\n      dev: virtio-scsi-pci, id \\"\\"\\n        ...\\n        bus: virtio-bus\\n          type virtio-pci-bus\\n          dev: virtio-scsi-device, id \\"\\"\\n            ...\\n            bus: scsi.0\\n              type SCSI\\n              dev: scsi-hd, id \\"\\"\\n                drive = \\"hd\\"\\n                ...\\n      dev: nvme, id \\"\\"\\n        drive = \\"drive0\\"\\n        ...\\n        bus: nvme-bus.0\\n          type nvme-bus\\n      dev: virtio-net-pci, id \\"\\"\\n        ...\\n        bus: virtio-bus\\n          type virtio-pci-bus\\n          dev: virtio-net-device, id \\"\\"\\n            ...\\n\\n```\\n\\n### List supported devices\\n\\n```sh\\n$ qemu-system-aarch64 -device help\\n$ qemu-system-aarch64 -device scsi-hd,help\\n```\\n\\n## Create disk image\\n\\n```sh\\nqemu-img create -f raw ubuntu.raw 20G\\nqemu-img create -f qcow2 ubuntu.qcow2 20G\\n```\\n\\nQEMU can boot from 3 ways:\\n\\n- BIOS in default\\n- Linux kernel and initrad\\n- UEFI\\n\\nFor **UEFI** boot, the `-bios` option should be used alongside `UEFI` firmware(`OVMF.fd` file) being provided to help QEMU do `UEFI` boot. For instance it is like: `-bios OVMF.fd`.\\n\\nGet a prebuilt `OVMF` file from the [OVMF](https://www.kraxel.org/repos/jenkins/edk2/).\\n\\n## BIOS boot\\n\\nTest entering BIOS,\\n\\n```sh\\nqemu-system-x86_64 -monitor stdio -m 1G\\n```\\n\\nThen QEMU will show like this,\\n\\n![](../attachments/images/bios.png)\\n\\n\\n## Kernel boot\\n\\n## UEFI boot\\n\\n### Test UEFI boot\\n\\naarch64,\\n\\n```sh\\nefi=\\"$PWD/UEFI/aarch64/QEMU_EFI.fd\\"\\n\\nqemu-system-aarch64 -monitor stdio -M virt -cpu cortex-a57 -m 1G -net none -bios $efi\\n\\nqemu-system-aarch64 -nographic -M virt -cpu cortex-a57 -m 1G -net none -bios $efi\\n```\\n\\nx86_64,\\n\\n```sh\\nefi=\\"$PWD/UEFI/ovmf-x64/OVMF-pure-efi.fd\\"\\n\\nqemu-system-x86_64 -monitor stdio -m 1G -net none -bios $efi\\n```\\n\\nThen QEMU will drop into the **UEFI** shell, like this following image show,\\n\\n![efi](../attachments/images/efi.png)\\n\\nOptions in detail:\\n\\n- `-nographic`: Don\'t create a video for the VM, just use the terminal.\\n:::info\\nquit QEMU: `Ctrl+A X`.  \\nenter QEMU monitor console: `Ctrl+A C`.  \\nsee at [How to quit the QEMU monitor when not using a GUI?](https://superuser.com/questions/1087859/how-to-quit-the-qemu-monitor-when-not-using-a-gui)\\n:::\\n\\n- `-monitor stdio`: Put QEMU monitor console in the terminal, while guest OS kept in created video device.\\n:::info\\nswitch between monitor console and guest OS: `Ctrl+Alt+1` or `Ctrl+Alt+2`.\\n:::\\n\\n- `-net none`: Disable iPXE.\\n\\n### Boot x86_64 ISO image\\n\\nBoot x86_64 image in Windows,\\n\\n```sh\\nefi=\\"$PWD/UEFI/ovmf-x64/OVMF-pure-efi.fd\\"\\niso=ubuntu-22.04-live-server-amd64.iso\\n```\\n\\n:::note\\n`ubuntu-**-amd64.iso` support both **UEFI** and Legacy **BIOS** boot, QEMU use **BIOS** when the option `-bios` is not specified!\\n:::\\n\\n1. Create a disk image to install the ubuntu OS,\\n\\n```sh\\nqemu-img create -f qcow2 ubuntu-image.qcow2 20G\\n```\\n\\n2. Boot to run the Ubuntu OS\\n\\n```sh\\nqemu-system-x86_64 \\\\\\n    -monitor stdio \\\\\\n    -accel whpx \\\\\\n    -m 8G \\\\\\n    -smp 4 \\\\\\n    -drive file=ubuntu-image.qcow2 \\\\\\n    -bios $efi \\\\\\n    -cdrom $iso\\n```\\n\\nOptions in details,\\n\\n- `-accel whpx`: use hardware acceleration\\n\\n3. [?]Boot the installed Ubuntu OS\\n\\n```sh\\n# Install OS into a disk image\\nqemu-system-x86_64 \\\\\\n    -accel whpx \\\\\\n    -m 8G \\\\\\n    -smp 4 \\\\\\n    -bios $efi \\\\\\n    -drive file=ubuntu.qcow2,format=qcow2,if=virtio \\\\\\n```\\n\\n### Boot aarch64 ISO image\\n\\nEmulate aarch64 ISO image in Windows,\\n\\n```sh\\nefi=\\"$PWD/UEFI/aarch64/QEMU_EFI.fd\\"\\niso=\\"ubuntu-22.04-live-server-arm64.iso\\"\\n\\nqemu-system-aarch64 \\\\\\n    -monitor stdio \\\\\\n    -machine virt \\\\\\n    -cpu cortex-a57 \\\\\\n    -m 4G \\\\\\n    -smp 4 \\\\\\n    -drive file=ubuntu.qcow2,format=raw,if=virtio \\\\\\n    -bios $efi \\\\\\n    -cdrom $iso\\n```\\n\\nEmulate aarch64 ISO image in mac M1,\\n\\n```sh\\nqemu-system-aarch64 \\\\\\n    -monitor stdio \\\\\\n    -machine virt \\\\\\n    -accel hvf \\\\\\n    -cpu host \\\\\\n    -m 4G \\\\\\n    -smp 4 \\\\\\n    -drive file=ubuntu.qcow2,format=raw,if=virtio \\\\\\n    -bios $efi \\\\\\n    -cdrom $iso\\n``` \\n\\nOptions in details,\\n\\n- `-accel hvf`: use hardware acceleration in mac M1.\\n- `-cpu host`: use mac M1 arm CPU.\\n\\n### Boot a preinstalled image\\n\\n```sh\\n# linux\\nfdisk -l ubuntu-core-22-arm64+raspi.img\\n\\n# osx\\nhdiutil imageinfo ubuntu-core-22-arm64+raspi.img\\n```\\n\\n```sh\\nkernel=\\"$PWD/TinyCore/boot/vmlinuz64\\"\\ninitrd=$\\"$PWD/TinyCore/boot/corepure64.gz\\"\\nimg=$\\"$PWD/TinyCorePure64-14.0.iso\\"\\nefi=\\"$PWD/UEFI/ovmf-x64/OVMF-pure-efi.fd\\"\\n\\nkernel=\\"$PWD/linux_qemu/x86_64/bzImage\\"\\nvmlinuz=\\"$PWD/linux_qemu/x86_64/vmlinux\\"\\ninitrd=\\"$PWD/linux_qemu/x86_64/rootfs.ext2\\"\\nimg=\\"$PWD/linux_qemu/x86_64/rootfs.ext2\\"\\n```\\n\\n```sh\\nqemu-system-x86_64 \\\\\\n    -nographic \\\\\\n    -m 4G \\\\\\n    -kernel $kernel \\\\\\n    -initrd $img \\\\\\n    -append \\"console=ttyS0\\" \\\\\\n    -netdev user,id=mynet,hostfwd=tcp::2222-:22 \\\\\\n    -device virtio-net-pci,netdev=mynet\\n```\\n\\n### Boot linux kernel\\n\\n## Troubleshooting\\n\\n## Resources\\n\\n[UEFI, PC boot process and UEFI with QEMU | joonas.fi](https://joonas.fi/2021/02/uefi-pc-boot-process-and-uefi-with-qemu/)\\n\\nhttps://medium.com/@ThyCrow/compiling-the-linux-kernel-and-creating-a-bootable-iso-from-it-6afb8d23ba22\\n\\nhttps://levelup.gitconnected.com/probably-the-simplest-way-to-install-debian-ubuntu-in-qemu-2db6afde27ef\\n\\n[UEFI on AARCH64 | Welcome to the Mike\u2019s homepage!](https://krinkinmu.github.io/2020/11/21/EFI-aarch64.html)\\n\\n[OVMF \xb7 tianocore/tianocore.github.io Wiki \xb7 GitHub](https://github.com/tianocore/tianocore.github.io/wiki/OVMF)\\n\\nhttps://wiki.debian.org/Arm64Qemu\\n\\nhttp://cdn.kernel.org/pub/linux/kernel/people/will/docs/qemu/qemu-arm64-howto.html\\n\\nhttps://futurewei-cloud.github.io/ARM-Datacenter/qemu/how-to-launch-aarch64-vm/\\n\\nhttps://xryan.net/p/212"},{"id":"/wiki-coral","metadata":{"permalink":"/blog/wiki-coral","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-coral.mdx","source":"@site/../../blog/wiki-coral.mdx","title":"Wiki Coral","description":"wiki-coral","date":"2023-09-18T00:00:00.000Z","formattedDate":"September 18, 2023","tags":[{"label":"wiki","permalink":"/blog/tags/wiki"},{"label":"coral","permalink":"/blog/tags/coral"},{"label":"serial console","permalink":"/blog/tags/serial-console"}],"readingTime":2.06,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/wiki-coral.mdx"},"authors":["frank"],"tags":["wiki","coral","serial console"],"description":"wiki-coral","keywords":["wiki","coral","mendel"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-09-18T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Wiki QEMU","permalink":"/blog/wiki-qemu"},"nextItem":{"title":"Wiki Cross Compilation","permalink":"/blog/wiki-cross-compilation"}},"content":"Set up Coral Dev Board for employing an Edge TPU coprocessor.\\n\\nPrototype new projects demanding fast on-device inference for the ML models.\\n\\n\x3c!--truncate--\x3e\\n\\n## Resources\\n\\n[Get started with the Dev Board | CoralCoralClose](https://coral.ai/docs/dev-board/get-started/)\\n\\n## Background\\n\\nThe official documents [Get started with the Dev Board](https://coral.ai/docs/dev-board/get-started/) contains comprehensive how-to contents and rich examples. Here are just some experiences from myself. You can always go back to the official website to review and get the details.\\n\\nThe recommended method to access the Coral board is using [Mendel Development Tool (mdt)](https://coral.ai/docs/dev-board/mdt/), which is required to be installed on your host machine alongside the `Python`. Common steps to enter the shell terminal from `mdt` are in following:\\n\\n1. `mdt` tool generate a pair of `SSH key`s, save the `private key` on the host and push the `public key` to the Coral using `http` via `41337` port.\\n2. Coral board has a running a `mdt-keymaster` server that is listening `41337` port, and put the `public key` into `~/.ssh/authorized_keys`.\\n3. `mdt shell` now can login to the shell terminal of Coral board like `ssh mendel@192.168.100.2` when connecting over USB-C(OTG) or `ssh mendel@indigo-quill.local` over the same network where your host PC is.\\n\\n:::info\\nCoral board is set up by disabling password login in `OpenSSH` in default, so it must be provided with `SSH key` otherwise you change the setting to be like `PasswordAuthentication yes`.\\n:::\\n\\n:::note\\nYou can check the `key master` by,\\n\\n```sh\\nmendel@indigo-quill:~$ lsof -i:41337\\nCOMMAND    PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\\nmdt-keyma 7846 mendel    5u  IPv4  20302      0t0  TCP 192.168.100.2:41337 (LISTEN)\\nmdt-keyma 7847 mendel    6u  IPv4  20619      0t0  TCP 192.168.101.2:41337 (LISTEN)\\n```\\n\\n:::\\n\\nAlthough `mdt` maybe facilitate the access to the Coral board, some magics and additional steps are kept from sight.\\n\\nTo do not use `mdt`, we need access the dev board through `serial console` instead of `mdt keymaster` server, to make configuration.\\n\\nThere are general ways to access a just-setup Coral in brief steps:\\n\\n1. Connect to Coral board\'s `serial console` by the instructions [Connect to the Dev Board\'s serial console](https://coral.ai/docs/dev-board/serial-console/)\\n2. Log into the Dev board by username: `mendel` and password: `mendel` in default.\\n3. Enable SSH Password Authentication. Edit `/etc/ssh/sshd_config` to change `PasswordAuthentication no` to `PasswordAuthentication yes`, and `sudo service ssh restart` to restart the ssh service.\\n4. Log into the shell using username: `mendel` and password: `mendel`.\\n5. If you want to keep the secure shell, generate `private SSH key` stored in host and `public SSH key` saved into Coral."},{"id":"/wiki-cross-compilation","metadata":{"permalink":"/blog/wiki-cross-compilation","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-cross-compilation.mdx","source":"@site/../../blog/wiki-cross-compilation.mdx","title":"Wiki Cross Compilation","description":"Wiki Cross Compilation","date":"2023-09-18T00:00:00.000Z","formattedDate":"September 18, 2023","tags":[{"label":"wiki","permalink":"/blog/tags/wiki"},{"label":"cross-compilation","permalink":"/blog/tags/cross-compilation"}],"readingTime":2.62,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/wiki-cross-compilation.mdx"},"authors":["frank"],"tags":["wiki","cross-compilation"],"description":"Wiki Cross Compilation","keywords":["Wiki Cross Compilation"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-09-18T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Wiki Coral","permalink":"/blog/wiki-coral"},"nextItem":{"title":"Wiki Samba","permalink":"/blog/wiki-samba"}},"content":"## Cross Compilation Anatomy\\n\\nCross-Compilation ecosystem involves the following components:\\n\\n- host system\\n  - cross-Compilation toolchain\\n    - cross compiler\\n    - cross linker\\n    - cross debugger\\n    - sysroot\\n      - target system library files\\n      - target system header files\\n      - target system other files\\n- target system\\n\\n\x3c!--truncate--\x3e\\n\\nCross-Compilation toolchain:\\n\\n- GCC\\n- Buildroot\\n- Yocto Project\\n- Crosstool-NG\\n- Linaro\\n- Clang/LLVM\\n\\n## GCC\\n\\nLet\'s explore what a toolchain is like and what are needed to build something for a `aarch64` platform on `x86_64` debian-like host.\\n\\n### Obtaining a cross-compilation toolchain for `aarch64`\\n\\nFor simplicity and in a super fast way, we will use a prebuilt and ready-on toolchain in `x86_64` Ubuntu.\\n\\n```sh\\napt install gcc make gcc-aarch64-linux-gnu binutils-aarch64-linux-gnu\\n```\\n\\n### Where is `cross compiler`\\n\\nWe see `cross compiler` binary type in host is `x86-64`,\\n\\n```sh\\n$ file /usr/bin/aarch64-linux-gnu-gcc-11\\n/usr/bin/aarch64-linux-gnu-gcc-11: ELF 64-bit LSB executable, x86-64, version 1 (GNU/Linux), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=b1112487d0dcb759db32e15b8f40f28a05484272, for GNU/Linux 3.2.0, stripped\\n```\\n\\n### Where is `sysroot`\\n\\nThe `sysroot` locates in `/usr/aarch64-linux-gnu`,\\n\\n```sh\\n$ tree --filelimit=100 /usr/aarch64-linux-gnu\\n/usr/aarch64-linux-gnu\\n\u251c\u2500\u2500 bin\\n\u2502\xa0\xa0 \u251c\u2500\u2500 ar -> ../../bin/aarch64-linux-gnu-ar\\n\u2502\xa0\xa0 \u251c\u2500\u2500 as -> ../../bin/aarch64-linux-gnu-as\\n\u2502\xa0\xa0 \u251c\u2500\u2500 ld -> ../../bin/aarch64-linux-gnu-ld\\n\u2502\xa0\xa0 \u251c\u2500\u2500 ld.bfd -> ../../bin/aarch64-linux-gnu-ld.bfd\\n\u2502\xa0\xa0 \u251c\u2500\u2500 ld.gold -> ../../bin/aarch64-linux-gnu-ld.gold\\n\u2502\xa0\xa0 \u251c\u2500\u2500 nm -> ../../bin/aarch64-linux-gnu-nm\\n\u2502\xa0\xa0 \u251c\u2500\u2500 objcopy -> ../../bin/aarch64-linux-gnu-objcopy\\n\u2502\xa0\xa0 \u251c\u2500\u2500 objdump -> ../../bin/aarch64-linux-gnu-objdump\\n\u2502\xa0\xa0 \u251c\u2500\u2500 ranlib -> ../../bin/aarch64-linux-gnu-ranlib\\n\u2502\xa0\xa0 \u251c\u2500\u2500 readelf -> ../../bin/aarch64-linux-gnu-readelf\\n\u2502\xa0\xa0 \u2514\u2500\u2500 strip -> ../../bin/aarch64-linux-gnu-strip\\n\u251c\u2500\u2500 include  [139 entries exceeds filelimit, not opening dir]\\n\u2514\u2500\u2500 lib\\n    \u251c\u2500\u2500 Mcrt1.o\\n    \u251c\u2500\u2500 Scrt1.o\\n    \u251c\u2500\u2500 crt1.o\\n    \u251c\u2500\u2500 crti.o\\n    \u251c\u2500\u2500 crtn.o\\n    \u251c\u2500\u2500 gcrt1.o\\n    \u251c\u2500\u2500 grcrt1.o\\n    \u251c\u2500\u2500 ld-linux-aarch64.so.1\\n```\\n\\nAs you see, the `binutils-aarch64-linux-gnu` will install `binutils` tools in `/usr/aarch64-linux-gnu/bin`,\\n\\nThese `binutils` are also `x86_64` binaries,\\n\\n```sh\\n file $(readlink -f /usr/aarch64-linux-gnu/bin/ar)\\n/usr/bin/aarch64-linux-gnu-ar: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=4f75b6dc6fe5ae92c78a51e6479ca2c65bbf5335, for GNU/Linux 3.2.0, stripped\\n```\\n\\nWhile target libraries are `aarch64` type,\\n\\n```sh\\nfile /usr/aarch64-linux-gnu/lib/crt1.o\\n/usr/aarch64-linux-gnu/lib/crt1.o: ELF 64-bit LSB relocatable, ARM aarch64, version 1 (SYSV), for GNU/Linux 3.7.0, not stripped\\n```\\n\\n### Compile `hello.c`\\n\\n```sh\\n$ aarch64-linux-gnu-gcc-11 hello.c -o a.out\\n$ file a.out\\na.out: ELF 64-bit LSB pie executable, ARM aarch64, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux-aarch64.so.1, BuildID[sha1]=367c436db0697f16039d9249e4a4e809ef9e68b3, for GNU/Linux 3.7.0, not stripped\\n```\\n\\n## Clang/LLVM\\n\\n[Cross compilation with Clang and LLVM tools](https://static.linaro.org/connect/bkk19/presentations/bkk19-210.pdf)\\n\\n[Cross compiling made easy, using Clang and LLVM \xb7 mcilloni\'s blog](https://mcilloni.ovh/2021/02/09/cxx-cross-clang/)\\n\\n```sh\\napt install lld clang llvm\\n```\\n\\n```sh\\n$ wget https://releases.linaro.org/components/toolchain/binaries/7.5-2019.12/aarch64-linux-gnu/sysroot-glibc-linaro-2.25-2019.12-aarch64-linux-gnu.tar.xz\\n\\n$ tar -xvf sysroot-glibc-linaro-2.25-2019.12-aarch64-linux-gnu.tar.xz\\n\\n$ mv sysroot-glibc-linaro-2.25-2019.12-aarch64-linux-gnu aarch64-linux-gnu\\n```\\n\\n```sh\\n$ ll aarch64-linux-gnu\\ntotal 20K\\ndrwxr-xr-x 2 11827 9000 4.0K Dec  4  2019 etc\\ndrwxr-xr-x 3 11827 9000 4.0K Dec  4  2019 lib\\ndrwxr-xr-x 2 11827 9000 4.0K Dec  4  2019 sbin\\ndrwxr-xr-x 8 11827 9000 4.0K Dec  4  2019 usr\\ndrwxr-xr-x 3 11827 9000 4.0K Dec  4  2019 var\\n```\\n\\n\\n```sh\\n$ cat > hello.c << EOL\\n#include <stdio.h>\\nint main(int argc, char *argv[])\\n{\\n  printf(\\"Hello cross-compilation world!\\\\n\\");\\n  return 0;\\n}\\nEOL\\n```\\n\\n```sh\\nsysroot=~/Documents/sysroot/aarch64-linux-gnu/usr\\n```\\n\\n```sh\\nclang --target=aarch64-linux-gnu hello.c -o hello_aarch64 -v\\n```\\n\\n```sh\\nclang --target=aarch64-linux-gnu hello.c -o hello_aarch64 --sysroot=$sysroot -v\\n```\\n\\n```sh\\nclang --target=aarch64-linux-gnu  -fsanitize=undefined \\\\\\n    -fuse-ld=lld \\\\\\n    --rtlib=compiler-rt -stdlib=libc++ \\\\\\n    -nostdinc++ -nostdlib \\\\\\n    -I${sysroot}/usr/include/ \\\\\\n    -Wl,-L${sysroot}/usr/lib \\\\\\n    --sysroot=$sysroot \\\\\\n    --verbose \\\\\\n    hello.c -o hello\\n```\\n\\n## Resources\\n\\nhttps://wiki.osdev.org/GCC_Cross-Compiler\\n\\nhttps://github.com/generia/buildroot-osx\\n\\nhttps://crosstool-ng.github.io/docs/\\n\\nhttps://github.com/messense/homebrew-macos-cross-toolchains/blob/main/.github/workflows/aarch64.yml"},{"id":"/wiki-samba","metadata":{"permalink":"/blog/wiki-samba","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-samba.mdx","source":"@site/../../blog/wiki-samba.mdx","title":"Wiki Samba","description":"Wiki Samba","date":"2023-09-15T00:00:00.000Z","formattedDate":"September 15, 2023","tags":[{"label":"wiki","permalink":"/blog/tags/wiki"},{"label":"samba","permalink":"/blog/tags/samba"}],"readingTime":0.215,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/wiki-samba.mdx"},"authors":["frank"],"tags":["wiki","samba"],"description":"Wiki Samba","keywords":["Wiki Samba"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-09-15T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Wiki Cross Compilation","permalink":"/blog/wiki-cross-compilation"},"nextItem":{"title":"Wiki WPF","permalink":"/blog/wiki-wpf"}},"content":"\x3c!--truncate--\x3e\\n\\n## Setting up Samba\\n\\n[How to Install Samba in Ubuntu](https://phoenixnap.com/kb/ubuntu-samba)\\n\\n## Troubleshooting Samba\\n\\n[Troubleshooting Access Denied on SAMBA - Ask Ubuntu](https://askubuntu.com/questions/1391434/troubleshooting-access-denied-on-samba)\\n\\n```editorconfig title=\\"/etc/samba.conf\\"\\n[documents]\\npath = /data/documents\\nvalid users = @simon\\nguest ok = no\\nwritable = yes\\nbrowsable = yes\\n```"},{"id":"/wiki-wpf","metadata":{"permalink":"/blog/wiki-wpf","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-wpf.md","source":"@site/../../blog/wiki-wpf.md","title":"Wiki WPF","description":"Wiki WPF","date":"2023-09-15T00:00:00.000Z","formattedDate":"September 15, 2023","tags":[{"label":"wiki","permalink":"/blog/tags/wiki"},{"label":"wpf","permalink":"/blog/tags/wpf"}],"readingTime":1.19,"hasTruncateMarker":false,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/wiki-wpf.mdx"},"authors":["frank"],"tags":["wiki","wpf"],"description":"Wiki WPF","keywords":["Wiki WPF"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-09-15T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Wiki Samba","permalink":"/blog/wiki-samba"},"nextItem":{"title":"Wiki FFmpeg","permalink":"/blog/wiki-ffmpeg"}},"content":"[GitHub - SingletonSean/wpf-tutorials: Tutorial source code for WPF concepts.](https://github.com/SingletonSean/wpf-tutorials)\\n\\n[GitHub - liviaerxin/WPF-MVVM-EFC-Example: \ud83d\udcf2 MVVM (WPF) application built with EFCore, Abstract Factory pattern and dependency injection (Microsoft Unity)](https://github.com/liviaerxin/WPF-MVVM-EFC-Example)\\n\\n## MVVM\\n\\n[MVVM Pattern Made Simple - CodeProject](https://www.codeproject.com/Articles/278901/MVVM-Pattern-Made-Simple)\\n\\n[MVVM in Depth - CodeProject](https://www.codeproject.com/Articles/659614/MVVM-in-Depth)\\n\\n[My attempt to understand MVVM pattern and questions raised during it : csharp](https://www.reddit.com/r/csharp/comments/i3pbmt/my_attempt_to_understand_mvvm_pattern_and/)\\n\\n[Patterns - WPF Apps With The Model-View-ViewModel Design Pattern | Microsoft Docs](https://docs.microsoft.com/en-us/archive/msdn-magazine/2009/february/patterns-wpf-apps-with-the-model-view-viewmodel-design-pattern)\\n\\n[Introduction to the MVVM Toolkit - Windows Community Toolkit | Microsoft Docs](https://docs.microsoft.com/en-us/windows/communitytoolkit/mvvm/introduction)\\n\\n## Features\\n\\n- IoC, Inversion of Control\\n- DI, Dependency Injection\\n- Navigation\\n- ViewModel-to-ViewModel Communication\\n  - [MVVM Light Messenger](https://dotnetpattern.com/mvvm-light-messenger/)\\n  - [Event Aggregator | Prism](https://prismlibrary.com/docs/event-aggregator.html)\\n  - [ReactiveUI - Message Bus](https://www.reactiveui.net/docs/handbook/message-bus/)\\n- Observable Object in ViewModel\\n  - Wrapping a non-observable model\\n\\n    ```C#\\n    // https://docs.microsoft.com/en-us/windows/communitytoolkit/mvvm/observableobject#wrapping-a-non-observable-model\\n    public class ObservableUser : ObservableObject\\n    {\\n        private readonly User user;mvvm-application.png\\n\\n        public ObservableUser(User user) => this.user = user;\\n\\n        public string Name\\n        {\\n            get => user.Name;\\n            set => SetProperty(user.Name, value, user, (u, n) => u.Name = n);\\n        }\\n    }\\n    ```\\n\\n## Principles\\n\\n![MVVM Application](../attachments/images/mvvm-application.png)\\n\\n- View-to-ViewModel one-to-one/many-to-one mapping\\n- ViewModel-to-ViewModel communication\\n- ViewModel-to-Model one-to-one/one-to-many binding\\n\\n## Access Database\\n\\nDAO or Repository\\n\\nEntity\\nDB Context\\n\\n## ReactiveUI\\n\\n[To property - pasoft-share/ReactiveUI](https://pasoft-sharereactiveui.readthedocs.io/en/stable/basics/to-property/)\\n\\nOne of the core features of ReactiveUI is to be able to convert properties to Observables, via WhenAny , and to convert Observables into Properties, via a method called ToProperty . These properties are called Output Properties in ReactiveUI, and they are a huge part of using the framework effectively."},{"id":"/wiki-ffmpeg","metadata":{"permalink":"/blog/wiki-ffmpeg","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-ffmpeg.mdx","source":"@site/../../blog/wiki-ffmpeg.mdx","title":"Wiki FFmpeg","description":"Learn FFmpeg","date":"2023-09-13T00:00:00.000Z","formattedDate":"September 13, 2023","tags":[{"label":"wiki","permalink":"/blog/tags/wiki"},{"label":"ffmpeg","permalink":"/blog/tags/ffmpeg"}],"readingTime":0.025,"hasTruncateMarker":false,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/wiki-ffmpeg.mdx"},"authors":["frank"],"tags":["wiki","ffmpeg"],"description":"Learn FFmpeg","keywords":["Learn FFmpeg"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-09-13T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Wiki WPF","permalink":"/blog/wiki-wpf"},"nextItem":{"title":"Linux Boot Process","permalink":"/blog/linux-boot-process"}},"content":"## Best Resources\\n\\n[FFmpeg Wiki](https://trac.ffmpeg.org/)"},{"id":"/linux-boot-process","metadata":{"permalink":"/blog/linux-boot-process","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/linux-boot-process.mdx","source":"@site/../../blog/linux-boot-process.mdx","title":"Linux Boot Process","description":"Linux Boot Process","date":"2023-09-12T00:00:00.000Z","formattedDate":"September 12, 2023","tags":[{"label":"Linux Boot Process","permalink":"/blog/tags/linux-boot-process"}],"readingTime":0.02,"hasTruncateMarker":false,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["Linux Boot Process"],"description":"Linux Boot Process","keywords":["Linux Boot Process"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-09-12T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Wiki FFmpeg","permalink":"/blog/wiki-ffmpeg"},"nextItem":{"title":"Install FFmpeg on Nvidia CUDA Container","permalink":"/blog/ffmpeg-on-cuda-container"}},"content":"https://www.freecodecamp.org/news/the-linux-booting-process-6-steps-described-in-detail/\\n\\nhttps://www.baeldung.com/linux/boot-process\\n\\nhttps://www.thegeekstuff.com/2011/02/linux-boot-process/\\n\\nhttps://opensource.com/article/18/1/analyzing-linux-boot-process"},{"id":"/ffmpeg-on-cuda-container","metadata":{"permalink":"/blog/ffmpeg-on-cuda-container","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/ffmpeg-on-cuda-container.mdx","source":"@site/../../blog/ffmpeg-on-cuda-container.mdx","title":"Install FFmpeg on Nvidia CUDA Container","description":"FFmpeg on CUDA Container","date":"2023-09-06T00:00:00.000Z","formattedDate":"September 6, 2023","tags":[{"label":"ffmpeg","permalink":"/blog/tags/ffmpeg"},{"label":"docker","permalink":"/blog/tags/docker"},{"label":"cuda","permalink":"/blog/tags/cuda"},{"label":"nvidia","permalink":"/blog/tags/nvidia"}],"readingTime":1.7,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/ffmpeg-on-cuda-container.mdx"},"authors":["frank"],"tags":["ffmpeg","docker","cuda","nvidia"],"description":"FFmpeg on CUDA Container","keywords":["FFmpeg on CUDA Container"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-09-06T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Linux Boot Process","permalink":"/blog/linux-boot-process"},"nextItem":{"title":"Intel VROC RAID on Ubuntu","permalink":"/blog/raid-intel-vroc"}},"content":"[Using FFmpeg with NVIDIA GPU Hardware Acceleration - NVIDIA Docs](https://docs.nvidia.com/video-technologies/video-codec-sdk/12.0/ffmpeg-with-nvidia-gpu/index.html)\\n\\n[NVIDIA FFmpeg Transcoding Guide | NVIDIA Technical Blog](https://developer.nvidia.com/blog/nvidia-ffmpeg-transcoding-guide/)\\n\\n[User Guide \u2014 container-toolkit 1.13.5 documentation](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/user-guide.html)\\n\\n\\n[wiki cuda](./wiki-cuda.mdx)\\n\\nThis documentation describes to install `FFmpeg` on `nvidia/cuda` **container** to use the **Nvidia GPU** to accelerate encoding.\\n\\nIf you want to know [how to install FFmpeg with NVIDIA GPU on Linux](https://www.cyberciti.biz/faq/how-to-install-ffmpeg-with-nvidia-gpu-acceleration-on-linux/), go to see that.\\n\\n\\n**FFmpeg** can support hardware-based decoding and encoding for Nvidia GPU card. With the help of Nvidia GPU, `h264_nvenc` can lead encoding speed with **5x** faster than `libx264` in **GTX1080** card.\\n\\nLet\'s see how to install everything one by one on the **Nvidia CUDA Docker** container `nvidia/cuda:12.2.0-devel-ubuntu20.04`, in which CUDA toolkit and GPU driver are already included.\\n\\n\x3c!--truncate--\x3e\\n\\n:::note\\n> It must use `nvidia/cuda:xxx-devel-xxx` image to build `FFmpeg`, because the `dev` image contain all the necessary libraries.\\n:::\\n\\n## Prerequisites\\n\\nMake sure **Nvidia GPU Driver** is installed in your host machine! As it will be mounted into the **container**. \\n\\nUse `ldconfig` to check if the required Nvidia GPU driver libraries are available inside the container. Such as,\\n\\n```sh\\nldconfig -p | grep libcuda\\n```\\n\\n:::note\\n> When running in the `nvidia/cuda` Docker container, what Nvidia libraries(from the host machine) should be mounted inside the container are specified by the `NVIDIA_DRIVER_CAPABILITIES` env variable, see [driver-capabilities](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/user-guide.html#driver-capabilities). Here for `FFmpeg` to employ GPU, it should be included at least as `NVIDIA_DRIVER_CAPABILITIES=video,utility`.\\n:::\\n\\n## Step by Step\\n\\n```sh\\ndocker run --rm --runtime=nvidia \\\\\\n    -e NVIDIA_VISIBLE_DEVICES=all \\\\\\n    -e NVIDIA_DRIVER_CAPABILITIES=compute,utility \\\\\\n    nvidia/cuda nvidia-smi\\n```\\n\\n```sh\\ndocker run --rm --runtime=nvidia \\\\\\n    -e NVIDIA_VISIBLE_DEVICES=all \\\\\\n    -e NVIDIA_DRIVER_CAPABILITIES=compute,utility \\\\\\n    nvidia/cuda bash\\n```\\n\\n## Complete Dockerfile\\n\\nThe source code is available at [Dockerfile](../code-snippets/dockerfile/nvidia-cuda-ffmpeg/Dockerfile)\\n\\nimport CodeBlock from \'@theme/CodeBlock\';\\nimport CodeSource from \'!!raw-loader!../code-snippets/dockerfile/nvidia-cuda-ffmpeg/Dockerfile\';\\n\\n<CodeBlock language=\\"yaml\\" title=\\"nvidia-cuda-ffmpeg/Dockerfile\\">{CodeSource}</CodeBlock>\\n\\n## Known issues\\n\\nNvidia Docker encoding stops after long running time with such error message: `CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected`.\\n\\n[[Issue]: NVidia Docker transcoding randomly stops working after 5 minutes to 4 hours later. \xb7 Issue #9287 \xb7 jellyfin/jellyfin \xb7 GitHub](https://github.com/jellyfin/jellyfin/issues/9287)\\n\\nPossible solution:\\n\\nEdit `/etc/defautls/grub`,\\n\\n```sh\\nGRUB_CMDLINE_LINUX_DEFAULT=\\"quiet splash systemd.unified_cgroup_hierarchy=0\\"\\n```\\n\\nThen run `update-grub` and reboot."},{"id":"/raid-intel-vroc","metadata":{"permalink":"/blog/raid-intel-vroc","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/raid-intel-vroc.mdx","source":"@site/../../blog/raid-intel-vroc.mdx","title":"Intel VROC RAID on Ubuntu","description":"Setup Intel VROC RAID on Ubuntu","date":"2023-08-29T00:00:00.000Z","formattedDate":"August 29, 2023","tags":[{"label":"intel vroc","permalink":"/blog/tags/intel-vroc"},{"label":"raid","permalink":"/blog/tags/raid"},{"label":"ubuntu","permalink":"/blog/tags/ubuntu"},{"label":"best practice","permalink":"/blog/tags/best-practice"}],"readingTime":6.26,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Docs Docusaurus Template","description":"Creates Docusaurus docs/slip","filepath":"docs/wiki-ffmpeg.md"},"authors":["frank"],"description":"Setup Intel VROC RAID on Ubuntu","keywords":["Setup Intel VROC RAID on Ubuntu"],"image":"https://i.imgur.com/mErPwqL.png","tags":["intel vroc","raid","ubuntu","best practice"],"date":"2023-08-29T00:00:00.000Z"},"prevItem":{"title":"Install FFmpeg on Nvidia CUDA Container","permalink":"/blog/ffmpeg-on-cuda-container"},"nextItem":{"title":"RAID on Ubuntu","permalink":"/blog/raid-on-ubuntu"}},"content":"- [Linux VROC User Guide](https://www.intel.com/content/dam/support/us/en/documents/memory-and-storage/ssd-software/Linux_VROC_6-0_User_Guide.pdf)\\n- [VROC Ubuntu Setup](https://www.intel.com/content/dam/support/us/en/documents/memory-and-storage/ssd-software/VROC-Ubuntu-Setup-UserGuide-342787-US.pdf)\\n\\nThis document will present how to create and manage **Intel VROC RAID** on Ubuntu with `mdadm` utility(It should also work in other Linux).\\n\\nFor setting up **Intel VROC RAID** on Ubuntu in `BIOS`, go to see [VROC Ubuntu Setup](https://www.intel.com/content/dam/support/us/en/documents/memory-and-storage/ssd-software/VROC-Ubuntu-Setup-UserGuide-342787-US.pdf).\\n\\nFor creating **software RAID** on Ubuntu, go to see:\\n\\n[Ubuntu RAID](./raid-on-ubuntu.mdx).\\n\\n\x3c!--truncate--\x3e\\n\\n## Background\\n\\nOn the premise machine, there are 2 NVMe SSDs and 8 SATA hard drives(HDDs), and also it ships with a in-box hardware-assisted RAID controller(**Intel VROC**) on the Intel CPU, which is supposed to keep overall advantages over **software RAID**.\\n\\nFor me, I would like to use these 8 HDDs(`sda`, `sdb`, ..., `sdh`) to store data for long time, while retaining the balance between redundancy and performance. So here **RAID 5**(Stripping with Parity) comes into my mind.\\n\\nTo leverage the power of **Intel VROC** in Ubuntu(Linux), you also need the `mdadm` command line tool to manage intel VROC which support RAID 0, RAID 1, RAID 5 and RAID 10\\n\\n:::note\\nIn my understanding, the intel VROC register in system with the common interface with `mdadm`, so the `mdadm` software can operate it. And running command will show the `mdadm` is using intel VROC,\\n\\n```sh\\n$ sudo mdadm --detail-platform\\n\\n       Platform : Intel(R) Virtual RAID on CPU\\n        Version : 8.0.3.1002\\n    RAID Levels : raid0 raid1 raid10 raid5\\n    Chunk Sizes : 4k 8k 16k 32k 64k 128k\\n    2TB volumes : supported\\n      2TB disks : supported\\n      Max Disks : 8\\n    Max Volumes : 2 per array, 8 per controller\\n I/O Controller : /sys/devices/pci0000:00/0000:00:17.0 (SATA)\\n          Port7 : /dev/sdh (ZR909K07)\\n          Port6 : /dev/sdg (ZV70BN24)\\n          Port3 : /dev/sdd (ZV70BD3T)\\n          Port4 : /dev/sde (ZR909Q89)\\n          Port1 : /dev/sdb (ZRT0S2FM)\\n          Port5 : /dev/sdf (ZR9099MM)\\n          Port2 : /dev/sdc (ZR909AGN)\\n          Port0 : /dev/sda (ZV70BMH9)\\n\\n       Platform : Intel(R) Virtual RAID on CPU\\n        Version : 8.0.3.1002\\n    RAID Levels : raid0 raid1 raid10\\n    Chunk Sizes : 4k 8k 16k 32k 64k 128k\\n    2TB volumes : supported\\n      2TB disks : supported\\n      Max Disks : 96\\n    Max Volumes : 2 per array, 24 per controller\\n 3rd party NVMe : supported\\n I/O Controller : /sys/devices/pci0000:8d/0000:8d:00.5 (VMD)\\n NVMe under VMD : /dev/nvme0n1 (633FC084FCVK)\\n NVMe under VMD : /dev/nvme1n1 (633FC0DEFCVK)\\n I/O Controller : /sys/devices/pci0000:6f/0000:6f:00.5 (VMD)\\n I/O Controller : /sys/devices/pci0000:51/0000:51:00.5 (VMD)\\n```\\n\\n:::\\n\\n:::info\\n\\nInstall Ubuntu Server on RAID:\\nUbuntu Server Image has inbox `mdadm` utilities and `VMD` drivers(which enable intel VROC functionalities), so it is quite convenient to create the RAID 1 on 2 SSDs either in BIOS stage(for intel VROC only) or in storage layer step during OS installation stage(software RAID), then install Ubuntu Server OS on the RAID 1.\\n\\nAfter creating the RAID 1 via intel VROC in BIOS, Ubuntu Server installation can detect the RAID created by VROC in step when set up the storage layer.\\n\\nIf you skip BIOS to create RAID during OS installation, remember to add `-e isms` when using `mdadm` to create RAID(you can enter the terminal, do ``) otherwise the RAID is software based and does not apply VROC.\\n\\nInstall Ubuntu Desktop on RAID:\\nUbuntu Desk Image does not ship the `mdadm` tool, so it is nearly impossible to create RAID and install Ubuntu Desktop OS on the RAID(however this one [Install Ubuntu 20.04 desktop with RAID 1 and LVM on machine with UEFI BIOS](https://askubuntu.com/questions/1299978/install-ubuntu-20-04-desktop-with-raid-1-and-lvm-on-machine-with-uefi-bios) from stackoverflow seems to be successful)\\n:::\\n\\n## Set up RAID 5 array\\n\\nHere, I use 8 disks: `/dev/sda`, `/dev/sdb`, ..., `/dev/sdh` to create **RAID 5** array and mount it for use in practice.\\n\\n### Create RAID array\\n\\nWhen creating RAID array, **Intel VROC** is different with **software RAID** array creation as an additional container is needed to create firstly. Inside the container, some information is labelled into the drives for Intel VROC controller to recognize them.\\n\\n1. Create RAID Container with Intel IMSM Metadata\\n\\nthe total number of drives is 8 and `-e imsm`.\\n\\n```sh\\nsudo mdadm --create /dev/md/imsm0 /dev/sd[a-h] -n 8 -e imsm\\n```\\n\\n2. Then, Create a RAID array in the `/dev/md/imsm0` container using total 8 drives with **RAID 5**.\\n\\n```sh\\nsudo mdadm --create /dev/md/md0 /dev/md/imsm0 -l 0 -n 2\\n```\\n\\n### Mount the RAID array for use\\n\\nAfter you create the RAID array in above step, all partitions and data will be erased from all individual disks.\\n\\nThe RAID array is treated as a **logical drive** now.\\n\\n1. Create a `ext4` filesystem on the RAID array\\n\\n```sh\\nsudo mkfs.ext4 -F /dev/md/md0\\n```\\n\\n2. Mount the RAID array\\n\\n```sh\\nsudo mkdir -p /mnt/md0\\n\\nsudo mount /dev/md/md0 /mnt/md0\\n```\\n\\n### Save RAID array configuration\\n\\nTo make sure that the RAID array is reassembled and mounted automatically after reboot, we will have to add some necessary information into `/etc/mdadm/mdadm.conf` and `/etc/fstab`.\\n\\n1. Scan active array and append into `/etc/mdadm/mdadm.conf` file with following:\\n\\n```sh\\nsudo mdadm --detail --scan | sudo tee -a /etc/mdadm/mdadm.conf\\n```\\n\\n2. Update `initramfs`, so the array will be available at early boot:\\n\\n```sh\\nsudo update-initramfs -u\\n```\\n\\n3. Add mount options to `/etc/fstab`, you can use `UUID=xxxx` instead of the `/dev/md0`.\\n\\n```sh\\necho \'/dev/md0 /mnt/md0 ext4 defaults,nofail,discard 0 0\' | sudo tee -a /etc/fstab\\n```\\n\\n## Remove RAID Array\\n\\n### [Optional] Umount the array from filesystem\\n\\nUmount the array from filesystem if mounted,\\n\\n```sh\\nsudo umount /dev/md/md0\\n```\\n\\n### Stop RAID container and array\\n\\n```sh\\n# Stop RAID container\\nsudo mdadm --stop /dev/md/imsm0\\n# Stop RAID array\\nsudo mdadm --stop /dev/md/md0\\n\\n# Stop all arrays and containers\\nsudo mdadm --stop --scan\\n```\\n\\n### Removes the RAID metadata\\n\\nRemoves the RAID metadata on each **drive** and resets the **drive** to normal\\n\\n```sh\\nsudo mdadm --zero-superblock /dev/sda\\nsudo mdadm --zero-superblock /dev/sd[a-h]\\n```\\n\\n### [Optional] Remove RAID configuration\\n\\nRemove mount information to the array if exist. Edit the `/etc/fstab`:\\n\\n```sh title=\\"/etc/fstab\\"\\nsudo nano /etc/fstab\\n```\\n\\nAlso, remove the array definition if exist, from the `/etc/mdadm/mdadm.conf` file:\\n\\n```sh title=\\"/etc/mdadm/mdadm.conf\\"\\nsudo nano /etc/mdadm/mdadm.conf\\n```\\n\\n## Manage RAID Array with mdadm\\n\\n### Find all RAID arrays\\n\\n```sh\\n$ cat /proc/mdstat\\n\\nPersonalities : [raid1] [linear] [multipath] [raid0] [raid6] [raid5] [raid4] [raid10] \\nmd126 : active raid1 nvme0n1[1] nvme1n1[0]\\n      3800741888 blocks super external:/md127/0 [2/2] [UU]\\n      \\nmd127 : inactive nvme0n1[1](S) nvme1n1[0](S)\\n      10402 blocks super external:imsm\\n       \\nunused devices: <none>\\n```\\n\\n### Query information on a RAID array\\n\\n```sh\\nsudo mdadm --detail /dev/md0\\nsudo mdadm --query /dev/md0\\n```\\n\\n### Query information on a physical disk drive\\n\\n```sh\\nsudo mdadm --query /dev/sda\\nsudo mdadm --examine /dev/sda\\n```\\n\\n### Stop a RAID array\\n\\n```sh\\nsudo mdadm --stop /dev/md0\\n# Stop all arrays\\nsudo mdadm --stop --scan\\n```\\n\\n### Starting a RAID Array\\n\\n```sh\\n# This works if the array is defined in the configuration `/etc/mdadm/mdadm.conf` file.\\nsudo mdadm --assemble --scan\\nsudo mdadm --assemble /dev/md0\\n# If the array is not persisted in `/etc/mdadm/mdadm.conf` file but keeping RAID metadata\\nsudo mdadm --assemble /dev/md0 /dev/sda /dev/sdb\\n```\\n\\n### Adding spare devices to a RAID Array\\n\\n```sh\\nsudo mdadm /dev/md0 --add /dev/sde\\n```\\n\\n```sh\\n$ lsblk -f\\nNAME        FSTYPE          FSVER  LABEL UUID                                 FSAVAIL FSUSE% MOUNTPOINTS\\nloop0       squashfs        4.0                                                     0   100% /snap/core20/1974\\nloop1       squashfs        4.0                                                     0   100% /snap/lxd/24322\\nloop2       squashfs        4.0                                                     0   100% /snap/snapd/19457\\nsda         isw_raid_member 1.3.00                                                           \\nsdb         isw_raid_member 1.3.00                                                           \\nsdc         isw_raid_member 1.3.00                                                           \\nsdd         isw_raid_member 1.3.00                                                           \\nsde         isw_raid_member 1.3.00                                                           \\nsdf         isw_raid_member 1.3.00                                                           \\nsdg         isw_raid_member 1.3.00                                                           \\nsdh         isw_raid_member 1.3.00                                                           \\nnvme0n1     isw_raid_member 1.3.00                                                           \\n\u251c\u2500md126                                                                                      \\n\u2502 \u251c\u2500md126p1 vfat            FAT32        292B-DB66                                 1G     1% /boot/efi\\n\u2502 \u2514\u2500md126p2 ext4            1.0          0f58386c-334d-4877-8051-b855bae37fb0    3.3T     0% /\\n\u2514\u2500md127                                                                                      \\nnvme1n1     isw_raid_member 1.3.00                                                           \\n\u251c\u2500md126                                                                                      \\n\u2502 \u251c\u2500md126p1 vfat            FAT32        292B-DB66                                 1G     1% /boot/efi\\n\u2502 \u2514\u2500md126p2 ext4            1.0          0f58386c-334d-4877-8051-b855bae37fb0    3.3T     0% /\\n\u2514\u2500md127                         \\n```\\n\\n```sh\\nsudo fdisk -l /dev/sda\\n```\\n\\n### Delete partition and data in disk\\n\\n```sh\\nsudo dd if=/dev/zero of=/dev/sda  bs=512  count=1\\n```"},{"id":"/raid-on-ubuntu","metadata":{"permalink":"/blog/raid-on-ubuntu","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/raid-on-ubuntu.mdx","source":"@site/../../blog/raid-on-ubuntu.mdx","title":"RAID on Ubuntu","description":"Setup Intel VROC RAID on Ubuntu","date":"2023-08-29T00:00:00.000Z","formattedDate":"August 29, 2023","tags":[{"label":"intel vroc","permalink":"/blog/tags/intel-vroc"},{"label":"raid","permalink":"/blog/tags/raid"},{"label":"ubuntu","permalink":"/blog/tags/ubuntu"},{"label":"best practice","permalink":"/blog/tags/best-practice"}],"readingTime":6.8,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Docs Docusaurus Template","description":"Creates Docusaurus docs/slip","filepath":"docs/wiki-ffmpeg.md"},"authors":["frank"],"description":"Setup Intel VROC RAID on Ubuntu","keywords":["Setup Intel VROC RAID on Ubuntu"],"image":"https://i.imgur.com/mErPwqL.png","tags":["intel vroc","raid","ubuntu","best practice"],"date":"2023-08-29T00:00:00.000Z"},"prevItem":{"title":"Intel VROC RAID on Ubuntu","permalink":"/blog/raid-intel-vroc"},"nextItem":{"title":"Awesome Troubleshooting","permalink":"/blog/awesome-troubleshooting"}},"content":"[How To Create RAID Arrays with mdadm on Ubuntu 22.04  | DigitalOcean](https://www.digitalocean.com/community/tutorials/how-to-create-raid-arrays-with-mdadm-on-ubuntu-22-04)\\n\\n[SoftwareRAID](https://help.ubuntu.com/community/Installation/SoftwareRAID)\\n\\n[How to install Ubuntu with software RAID-1](https://www.servers.com/support/knowledge/linux-administration/how-to-install-ubuntu-with-software-raid-1)\\n\\nWhat is RAID?\\n\\nThe Redundant Array of Independent Disks, commonly known as RAID, is a technology used to combine multiple physical disk drives into a single logical unit for the purpose of data storage and performance improvement. \\n\\nThis blog will demonstrate to set up **software RAID** on Ubuntu(It should also work on other Linux).\\n\\nTo setup **Intel VROC RAID** on Ubuntu, go to see: [Intel VROC RAID on Ubuntu](./raid-intel-vroc.mdx).\\n\\nThe hierarchy of storage abstraction layers in Linux.\\n\\n```plaintext\\n\\n    +------------------------+\\n    |   Application          |\\n    |                        |\\n    |open(\\"/mnt/media/1.png\\")|\\n    |                        |\\n    +------------------------+\\n\\n\\n\\n    +------------------------+\\n    |    Mount Point         |   Higher layer\\n    |                        |        ^\\n    |/dev/sda1 -> /mnt/media |        |\\n    |/dev/sda2 -> /mnt/file  |        |\\n    |                        |        |\\n    +------------------------+        |\\n                                      |\\n    +------------------------+        |\\n    |    Logical Volume      |        |\\n    |                        |        |\\n    | /dev/mapper/vg1-lg1,   |        |\\n    | /dev/mapper/vg1-lg2,   |        |\\n    +------------------------+        |\\n                                      |\\n    +------------------------+        |\\n    |     File System        |        |\\n    |                        |        |\\n    |   ext4, Btrfs, etc     |        |\\n    |                        |        |\\n    +------------------------+        |\\n                                      |\\n    +------------------------+        |\\n    |      Partition         |        |\\n    |                        |        |\\n    |  /dev/sda1, /dev/sda2  |        |\\n    |                        |        |\\n    +------------------------+        |\\n                                      |\\n                                      |\\n    +------------------------+        |\\n    |  Physical Disk Drive   |        |\\n    |                        |        |\\n    |    HDD /dev/hda        |  Lower layer\\n    |    SSD /dev/sda        |\\n    +------------------------+\\n```\\n\\nThe **RAID** is treated as **Logical Disk Drive** above the **Physical Disk Drive** layer. So you should do partitioning on it after being created.\\n\\n\x3c!--truncate--\x3e\\n\\n## Background\\n\\nRecently, there is a chance for me to install Ubuntu(server) OS on a Dell Precision xxx workstation which is includes 2 NVMe SSDs and 8 SATA hard drives(HDDs) and has in-box hardware-assisted RAID controller(**Intel VROC**). In the past, I just play cloud virtual machines or personal host with single disk.\\n\\nConfiguring storage is a critical part of setting up a reliable workstation. So firstly, how to organize these following disks to their roles?\\n\\n- 2 SSDs hold the system to load quickly\\n- 8 HDDs store data persistently\\n\\nIn order to access these physical disks easily and reduce damages from data loss, I need to combine multiple disks to act as one, while keep data redundant and backup. After step-by-step research, there are some enterprise solutions present for me. These drive layer or file system layer approaches designed for specific purposes have their own advantages over others while they maybe achieve some same features.\\n\\nHere are some benefits and shortcomings of them alongside common use cases:\\n\\n- **RAID**(Redundant Array of Independent Disks)\\nAbstraction level: drive layer\\nConcept: RAID uses multiple drives to act as one(logical drive).\\nBenefits: improve data redundancy and data read/write performance\\n\\n- **LVM**(Logical Volume Management)\\nAbstraction level: file system layer\\nConcept: Manage a logical volume over multiple drives, each drive is a Physical Volume(PV).\\nBenefits: combine multiple disks into one logical volume, extend the volume with new disk added, increase/decrease mounted folder in file system\\n\\n- **ZFS**(Z File System)\\n\\nThere are three types of raid, as Wiki saying:\\n\\n1. hardware RAID\\n2. software RAID\\n   - **mdadm** in Linux\\n3. hardware-assisted software RAID, firmware RAID, fake RAID\\n   - **Intel VROC** (Virtual RAID on CPU)\\n\\nThis document will introduce how to set up software RAID(RAID0, RAID1, RAID5, RAID 10) on **already-installed** Ubuntu.\\n\\nTo create a RAID to hold the Ubuntu OS when installing Ubuntu, see [SoftwareRAID](https://help.ubuntu.com/community/Installation/SoftwareRAID) or [How to install Ubuntu with software RAID-1](https://www.servers.com/support/knowledge/linux-administration/how-to-install-ubuntu-with-software-raid-1)\\n\\nIn addition, there are different challenges you will face when installing Ubuntu Server and Ubuntu Desktop.\\n\\n> Install Ubuntu Server on RAID:\\n> Ubuntu Server Image has inbox `mdadm` utilities, so it is quite convenient to create the software RAID on multiple disks then install Ubuntu Server OS on the RAID in storage layer step during OS installation stage.\\n\\n---\\n\\n> Install Ubuntu Desktop on RAID:\\n> Ubuntu Desk Image does not ship the `mdadm` tool, so it is nearly impossible to create RAID and install Ubuntu Desktop OS on the RAID(however this one [Install Ubuntu 20.04 desktop with RAID 1 and LVM on machine with UEFI BIOS](https://askubuntu.com/questions/1299978/install-ubuntu-20-04-desktop-with-raid-1-and-lvm-on-machine-with-uefi-bios) from stackoverflow seems to be successful)\\n\\n## Set up RAID array\\n\\nTo create a RAID array ready to use in practice, there are always common steps:\\n\\n1. Create a RAID array(RAID 0, RAID 1, RAID 5 or RAID 10)\\n2. Mount the RAID array\\n3. Save the RAID array configuration for system boot\\n\\n### Create RAID array with mdadm\\n\\nCreate **RAID 0** array using devices: `/dev/sda` and `/dev/sdb`\\n\\n```sh\\nsudo mdadm --create --verbose /dev/md0 -l 0 -n 2 /dev/sda /dev/sdb\\n```\\n\\n### Mount RAID array for use\\n\\n1. Create a `ext4` filesystem on the array\\n\\n```sh\\nsudo mkfs.ext4 -F /dev/md0\\n```\\n\\n2. Mount the array\\n\\n```sh\\nsudo mkdir -p /mnt/md0\\n\\nsudo mount /dev/md0 /mnt/md0\\n```\\n\\n### Save RAID array configuration\\n\\nPersist the RAID array configuration to make the system reassemble and mount the RAID array automatically after reboot.\\n\\nAppend the line to `/etc/mdadm/mdadm.conf`:\\n\\n```sh\\nsudo mdadm --detail --scan | sudo tee -a /etc/mdadm/mdadm.conf\\n```\\n\\nMake RAID array available in early boot stage:\\n\\n```sh\\nsudo update-initramfs -u\\n```\\n\\nPersist the mount point, edit `/etc/fstab`:\\n\\n```conf title=\\"/etc/fstab\\"\\n/dev/md0  /mnt/md0  ext4  defaults,nofail,discard 0 0\\n```\\n\\nor persist the mount point by using `UUID`, get `UUID` of the disk drive,\\n\\n```sh\\n$ blkid /dev/md124\\n/dev/md124: UUID=\\"b7fa44f2-0f05-47a1-b4ef-e9ad306898de\\" BLOCK_SIZE=\\"4096\\" TYPE=\\"ext4\\"\\n```\\n\\nthen edit in `/etc/fstab`,\\n\\n```conf title=\\"/etc/fstab\\"\\nUUID=b7fa44f2-0f05-47a1-b4ef-e9ad306898de  /volume  ext4  defaults,nofail,discard 0 0\\n```\\n\\nfinally apply the new mount,\\n\\n```sh\\nsudo mount -a\\n```\\n\\n## Delete RAID Array with mdadm\\n\\nMake sure to remove what are using the RAID array,\\n\\n[Optional] Umount the array from filesystem if mounted,\\n\\n```sh\\nsudo umount /dev/md0\\n```\\n\\nStop RAID array,\\n\\n```sh\\nsudo mdadm --stop /dev/md0\\n# Stop all arrays\\nsudo mdadm --stop --scan\\n```\\n\\nRemoves the RAID metadata and resets them to normal on the **Drives**,\\n\\n```sh\\nsudo mdadm --zero-superblock /dev/sda\\nsudo mdadm --zero-superblock /dev/sd[a-h]\\n```\\n\\n[Optional] Remove any persistent references to the array if exist. Edit the `/etc/fstab`:\\n\\n```sh title=\\"/etc/fstab\\"\\nsudo nano /etc/fstab\\n```\\n\\n[Optional] Also, remove the array definition if exist, from the `/etc/mdadm/mdadm.conf` file:\\n\\n```sh title=\\"/etc/mdadm/mdadm.conf\\"\\nsudo nano /etc/mdadm/mdadm.conf\\n```\\n\\n## Manage RAID Array with mdadm\\n\\n### Find the RAID arrays\\n\\n```sh\\n$ cat /proc/mdstat\\n\\nPersonalities : [raid1] [linear] [multipath] [raid0] [raid6] [raid5] [raid4] [raid10] \\nmd126 : active raid1 nvme0n1[1] nvme1n1[0]\\n      3800741888 blocks super external:/md127/0 [2/2] [UU]\\n      \\nmd127 : inactive nvme0n1[1](S) nvme1n1[0](S)\\n      10402 blocks super external:imsm\\n       \\nunused devices: <none>\\n```\\n\\n### Query information on RAID array\\n\\n```sh\\nsudo mdadm --detail /dev/md0\\nsudo mdadm --query /dev/md0\\n```\\n\\n### Query information on individual physical devices\\n\\n```sh\\nsudo mdadm --query /dev/sda\\nsudo mdadm --examine /dev/sda\\n```\\n\\n### Stop RAID array\\n\\n```sh\\nsudo mdadm --stop /dev/md0\\n# Stop all arrays\\nsudo mdadm --stop --scan\\n```\\n\\n### Start an RAID array\\n\\n```sh\\n# This works if the array is defined in the configuration `/etc/mdadm/mdadm.conf` file.\\nsudo mdadm --assemble --scan\\nsudo mdadm --assemble /dev/md0\\n# If the array is not persisted in `/etc/mdadm/mdadm.conf` file but keeping RAID metadata\\nsudo mdadm --assemble /dev/md0 /dev/sda /dev/sdb\\n```\\n\\n### Add a spare device to an RAID array\\n\\n```sh\\nsudo mdadm /dev/md0 --add /dev/sde\\n```\\n\\n### Check block devices\\n\\n```sh\\n$ lsblk -f\\nNAME        FSTYPE          FSVER  LABEL UUID                                 FSAVAIL FSUSE% MOUNTPOINTS\\nloop0       squashfs        4.0                                                     0   100% /snap/core20/1974\\nloop1       squashfs        4.0                                                     0   100% /snap/lxd/24322\\nloop2       squashfs        4.0                                                     0   100% /snap/snapd/19457\\nsda         isw_raid_member 1.3.00                                                           \\nsdb         isw_raid_member 1.3.00                                                           \\nsdc         isw_raid_member 1.3.00                                                           \\nsdd         isw_raid_member 1.3.00                                                           \\nsde         isw_raid_member 1.3.00                                                           \\nsdf         isw_raid_member 1.3.00                                                           \\nsdg         isw_raid_member 1.3.00                                                           \\nsdh         isw_raid_member 1.3.00                                                           \\nnvme0n1     isw_raid_member 1.3.00                                                           \\n\u251c\u2500md126                                                                                      \\n\u2502 \u251c\u2500md126p1 vfat            FAT32        292B-DB66                                 1G     1% /boot/efi\\n\u2502 \u2514\u2500md126p2 ext4            1.0          0f58386c-334d-4877-8051-b855bae37fb0    3.3T     0% /\\n\u2514\u2500md127                                                                                      \\nnvme1n1     isw_raid_member 1.3.00                                                           \\n\u251c\u2500md126                                                                                      \\n\u2502 \u251c\u2500md126p1 vfat            FAT32        292B-DB66                                 1G     1% /boot/efi\\n\u2502 \u2514\u2500md126p2 ext4            1.0          0f58386c-334d-4877-8051-b855bae37fb0    3.3T     0% /\\n\u2514\u2500md127                         \\n```\\n\\n### List UUID of devices\\n\\n```sh\\n$ sudo blkid\\n/dev/sdf: TYPE=\\"isw_raid_member\\"\\n/dev/nvme0n1: TYPE=\\"isw_raid_member\\"\\n/dev/sdd: TYPE=\\"isw_raid_member\\"\\n/dev/sdb: TYPE=\\"isw_raid_member\\"\\n/dev/sdg: TYPE=\\"isw_raid_member\\"\\n/dev/sde: TYPE=\\"isw_raid_member\\"\\n/dev/sdc: TYPE=\\"isw_raid_member\\"\\n/dev/md126p2: UUID=\\"ff1f3640-e590-486b-8570-c34dfd7bd1de\\" BLOCK_SIZE=\\"4096\\" TYPE=\\"ext4\\" PARTUUID=\\"07473e4a-9324-435d-9238-cf358cd9a6a9\\"\\n/dev/md126p1: UUID=\\"A636-3441\\" BLOCK_SIZE=\\"512\\" TYPE=\\"vfat\\" PARTUUID=\\"7eb27871-d9ad-4132-af06-7110948faf06\\"\\n/dev/nvme1n1: TYPE=\\"isw_raid_member\\"\\n/dev/sda: TYPE=\\"isw_raid_member\\"\\n/dev/md124: UUID=\\"b7fa44f2-0f05-47a1-b4ef-e9ad306898de\\" BLOCK_SIZE=\\"4096\\" TYPE=\\"ext4\\"\\n/dev/sdh: TYPE=\\"isw_raid_member\\"\\n/dev/loop1: TYPE=\\"squashfs\\"\\n/dev/loop4: TYPE=\\"squashfs\\"\\n/dev/loop2: TYPE=\\"squashfs\\"\\n/dev/loop0: TYPE=\\"squashfs\\"\\n/dev/loop3: TYPE=\\"squashfs\\"\\n```\\n\\n### Partition a disk\\n\\n```sh\\nsudo fdisk -l /dev/sda\\n```\\n\\n### Create filesystem on disk\\n\\n```sh\\nsudo mkfs.ext4 -F /dev/sda\\n```\\n\\n### Delete partition and data in disk\\n\\n```sh\\nsudo dd if=/dev/zero of=/dev/sda  bs=512  count=1\\n```"},{"id":"/awesome-troubleshooting","metadata":{"permalink":"/blog/awesome-troubleshooting","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/awesome-troubleshooting.md","source":"@site/../../blog/awesome-troubleshooting.md","title":"Awesome Troubleshooting","description":"Awesome Troubleshooting","date":"2023-08-14T00:00:00.000Z","formattedDate":"August 14, 2023","tags":[{"label":"Awesome Troubleshooting","permalink":"/blog/tags/awesome-troubleshooting"}],"readingTime":0.095,"hasTruncateMarker":false,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["Awesome Troubleshooting"],"description":"Awesome Troubleshooting","keywords":["best-practice","troubleshooting"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-08-14T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"RAID on Ubuntu","permalink":"/blog/raid-on-ubuntu"},"nextItem":{"title":"Keyboard Shortcut Collection","permalink":"/blog/keyboard-shortcut-collection"}},"content":"A curated collection of troubleshooting practices:\\n\\n[How we spent two weeks hunting an NFS bug in the Linux kernel](https://about.gitlab.com/blog/2018/11/14/how-we-spent-two-weeks-hunting-an-nfs-bug/)"},{"id":"/keyboard-shortcut-collection","metadata":{"permalink":"/blog/keyboard-shortcut-collection","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/keyboard-shortcut-collection.md","source":"@site/../../blog/keyboard-shortcut-collection.md","title":"Keyboard Shortcut Collection","description":"Keyboard Shortcut Collection","date":"2023-08-13T00:00:00.000Z","formattedDate":"August 13, 2023","tags":[{"label":"best practice","permalink":"/blog/tags/best-practice"}],"readingTime":0.05,"hasTruncateMarker":false,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["best practice"],"description":"Keyboard Shortcut Collection","keywords":["Keyboard Shortcut Collection"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-08-13T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Awesome Troubleshooting","permalink":"/blog/awesome-troubleshooting"},"nextItem":{"title":"Set Up Samba Server in Docker","permalink":"/blog/docker-setup-samba-server"}},"content":"[VS Code Keyboard Shortcuts Macos](https://code.visualstudio.com/shortcuts/keyboard-shortcuts-macos.pdf)\\n\\n[VS Code Keyboard Shortcuts Windows](https://code.visualstudio.com/shortcuts/keyboard-shortcuts-windows.pdf)"},{"id":"/docker-setup-samba-server","metadata":{"permalink":"/blog/docker-setup-samba-server","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/docker-setup-samba-server.mdx","source":"@site/../../blog/docker-setup-samba-server.mdx","title":"Set Up Samba Server in Docker","description":"Set Up Samba Server in Docker","date":"2023-08-12T00:00:00.000Z","formattedDate":"August 12, 2023","tags":[{"label":"docker","permalink":"/blog/tags/docker"},{"label":"samba","permalink":"/blog/tags/samba"}],"readingTime":3.01,"hasTruncateMarker":false,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["docker","samba"],"description":"Set Up Samba Server in Docker","keywords":["Set Up Samba Server in Docker"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-08-12T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Keyboard Shortcut Collection","permalink":"/blog/keyboard-shortcut-collection"},"nextItem":{"title":"Docker Cheat Sheet","permalink":"/blog/cheatsheet-docker"}},"content":"**!IMPORTANT**: Permission setting is very annoying but critical, sometimes you need take long time to fine tune it and debug.\\n**!IMPORTANT**: When setting up a Samba server in Docker in OSX, you will encounter problems such as `Operation not suppored` when using `bind mount`. Roughly saying, the reason is Docker run in a light VM in Mac and your Mac host uses a different file system(HFS+) compared to Linux(ext4 or similar). So switching to `volume mount` will solve this potential problem.\\n\\nSome takeaways about Permission:\\n\\n- Creating and deleting files is controlled by permissions on the directory.\\n- Modifying the file is controlled by permissions on the file. You may have a mask which is removing the write privilege from the file.\\n\\nWhen I turned to set up Samba server locally, the main purpose is that I would like to integrate the Samba server into my Docker Compose project to mock a real remote Samba server, which will facilitate your local development in Docker environment.\\n\\nSo this blog will illustrate to set up a Samba server and a client, and test interaction between them.\\n\\n## Start Samba Server in Docker\\n\\nHere, we use Samba server image from [dperson/samba](https://hub.docker.com/r/dperson/samba). Although there is an alternative from [ghcr.io/servercontainers/samba](https://hub.docker.com/r/servercontainers/samba) or [crazymax/samba](https://github.com/crazy-max/docker-samba)\\n\\nIn OSX, it\'s critical to use `volume mount` and avoid using `bind mount` as we mentioned above.\\n\\n:::note\\nIn OSX, due to the docker desktop itself is running in VM, it will cause some error like `Operation not supported` when binding a local file folder via `bind mount` even you set `777` mask on the folder. So it\'s recommended to use `volume mount` to bind to `/mnt` in Samba server in OSX.\\n\\nFurthermore, the Samba server will log such message: `error reading meta xattr: Not supported`.\\n:::\\n\\nIn Linux, it\'s okay to use either `volume mount` or `bind mount`.  \\n\\n```sh\\ndocker run -it --rm \\\\\\n    --name samba \\\\\\n    -p 139:139 -p 445:445 \\\\\\n    -v mnt:/mnt:z \\\\\\n    dperson/samba \\\\\\n    -p -s \\"Mount;/mnt;yes;no;yes\\" -u \\"bob;bobspasswd\\" -g \\"log level = 5\\"\\n```\\n\\n:::note\\n`-s \\"<Mount;/mnt>;yes;no;yes\\"` means [browsable:yes;readonly:no;guest:yes]\\", which will allow the guest to `read` and the user to `read/write`!\\n:::\\n\\n\\nGet the samba server IP address:\\n\\n```sh\\n$ docker inspect \\\\\\n    -f \'{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}\' \\\\\\n    samba\\n172.17.0.2\\n```\\n\\n## Start Samba Client in Docker\\n\\nUse `dperson/samba` or `busybox` image,\\n\\n```sh\\ndocker run -it --rm --privileged dperson/samba bash\\n```\\n\\nor\\n\\n```sh\\ndocker run -it --rm --privileged busybox sh\\n```\\n\\nInside the container:\\n\\n```sh\\nmkdir /smb_share\\n\\n# mount -t cifs //[server-ip]/[share-path] /[mount-point]\\nmount -t cifs //172.17.0.2/Mount /smb_share -o rw,username=bob,password=bobspasswd\\n\\n# write file\\necho \\"xxxx\\" > /smb_share/f.txt\\n```\\n\\n## Start Samba Client which Create Volume in Docker\\n\\n1. Create a CIFS/Samba Volume\\n\\n```sh\\ndocker volume create \\\\\\n    --driver local \\\\\\n    --opt type=cifs \\\\\\n    --opt device=//172.17.0.2/Mount \\\\\\n    --opt o=username=bob,password=bobspasswd \\\\\\n    --name samba-volume\\n```\\n\\n```sh\\n$ docker inspect samba-volume\\n[\\n    {\\n        \\"CreatedAt\\": \\"2023-08-13T16:24:03Z\\",\\n        \\"Driver\\": \\"local\\",\\n        \\"Labels\\": null,\\n        \\"Mountpoint\\": \\"/var/lib/docker/volumes/samba-volume/_data\\",\\n        \\"Name\\": \\"samba-volume\\",\\n        \\"Options\\": {\\n            \\"device\\": \\"//172.17.0.2/Mount\\",\\n            \\"o\\": \\"addr=username=bob,password=bobspasswd\\",\\n            \\"type\\": \\"cifs\\"\\n        },\\n        \\"Scope\\": \\"local\\"\\n    }\\n]\\n```\\n\\n2. Start a container using the created volume `samba-volume`.\\n\\n```sh\\ndocker run -it --rm \\\\\\n    -v samba-volume:/mnt \\\\\\n    busybox \\\\\\n    sh\\n```\\n\\n## Use Case in Docker Compose\\n\\n[](../code-snippets/docker-compose/samba/docker-compose.yml)\\n\\nimport CodeBlock from \'@theme/CodeBlock\';\\nimport CodeSource from \'!!raw-loader!../code-snippets/docker-compose/samba/docker-compose.yml\';\\n\\n<CodeBlock language=\\"yaml\\" title=\\"docker-compose-samba.yml\\">{CodeSource}</CodeBlock>\\n\\n\\n## Troubleshooting\\n\\nWhen you mount an Samba Share in Linux, you may encounter error like `failed: Invalid argument`,\\n\\n```sh\\nbash-5.1# mount -t cifs //172.17.0.2/Mount /mnt/smb_share -o iocharset=utf8,rw,vers=1.0\\nmount: mounting //172.17.0.2/Mount on /mnt/smb_share failed: Invalid argument\\n```\\n\\nYou can use `dmesg` to debug,\\n\\n```sh\\nbash-5.1# dmesg\\n[317258.750535] CIFS: Attempting to mount \\\\\\\\172.17.0.2\\\\Mount\\n[317258.752956] CIFS: VFS: No username specified\\n[317336.240984] cifs: Unknown parameter \'passwd\'\\n[317344.451345] CIFS: Attempting to mount \\\\\\\\172.17.0.2\\\\Mount\\n```"},{"id":"/cheatsheet-docker","metadata":{"permalink":"/blog/cheatsheet-docker","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/cheatsheet-docker.md","source":"@site/../../blog/cheatsheet-docker.md","title":"Docker Cheat Sheet","description":"Docker Useful Commands","date":"2023-08-11T00:00:00.000Z","formattedDate":"August 11, 2023","tags":[{"label":"docker","permalink":"/blog/tags/docker"},{"label":"docker compose","permalink":"/blog/tags/docker-compose"},{"label":"best practice","permalink":"/blog/tags/best-practice"},{"label":"cheat sheet","permalink":"/blog/tags/cheat-sheet"}],"readingTime":1.72,"hasTruncateMarker":false,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["docker","docker compose","best practice","cheat sheet"],"description":"Docker Useful Commands","keywords":["docker","docker compose","cheatsheet"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-08-11T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Set Up Samba Server in Docker","permalink":"/blog/docker-setup-samba-server"},"nextItem":{"title":"Set Up NFS Sever in Docker","permalink":"/blog/docker-setup-nfs-sever"}},"content":"- include `docker` and `docker compose` quick reference\\n- cover most useful commands\\n\\n## Docker\\n\\n### Test image `busybox`\\n\\nFamous `busybox` image that provide many common UNIX utilities for testing.\\n\\n```sh\\ndocker run -it --rm --privileged busybox sh\\n```\\n\\n### Find the IP address of Docker container\\n\\n```sh\\ndocker inspect \\\\\\n    -f \'{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}\' \\\\\\n    nfs\\n```\\n\\n### Delete all containers(include all status of running, stopped, created)\\n\\n```sh\\ndocker rm -f $(docker ps -a -q)\\n```\\n\\n### Delete the container by image name\\n\\n```sh\\ndocker rm -f $(docker ps -a -q  --filter ancestor=<image name here!>)\\n```\\n\\n```sh\\ndrmi() { docker rm -f $(docker ps -a | awk -v i=\\"^$1.*\\" \'{if($2~i){print$1}}\'); }\\n```\\n\\n### Delete all volumes\\n\\n```sh\\ndocker volume rm $(docker volume ls -q)\\n```\\n\\n### Keep container running for for testing and debugging\\n\\n```sh\\n# Use -t(-tty)\\ndocker run --rm -d -t busybox\\n```\\n\\n```sh\\ndocker run --rm -d busybox tail -f /dev/null\\n```\\n\\n```sh\\ndocker run --rm -d busybox sleep infinity\\n```\\n\\n## Docker Compose\\n\\n### Check `docker-compose.yml` rendering\\n\\n```sh\\ndocker compose --env-file .env --env-file .prod.env config\\n```\\n\\n### Rebuild image and restart a service which you specified\\n\\n```sh\\ndocker-compose up --no-deps web-app -d\\n```\\n\\n### Remove a service\\n\\n```sh\\ndocker-compose rm -s -v web-auth\\n```\\n\\n### `env_file` in `docker-compose.yml`\\n\\n- `env_file` equals `environment` functions.\\n- If you use both the `env_file` and `environment` attribute, environment variables set by environment take precedence.\\n- `env_file` not used for variables substitution in `docker-compose.yml` file\\n- `env_file` is not the same as `--env-file` used in `docker-compose --env-file` cli.\\n  - `--env-file .env.prod` will be used for interpolation for `docker-compose.yml` file.\\n\\n[Variables resolved from env_file but not taking effect in docker-compose.yaml](https://forums.docker.com/t/variables-resolved-from-env-file-but-not-taking-effect-in-docker-compose-yaml/105394/2)\\n\\n```sh\\ndocker compose --env-file .env --env-file .prod.env up -d\\n```\\n\\n### Exclude sub folders when mounting a local folder\\n\\nIt\'s very useful when developing a node project. That will help only mount the local source codes while excluding the local `node_modules` folder only in the container.\\n\\n```yml\\nversion: \\"3\\"\\nservices:\\n  node:\\n    image: \\"node:16\\"\\n    working_dir: /home/node/app\\n    volumes:\\n      - ./:/home/node/app\\n      - /home/node/app/node_modules\\n    expose:\\n      - \\"8081\\"\\n    command: \\"npm start\\"\\n```"},{"id":"/docker-setup-nfs-sever","metadata":{"permalink":"/blog/docker-setup-nfs-sever","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/docker-setup-nfs-sever.mdx","source":"@site/../../blog/docker-setup-nfs-sever.mdx","title":"Set Up NFS Sever in Docker","description":"Setup NFS Sever","date":"2023-08-11T00:00:00.000Z","formattedDate":"August 11, 2023","tags":[{"label":"docker","permalink":"/blog/tags/docker"},{"label":"nfs","permalink":"/blog/tags/nfs"}],"readingTime":2.85,"hasTruncateMarker":false,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/setup-nfs-sever.md"},"authors":["frank"],"tags":["docker","nfs"],"description":"Setup NFS Sever","keywords":["Setup NFS Sever"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-08-11T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Docker Cheat Sheet","permalink":"/blog/cheatsheet-docker"},"nextItem":{"title":"Git Best Practices","permalink":"/blog/git-best-practices"}},"content":"This document will introduce to set up a NFS server in Docker container and use another Docker container to act as a Client to test this NFS server.\\n\\n> To set up a **NFS server** in your Host, you can check [NFS server installed and configured](https://phoenixnap.com/kb/ubuntu-nfs-server).\\n\\n## Start Up NFS Server\\n\\nUse docker image [gists/nfs-server](https://hub.docker.com/r/gists/nfs-server) to start up a **NFS server** container.\\n\\nIn OSX, it\'s critical to use `volume mount` and avoid using `bind mount` as we mentioned above.\\n\\nIn Linux, it\'s okay to use either `volume mount` or `bind mount`.  \\n\\n```sh\\ndocker run --rm -d \\\\\\n    --name nfs \\\\\\n    --privileged \\\\\\n    -p 2049:2049 \\\\\\n    -v /tmp/volume:/nfs-share \\\\\\n    -e NFS_DIR=/nfs-share \\\\\\n    -e NFS_OPTION=\\"rw,fsid=0,async,no_subtree_check,no_auth_nlm,insecure,no_root_squash\\" \\\\\\n    gists/nfs-server\\n```\\n\\n:::note\\nBefore we use an old nfs server image [itsthenetwork/nfs-server-alpine](https://hub.docker.com/r/itsthenetwork/nfs-server-alpine/) which was not maintained more than 4 years and not supported natively in platform `linux/arm/v6`.\\n\\n```sh\\ndocker run -it --rm \\\\\\n    --name nfs \\\\\\n    --privileged \\\\\\n    -v /tmp/volume:/nfs-share \\\\\\n    -e SHARED_DIRECTORY=/nfs-share \\\\\\n    -p 2049:2049 \\\\\\n    itsthenetwork/nfs-server-alpine:latest\\n```\\n\\n:::\\n\\n:::note\\nIn OSX, due to the docker desktop itself is running in VM, it will cause some error like `Operation not supported` when binding a local file folder via `bind mount` even you set `777` mask on the folder. So it\'s recommended to use `volume` to bind to `/mnt` in Samba server in OSX.\\n\\nFurthermore, the Samba server will log such message: `error reading meta xattr: Not supported`.\\n:::\\n\\nGet the ip address of the **NFS** server, which will be used later to connect the **NFS** server when mounting in a Docker container client. If you only want to mount the **NFS** server from the host, you can just know the ip address of your host.\\n\\n\\n```sh\\ndocker inspect \\\\\\n    -f \'{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}\' \\\\\\n    nfs\\n```\\n\\nHere the output is\\n\\n```sh\\n172.17.0.2\\n```\\n\\n## Use NFS Client in Docker\\n\\nLet\'s make use of a Docker container to act in a NFS client to access shared data in the running-up NFS server.\\n\\n:::note\\nrun container as root by option `--privileged` or `--cap-add SYS_ADMIN` when permissions denied inside the container:\\n:::\\n\\n```sh\\ndocker run -it --rm --privileged busybox sh\\n```\\n\\nInside the container:\\n\\n:::note\\nDue to the fsid=0 parameter set in the /etc/exports file, there\'s no need to specify the folder name when mounting from a client. For example, this works fine even though the folder being mounted and shared is /nfs-share:\\n:::\\n\\n```sh\\n# In the container\\n\\nmkdir /mnt\\n# nfs v4\\nmount -v -o vers=4,loud 172.17.0.2:/ /mnt\\n\\n# create a file to test\\necho \\"some text here\\" > /mnt/file1.txt\\n```\\n\\nThen go to the Host to list directory `/data/volume/test`, where you will find the `file1.txt` is sitting.\\n\\n```sh\\n# In the host\\ncat /data/volume/test/file1.txt\\n```\\n\\n## Use NFS Client With Volume Mount in Docker\\n\\n1. Create a NFS volume in Docker\\n\\n```sh\\ndocker volume create --driver local \\\\\\n    --opt type=nfs \\\\\\n    --opt o=addr=172.17.0.2,nfsvers=4 \\\\\\n    --opt device=:/ \\\\\\n    nfs-volume\\n```\\n\\n```sh\\ndocker inspect nfs-volume\\n```\\n\\n2. Run the container with the created volume `nfs-volume`.\\n\\n```sh\\ndocker run -it --rm \\\\\\n    --privileged \\\\\\n    --name nfs-test \\\\\\n    -v nfs-volume:/mnt \\\\\\n    busybox \\\\\\n    sh\\n```\\n\\nAlternative, you can use the combined one command which will create a volume `nfsvolume`, \\n\\n```sh\\ndocker run -it --rm \\\\\\n    --privileged \\\\\\n    --name nfs-test \\\\\\n    --mount \'type=volume,source=nfsvolume,volume-driver=local,volume-opt=type=nfs,volume-opt=device=:/,\\"volume-opt=o=addr=172.17.0.2,rw,nfsvers=4,async\\",target=/mnt\' \\\\\\n    busybox \\\\\\n    sh\\n```\\n\\n## Setup a NFS Server and Mount NFS Volume int Docker Compose\\n\\n\\n\\n## About NFS Options\\n\\n[Understanding the /etc/exports File \u2013 The Geek Diary](https://www.thegeekdiary.com/understanding-the-etc-exports-file/)"},{"id":"/git-best-practices","metadata":{"permalink":"/blog/git-best-practices","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/git-best-practices.md","source":"@site/../../blog/git-best-practices.md","title":"Git Best Practices","description":"Git Submodules","date":"2023-08-02T00:00:00.000Z","formattedDate":"August 2, 2023","tags":[{"label":"git","permalink":"/blog/tags/git"},{"label":"git submodules","permalink":"/blog/tags/git-submodules"},{"label":"best practice","permalink":"/blog/tags/best-practice"}],"readingTime":5.175,"hasTruncateMarker":false,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/git-submodules.md"},"authors":["frank"],"tags":["git","git submodules","best practice"],"description":"Git Submodules","keywords":["Git Submodules"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-08-02T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Set Up NFS Sever in Docker","permalink":"/blog/docker-setup-nfs-sever"},"nextItem":{"title":"Share Data between Docker Containers","permalink":"/blog/docker-containers-data-sharing"}},"content":"Global configuration\\n\\n```sh\\ngit config --global --list\\ngit config --local --list\\n```\\n\\n**GIT** two popular authentication methods: [SSH Key](#git-ssh-key) and [Credentials](#git-credentials)\\n\\n## Git SSH key\\n\\n[How to Authenticate Your Git to GitHub with SSH Keys](https://hackernoon.com/how-to-authenticate-your-git-to-github-with-ssh-keys)\\n\\n## Git credential\\n\\nStore username/password instead of ssh for multiple remotes\\n\\nTo enable git credentials\\n\\n```sh\\n# local\\ngit config credential.helper store\\n# global\\ngit config --global credential.helper store\\n```\\n\\nEach credential is stored in `~/.git-credentials` file on its own line as a URL like:\\n\\n```sh\\nhttps://<USERNAME>:<PASSWORD>@github.com\\n```\\n\\nConfigure credentials,\\n\\n```sh\\n# Global\\ngit config --global credential.https://github.com.username <your_username>\\n\\n# Or \\ngit config --local user.name <your_username>\\ngit config --local user.email <your_useremail>\\n# Then git pull or git push to let it cache your username/password after it prompt you to input password in the first time\\n```\\n\\n\\nAlternatively, we can directly edit our global Git config file `~/.gitconfig`,\\n\\n```sh\\n[credential \\"https://github.com\\"]\\n\\tusername = <username>\\n```\\n\\n[Git - Config Username & Password - Store Credentials - ShellHacks](https://www.shellhacks.com/git-config-username-password-store-credentials/)\\n\\n[Configuring Git Credentials](https://www.baeldung.com/ops/git-configure-credentials)\\n\\n## Git submodule\\n\\n1. Pull the repo and its all submodules in **the first time**.\\n\\n```sh\\ngit clone http://10.6.64.66:30000/mtr/mtr.git\\n\\ncd mtr\\n\\ngit submodule update --init --recursive --progress\\n```\\n\\nOr just one command to clone with all the submodules.\\n\\n```sh\\ngit clone --recursive http://10.6.64.66:30000/mtr/mtr.git\\n```\\n\\n2. Pull the repo and its all submodules later\\n\\n```sh\\ngit submodule update --recursive --progress\\n```\\n\\n3. Enter each sub repository to pull its own latest of `main` per repository, when the parent repo does point to the latest branch of its submodules!\\n\\nSometimes, it is very annoying to keep the parent repository up to date on the latest reference of its every sub repository!\\nThis approach give you the flexibility while being like a shortcut.\\n\\n```sh\\ngit submodule foreach git checkout main\\n```\\n\\n```sh\\ngit submodule foreach git pull\\n```\\n\\n```sh\\ngit submodule foreach git pull origin main\\n```\\n\\n```sh\\ngit submodule update --recursive --remote\\n```\\n\\n## Discard local commits\\n\\nAssume your local repo has 10 commits ahead of the `origin/main`, and you want to move back to the `origin/main`.\\n\\n```sh\\ngit reset --hard origin/main\\n```\\n\\n\\n## Create a subdirectory inside Git and use it as Git submodule\\n\\nFirst, create a subdirectory `./include/private` and initialize it as a new Git repository inside Git repo, then push it to remote.\\n\\nOnce done, we\'ll have subdirectory `./include/private` which has been gitted.\\n\\nCheck current parent Git submodule, and our `./include/private` sit outside.\\n\\n```sh\\n$ git submodule\\n-96788d8ac53a815778a8cfd19addb3590a8be5ea code-snippets/assembly\\n-990e3db80c61c64ba9097adb7e729a6568c272ec code-snippets/c\\n-dd2097c0884363948877dea2b3f68efb90e6d204 code-snippets/cpp\\n-a4c753b89c423cd02718bece5a8a6302bd2385c7 code-snippets/docker-compose\\n-e23cfb82c6fefae4fdc6a144228bebb580bf7c13 code-snippets/python\\n```\\n\\n- Option 1, Using `git submodule add` command in **parent** directory(note: works even `./include/private` folder exists):\\n\\n```sh\\ngit submodule add https://github.com/liviaerxin/private.git include/private\\n```\\n\\nFinally, commit,\\n\\n```sh\\ngit commit -m \\"add submodule private\\"\\n```\\n\\n- Option 2, Editing `.gitmodules` file in **parent** directory by adding:\\n\\n```sh title=\\".gitmodules\\"\\n[submodule \\"include/private\\"]\\n\\tpath = include/private\\n\\turl = https://github.com/liviaerxin/private.git\\n```\\n\\nIndexing the submodule,\\n\\n```sh\\ngit add include/private\\n```\\n\\nVerifying that the submodule has been included,\\n\\n```sh\\n$ git submodule\\n-96788d8ac53a815778a8cfd19addb3590a8be5ea code-snippets/assembly\\n-990e3db80c61c64ba9097adb7e729a6568c272ec code-snippets/c\\n-dd2097c0884363948877dea2b3f68efb90e6d204 code-snippets/cpp\\n-a4c753b89c423cd02718bece5a8a6302bd2385c7 code-snippets/docker-compose\\n-e23cfb82c6fefae4fdc6a144228bebb580bf7c13 code-snippets/python\\n-e9e1b5f114e5da1896dae6c08ca01bc83b844b4d include/private\\n```\\n\\nFor managing the submodule,\\n1. Sync local private file: `.git/config` by running `git submodule init`, which will let the submodule update when running `git submodule update` later. \\n\\nFinally, commit,\\n\\n```sh\\ngit commit -m \\"add submodule private\\"\\n```\\n\\nIn conclusion, `git submodule add` equals:\\n\\n1. Run `git clone {submodule} include/{submodule}`.\\n2. Add submodule configuration such as `path = include/{submodule}` and `url=https://github.com/xxx/{submodule}.git` into `.gitmodules` file.\\n3. Add the sub folder `include/{submodule}`: `git add include/{submodule}`.\\n4. Sync `.git/config` file: `git submodule init`.\\n\\nSometimes the warning to the changes of submodules will be annoying, especially if you update submodules frequently.\\n\\nTo ignore all changes to the submodules:\\n\\n```sh title=\\".gitmodules\\"\\n[submodule \\"include/private\\"]\\n\\tpath = include/private\\n\\turl = https://github.com/liviaerxin/private.git\\n  ignore = all\\n```\\n\\nOnce you have ignored changes in a submodule, you will no longer see them in the output of the git status command. You will also not be able to commit or push the changes to the submodule.\\n\\nTo view the changes in the submodule, you can use the git submodule summary command. This command will show you a summary of the changes in the submodule, even if they are ignored.\\n\\nOnce you have unignored changes in a submodule, you will be able to see them in the output of the git status command and you will be able to commit and push the changes to the submodule.\\n\\nHere are some additional things to keep in mind when ignoring changes in a submodule:\\n- Ignoring changes in a submodule does not prevent you from updating the submodule. You can still use the git submodule update command to update the submodule to the latest version.\\n- Ignoring changes in a submodule does not prevent you from cloning the submodule. You can still use the git submodule clone command to clone the submodule into another repository.\\n- Ignoring changes in a submodule does not prevent you from deleting the submodule. You can still use the git submodule deinit command to delete the submodule from your repository.\\n\\nOverall, ignoring changes in a submodule can be a useful way to keep your repository clean and organized. However, it is important to understand the implications of ignoring changes before you do so.\\n\\n## Carve out a subdirectory from Git and use it as Git submodule\\n\\n\\n## Git subtree\\n\\nWhen you should consider using a **Git subtree** instead of **Git submodule**?\\n\\nIf you need to manage multiple projects within a single repository as:\\n\\n1. I have a main project for writing blogs\\n2. However, I also manage several projects to maintain my daily coding snippets such as `C`, `Python`, ...etc. \\n  - I want to store these **sub-projects** in the specified sub-folders of my main repository.\\n  - I will update these **sub-projects** frequently.\\n  - I will pull and push changes of these **sub-projects** in local sub working directories.\\n  - I don\'t want to the main repository to warn me the new commits from **sub-projects** every time I update the **sub-projects**.\\n\\nDrawbacks:\\n- To update and commit changes on these **sub-projects** you need to remember some \\"information\\", because the metadata of these **sub-projects** will be not stored in a file like `.gitmodules` in main repo.\\n\\n[About Git subtree merges](https://docs.github.com/en/get-started/using-git/about-git-subtree-merges)\\n\\n[Git Subtree: Alternative to Git Submodule | Atlassian Git Tutorial](https://www.atlassian.com/git/tutorials/git-subtree)"},{"id":"/docker-containers-data-sharing","metadata":{"permalink":"/blog/docker-containers-data-sharing","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/docker-containers-data-sharing.md","source":"@site/../../blog/docker-containers-data-sharing.md","title":"Share Data between Docker Containers","description":"Docker Containers Data Sharing","date":"2023-07-19T00:00:00.000Z","formattedDate":"July 19, 2023","tags":[{"label":"docker","permalink":"/blog/tags/docker"},{"label":"dev-ops","permalink":"/blog/tags/dev-ops"},{"label":"docker-volume","permalink":"/blog/tags/docker-volume"},{"label":"data","permalink":"/blog/tags/data"}],"readingTime":1.69,"hasTruncateMarker":false,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/docker-containers-data-sharing.md"},"authors":["frank"],"tags":["docker","dev-ops","docker-volume","data"],"description":"Docker Containers Data Sharing","keywords":["Docker Containters Data Sharing"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-07-19T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Git Best Practices","permalink":"/blog/git-best-practices"},"nextItem":{"title":"REST API Filtering, Sorting and Pagination","permalink":"/blog/rest-api-filtering-sorting-pagination"}},"content":"There are three types of data to manage data in Docker,\\n\\n- bind mount\\n- volume mount\\n- tmpfs mount\\n\\n![](../attachments/images/types-of-mounts-volume.png)\\n\\nRead [Manage data in Docker](https://docs.docker.com/storage/) for more information, it\'s a great official documentation!\\n\\nHere, this page demonstrates some use cases in practices that you maybe face. As the official documentation says, **Volume** is alway the first choice and preferred mechanism for persisting and sharing data between containers, as one of the biggest advantages is that **volume** is thoroughly managed by Docker. That means:\\n\\n- You can manage **volume** using Docker CLI commands ir the Docker API.\\n- **Volume** is easier to back up and migrate than **bind mounts**.\\n- **Volume** work the same interface in Linux and Windows, such as no need to worry about `POSIX` file path style in Windows.\\n- **Volume** driver features support you to store data on remote hosts or cloud storage easily.\\n- **Volume** on Docker Desktop have much higher performance than bind mount from Mac and Windows hosts.\\n\\nLet\'s look at some use cases that leverage volume **driver** features\\n\\n## Use a volume to bind a local folder\\n\\nIn default, the volume is created by Docker and its corresponding folder resides in Docker managed folder like `/var/lib/docker/volumes/`:\\n\\n```sh\\n$ docker create volume xxx\\n```\\n\\n```sh\\n$ docker volume inspect xxx\\n[\\n    {\\n        \\"CreatedAt\\": \\"2023-07-19T14:41:18+08:00\\",\\n        \\"Driver\\": \\"local\\",\\n        \\"Labels\\": {},\\n        \\"Mountpoint\\": \\"/var/lib/docker/volumes/xxx/_data\\",\\n        \\"Name\\": \\"xxx\\",\\n        \\"Options\\": {},\\n        \\"Scope\\": \\"local\\"\\n    }\\n]\\n```\\n\\nHowever, sometimes you would like to bind the volume into a specified local folder(like `/data/volumes/testvol`) in hosts(only available in `Linux`)\\n\\n```sh\\n$ docker volume create --opt type=none --opt o=bind --opt device=/data/volumes/testvol testvol\\n```\\n\\n```sh\\n$ docker inspect testvol\\n[\\n    {\\n        \\"CreatedAt\\": \\"2023-07-13T04:36:16Z\\",\\n        \\"Driver\\": \\"local\\",\\n        \\"Labels\\": {},\\n        \\"Mountpoint\\": \\"/var/lib/docker/volumes/testvol/_data\\",\\n        \\"Name\\": \\"testvol\\",\\n        \\"Options\\": {\\n            \\"device\\": \\"/data/volumes/testvol\\",\\n            \\"o\\": \\"bind\\",\\n            \\"type\\": \\"none\\"\\n        },\\n        \\"Scope\\": \\"local\\"\\n    }\\n```\\n\\nIn Docker compose yaml,\\n\\n```yml\\nservices:\\n  frontend:\\n    image: node:lts\\n    volumes:\\n      - testvol:/home/node/app\\nvolumes:\\n  db-data:\\n  testvol:\\n    driver: local\\n    driver_opts:\\n      type: none\\n      o: bind\\n      device: /data/volumes/testvol\\n```\\n\\n## Use NFS volume\\n\\n## Use Samba volume\\n\\n## References\\n\\n[Volumes | Docker Documentation](https://docs.docker.com/storage/volumes/#share-data-between-machines)"},{"id":"/rest-api-filtering-sorting-pagination","metadata":{"permalink":"/blog/rest-api-filtering-sorting-pagination","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/rest-api-filtering-sorting-pagination.md","source":"@site/../../blog/rest-api-filtering-sorting-pagination.md","title":"REST API Filtering, Sorting and Pagination","description":"REST API Filtering, Sorting and Pagination","date":"2023-07-18T00:00:00.000Z","formattedDate":"July 18, 2023","tags":[{"label":"backend","permalink":"/blog/tags/backend"},{"label":"best practice","permalink":"/blog/tags/best-practice"},{"label":"rest api","permalink":"/blog/tags/rest-api"},{"label":"filtering","permalink":"/blog/tags/filtering"},{"label":"sorting","permalink":"/blog/tags/sorting"},{"label":"pagination","permalink":"/blog/tags/pagination"}],"readingTime":0.205,"hasTruncateMarker":false,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["backend","best practice","rest api","filtering","sorting","pagination"],"description":"REST API Filtering, Sorting and Pagination","keywords":["rest api","filtering, sorting and pagination"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-07-18T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Share Data between Docker Containers","permalink":"/blog/docker-containers-data-sharing"},"nextItem":{"title":"Learn ASGI","permalink":"/blog/wiki-asgi"}},"content":"[api-guidelines/Guidelines.md at vNext \xb7 microsoft/api-guidelines \xb7 GitHub](https://github.com/microsoft/api-guidelines/blob/vNext/Guidelines.md#971-filter-operations)\\n\\n[REST API Design: Filtering, Sorting, and Pagination | Moesif Blog](https://www.moesif.com/blog/technical/api-design/REST-API-Design-Filtering-Sorting-and-Pagination/)\\n\\n[How we write our query filter engine on our REST API (part 1) | by Adam Ben Aharon | Melio\u2019s R&D blog | Medium](https://medium.com/meliopayments/how-we-write-our-query-filter-engine-on-our-rest-api-part-1-441cb13dcc15)"},{"id":"/wiki-asgi","metadata":{"permalink":"/blog/wiki-asgi","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-asgi.mdx","source":"@site/../../blog/wiki-asgi.mdx","title":"Learn ASGI","description":"Learn ASGI","date":"2023-07-11T00:00:00.000Z","formattedDate":"July 11, 2023","tags":[{"label":"backend","permalink":"/blog/tags/backend"},{"label":"asgi","permalink":"/blog/tags/asgi"},{"label":"wiki","permalink":"/blog/tags/wiki"}],"readingTime":0.895,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/wiki-asgi.md"},"authors":["frank"],"tags":["backend","asgi","wiki"],"description":"Learn ASGI","keywords":["Learn ASGI"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-07-11T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"REST API Filtering, Sorting and Pagination","permalink":"/blog/rest-api-filtering-sorting-pagination"},"nextItem":{"title":"C/C++ Build System","permalink":"/blog/c-build-system"}},"content":"Nowadays as web server framework is getting easy to use and work with. In Python areas, FastAPI obtains nearly 60k stars and becomes the most popular web framework for Pythoners.\\n\\nLooking at the advantage of `FastAPI`, it simplifies everything from parsing http requests, middleware processing, authentication, database manipulation and more.\\n\\nLet\'s dive into the behind-the-scenes technique stacks of `FastAPI`.\\n\x3c!--truncate--\x3e\\nBefore research, there are some common questions around the web server development:\\n\\n- How to process messages on `HTTP` protocol on `TCP` protocol? What\'re the favorite library used to do that?\\n- What are the differences between `WSGI` and `ASGI`?\\n- Data model used for database and users\\n\\n\\nstacks from low-level to high-level\\n\\nUvicorn:\\n\\n- ASGI web server implementation/interface\\n  - scope\\n  - receive\\n  - send\\n- h11 to process HTTP messages\\n- websocket to process websocket messages\\n\\nStarlette:\\n\\n- ASGI framework\\n- abstract Request class for receive in `Uvicorn`\\n- abstract Response class for send in `Uvicorn`\\n- provide middleware\\n\\nFastAPI:\\n\\n- Fast to code\\n- OpenAPI docs\\n- Pydantic native model\\n\\n`APIRoute`\\n\\n`APIRouter`\\n\\n`Application` <-- `APIRouter` <-- `APIRoute`"},{"id":"/c-build-system","metadata":{"permalink":"/blog/c-build-system","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/c-build-system.md","source":"@site/../../blog/c-build-system.md","title":"C/C++ Build System","description":"Learn Avalonia","date":"2023-07-07T00:00:00.000Z","formattedDate":"July 7, 2023","tags":[{"label":"make","permalink":"/blog/tags/make"},{"label":"ninja","permalink":"/blog/tags/ninja"},{"label":"msbuild","permalink":"/blog/tags/msbuild"},{"label":"cmake","permalink":"/blog/tags/cmake"},{"label":"meson","permalink":"/blog/tags/meson"},{"label":"ci-cd","permalink":"/blog/tags/ci-cd"}],"readingTime":0.685,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["make","ninja","msbuild","cmake","meson","ci-cd"],"description":"Learn Avalonia","keywords":["practice","avalonia"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-07-07T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Learn ASGI","permalink":"/blog/wiki-asgi"},"nextItem":{"title":"Resumable Upload","permalink":"/blog/resumable-upload"}},"content":"[List of build automation software - Wikipedia](https://en.wikipedia.org/wiki/List_of_build_automation_software)\\n\\n\x3c!--truncate--\x3e\\n\\n```plantuml\\n@startuml\\nskinparam nodesep 50\\nskinparam ranksep 100\\n\\n!include <material/common>\\n!include <material/code_braces>\\n!include <material/code_array>\\n!include <material/code_brackets>\\n!include <material/code_parentheses>\\n!include <material/code_tags>\\n\\ntogether {\\nfolder \\"Project\\" as source <<Source Code>> {\\n    file sourcefile[\\n        *.cpp\\n        *.c\\n        *.h\\n        <$ma_code_braces>\\n    ]\\n}\\n\\ncomponent \\"CMake\\" as cmake {\\n    file cmakefiles[\\n        CMakefiles.txt\\n        <$ma_code_braces>\\n    ]\\n}\\n}\\n\\ncomponent \\"Make\\" as make {\\n    file makefile[\\n        Makefile\\n        <$ma_code_braces>\\n    ]\\n}\\n\\ncomponent \\"MSBuild\\" as msbuild {\\n    file msbuildfile[\\n        .vcproj\\n        <$ma_code_braces>\\n    ]\\n}\\n\\npackage \\"Windows Application\\" as wa <<.exe>> <<*.DLL>> {\\n}\\n\\npackage \\"Unix Application\\" as ua <<.>> <<*.so>> {\\n}\\n\\n\\n\\ncmake --\x3e make: Generator: Make\\ncmake --\x3e msbuild : Generator: Visual Studio 2022\\n\\nsource --\x3e wa\\nmsbuild --\x3e wa\\n\\nsource --\x3e ua\\nmake --\x3e ua\\n```\\n\\n## Build System\\n\\nMake\\n\\nNinja\\n\\nMSBuild\\n\\n## Build System Generator\\n\\nCMake\\n\\nMeson\\n\\n## CI"},{"id":"/resumable-upload","metadata":{"permalink":"/blog/resumable-upload","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/resumable-upload.md","source":"@site/../../blog/resumable-upload.md","title":"Resumable Upload","description":"Resumable Upload","date":"2023-07-07T00:00:00.000Z","formattedDate":"July 7, 2023","tags":[{"label":"fastapi","permalink":"/blog/tags/fastapi"},{"label":"backend","permalink":"/blog/tags/backend"},{"label":"protocol","permalink":"/blog/tags/protocol"},{"label":"tus","permalink":"/blog/tags/tus"}],"readingTime":0.71,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/resumable-upload.md"},"authors":["frank"],"tags":["fastapi","backend","protocol","tus"],"description":"Resumable Upload","keywords":["file upload","resumable"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-07-07T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"C/C++ Build System","permalink":"/blog/c-build-system"},"nextItem":{"title":"Wiki Avalonia","permalink":"/blog/wiki-avalonia"}},"content":"To implement a resumable file upload, it is necessary to contain three parts:\\n\\n- Protocol: provide a mechanism for resumable file uploads\\n- Upload Server: receive an interrupted upload and store it in local machine or in cloud storage\\n- Upload Client: upload the file which may be interrupted\\n\\n\x3c!--truncate--\x3e\\n\\n## A Basic Resumable Upload\\n\\n```js reference\\nhttps://github.com/liviaerxin/hello-python/blob/main/app_resumable_upload.py\\n```\\n\\n## TUS Resumable Upload\\n\\nFastAPI implementing tus v1.0.0 server in Python\\n\\n```js reference\\nhttps://github.com/liviaerxin/hello-python/blob/main/app_tusd.py\\n```\\n\\n\\n[Implementations | tus.io](https://tus.io/implementations)\\n\\n[Resumable file upload](https://javascript.info/resume-upload)\\n\\n[GitHub - tus/tus-js-client: A pure JavaScript client for the tus resumable upload protocol](https://github.com/tus/tus-js-client)\\n\\n[GitHub - tus/tusd: Reference server implementation in Go of tus: the open protocol for resumable file uploads](https://github.com/tus/tusd)\\n\\nIO, StreamIO, FileIO\\n\\nhigh-level used by asyncio.io in socket/tcp/http\\n\\n[Streams \u2014 Python 3.11.4 documentation](https://docs.python.org/3/library/asyncio-stream.html#streamreader)\\n\\nstarlette.Request.stream = http Request Body\\n\\nlow-level:  \\n[io \u2014 Core tools for working with streams \u2014 Python 3.11.4 documentation](https://docs.python.org/3/library/io.html#io.RawIOBase)"},{"id":"/wiki-avalonia","metadata":{"permalink":"/blog/wiki-avalonia","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-avalonia.md","source":"@site/../../blog/wiki-avalonia.md","title":"Wiki Avalonia","description":"Learn Avalonia","date":"2023-07-07T00:00:00.000Z","formattedDate":"July 7, 2023","tags":[{"label":"practice","permalink":"/blog/tags/practice"},{"label":"avalonia","permalink":"/blog/tags/avalonia"}],"readingTime":0.42,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"tags":["practice","avalonia"],"description":"Learn Avalonia","keywords":["practice","avalonia"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-07-07T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Resumable Upload","permalink":"/blog/resumable-upload"},"nextItem":{"title":"MDX Features of Docusaurus","permalink":"/blog/docusaurus-mdx-features"}},"content":"\x3c!--truncate--\x3e\\n\\n[skiasharp - Is it possible to create a Skia Canvas element in an Avalonia application? - Stack Overflow](https://stackoverflow.com/questions/61627374/is-it-possible-to-create-a-skia-canvas-element-in-an-avalonia-application)\\n\\n[Poor rendering performance of Image control \xb7 Issue #2849 \xb7 AvaloniaUI/Avalonia \xb7 GitHub](https://github.com/AvaloniaUI/Avalonia/issues/2849)\\n\\n[How to render a window with an OpenGlControl to RenderTargetBitmap? \xb7 Discussion #7772 \xb7 AvaloniaUI/Avalonia \xb7 GitHub](https://github.com/AvaloniaUI/Avalonia/discussions/7772)\\n\\n[Missing WriteableBitmap.WritePixels? \xb7 Discussion #7661 \xb7 AvaloniaUI/Avalonia \xb7 GitHub](https://github.com/AvaloniaUI/Avalonia/discussions/7661)\\n\\n[Enable GPU-backed images for the Skia backend by mstr2 \xb7 Pull Request #2858 \xb7 AvaloniaUI/Avalonia \xb7 GitHub](https://github.com/AvaloniaUI/Avalonia/pull/2858)\\n\\n## SkiaSharp\\n\\n[SkiaSharp/GRContextTest.cs at main \xb7 mono/SkiaSharp \xb7 GitHub](https://github.com/mono/SkiaSharp/blob/main/tests/Tests/GRContextTest.cs)"},{"id":"/docusaurus-mdx-features","metadata":{"permalink":"/blog/docusaurus-mdx-features","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/docusaurus-mdx-features.mdx","source":"@site/../../blog/docusaurus-mdx-features.mdx","title":"MDX Features of Docusaurus","description":"MDX Features","date":"2023-07-06T00:00:00.000Z","formattedDate":"July 6, 2023","tags":[{"label":"mdx","permalink":"/blog/tags/mdx"},{"label":"docusaurus","permalink":"/blog/tags/docusaurus"},{"label":"react","permalink":"/blog/tags/react"},{"label":"best practice","permalink":"/blog/tags/best-practice"}],"readingTime":4.22,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"description":"MDX Features","authors":["frank"],"tags":["mdx","docusaurus","react","best practice"],"keywords":["mdx features in docusaurus"],"image":"https://i.imgur.com/mErPwqL.png","date":"2023-07-06T00:00:00.000Z"},"prevItem":{"title":"Wiki Avalonia","permalink":"/blog/wiki-avalonia"},"nextItem":{"title":"FFmpeg Command Samples","permalink":"/blog/ffmpeg-command-samples"}},"content":"\x3c!--truncate--\x3e\\n\\n## React Component\\n\\nCode as:\\n\\n```jsx title=\\"docs/mdx-features.mdx\\"\\nexport const Highlight = ({children, color}) => (\\n  <span\\n    style={{\\n      backgroundColor: color,\\n      borderRadius: \'2px\',\\n      color: \'#fff\',\\n      padding: \'0.2rem\',\\n    }}>\\n    {children}\\n  </span>\\n);\\n\\n<Highlight color=\\"#25c2a0\\">Docusaurus green</Highlight> and <Highlight color=\\"#1877F2\\">Facebook blue</Highlight> are my favorite colors.\\n```\\n\\nRender as:\\n\\nexport const Highlight = ({children, color}) => (\\n  <span\\n    style={{\\n      backgroundColor: color,\\n      borderRadius: \'2px\',\\n      color: \'#fff\',\\n      padding: \'0.2rem\',\\n    }}>\\n    {children}\\n  </span>\\n);\\n\\n<Highlight color=\\"#25c2a0\\">Docusaurus green</Highlight> and <Highlight color=\\"#1877F2\\">Facebook blue</Highlight> are my favorite colors.\\n\\n<br/><br/><br/>\\n\\nCode as:\\n\\n```jsx title=\\"src/components/Highlight\\"\\nimport React from \'react\';\\n\\nexport default function SharedHighlight({children, color}) {\\n  return (\\n    <span\\n      style={{\\n        backgroundColor: color,\\n        borderRadius: \'2px\',\\n        color: \'#fff\',\\n        padding: \'0.2rem\',\\n      }}>\\n      {children}\\n    </span>\\n  );\\n}\\n```\\nWith:\\n```jsx title=\\"docs/mdx-features.mdx\\"\\nimport SharedHighlight from \'@site/src/components/Highlight\';\\n\\n<SharedHighlight color=\\"#25c2a0\\">Docusaurus green</SharedHighlight>\\nI can write **Markdown** alongside my _JSX_!\\n```\\n\\nRender as:\\n\\nimport SharedHighlight from \'@site/src/components/Highlight\';\\n\\n<SharedHighlight color=\\"#25c2a0\\">Docusaurus green</SharedHighlight>\\n\\nI can write **Markdown** alongside my _JSX_!\\n\\n## Tabs\\n\\nCode as:\\n\\n```jsx title=\\"docs/mdx-features.mdx\\"\\nimport Tabs from \'@theme/Tabs\';\\nimport TabItem from \'@theme/TabItem\';\\n\\n<Tabs>\\n  <TabItem value=\\"apple\\" label=\\"Apple\\" default>\\n    This is an apple \ud83c\udf4e\\n  </TabItem>\\n  <TabItem value=\\"orange\\" label=\\"Orange\\">\\n    This is an orange \ud83c\udf4a\\n  </TabItem>\\n  <TabItem value=\\"banana\\" label=\\"Banana\\">\\n    This is a banana \ud83c\udf4c\\n  </TabItem>\\n</Tabs>\\n```\\n\\nRender as:\\n\\nimport Tabs from \'@theme/Tabs\';\\nimport TabItem from \'@theme/TabItem\';\\n\\n<Tabs>\\n  <TabItem value=\\"apple\\" label=\\"Apple\\" default>\\n    This is an apple \ud83c\udf4e\\n  </TabItem>\\n  <TabItem value=\\"orange\\" label=\\"Orange\\">\\n    This is an orange \ud83c\udf4a\\n  </TabItem>\\n  <TabItem value=\\"banana\\" label=\\"Banana\\">\\n    This is a banana \ud83c\udf4c\\n  </TabItem>\\n</Tabs>\\n\\n## NOTES\\n\\n```mdx title=\\"docs/mdx-features.mdx\\"\\n\x3c!-- Prettier doesn\'t change this --\x3e\\n:::note\\n\\nHello world\\n\\n:::\\n```\\n\\n:::note\\n\\nHello world\\n\\n:::\\n\\n```md\\n\x3c!-- Prettier changes this --\x3e\\n:::note\\nHello world\\n:::\\n```\\n\\n```md\\n\x3c!-- to this --\x3e\\n::: note Hello world:::\\n```\\n\\n```md title=\\"docs/mdx-features.mdx\\"\\n:::note Your Title\\n\\nSome **content** with _Markdown_ `syntax`.\\n\\n:::\\n```\\n\\n:::note Your Title\\n\\nSome **content** with _Markdown_ `syntax`.\\n\\n:::\\n\\n\\n```md title=\\"docs/mdx-features.mdx\\"\\n:::tip Use tabs in admonitions\\n\\n<Tabs>\\n  <TabItem value=\\"apple\\" label=\\"Apple\\">This is an apple \ud83c\udf4e</TabItem>\\n  <TabItem value=\\"orange\\" label=\\"Orange\\">This is an orange \ud83c\udf4a</TabItem>\\n  <TabItem value=\\"banana\\" label=\\"Banana\\">This is a banana \ud83c\udf4c</TabItem>\\n</Tabs>\\n\\n:::\\n```\\n\\n:::tip Use tabs in admonitions\\n\\n<Tabs>\\n  <TabItem value=\\"apple\\" label=\\"Apple\\">This is an apple \ud83c\udf4e</TabItem>\\n  <TabItem value=\\"orange\\" label=\\"Orange\\">This is an orange \ud83c\udf4a</TabItem>\\n  <TabItem value=\\"banana\\" label=\\"Banana\\">This is a banana \ud83c\udf4c</TabItem>\\n</Tabs>\\n\\n:::\\n\\n## Math\\n\\n\\n```mdx title=\\"docs/mdx-features.mdx\\"\\nLet $f\\\\colon[a,b]\\\\to\\\\R$ be Riemann integrable. Let $F\\\\colon[a,b]\\\\to\\\\R$ be\\n$F(x)=\\\\int_{a}^{x} f(t)\\\\,dt$. Then $F$ is continuous, and at all $x$ such that\\n$f$ is continuous at $x$, $F$ is differentiable at $x$ with $F\'(x)=f(x)$.\\n```\\n\\nLet $f\\\\colon[a,b]\\\\to\\\\R$ be Riemann integrable. Let $F\\\\colon[a,b]\\\\to\\\\R$ be\\n$F(x)=\\\\int_{a}^{x} f(t)\\\\,dt$. Then $F$ is continuous, and at all $x$ such that\\n$f$ is continuous at $x$, $F$ is differentiable at $x$ with $F\'(x)=f(x)$.\\n\\n```mdx title=\\"docs/mdx-features.mdx\\"\\n$$\\nI = \\\\int_0^{2\\\\pi} \\\\sin(x)\\\\,dx\\n$$\\n```\\n\\n$$\\nI = \\\\int_0^{2\\\\pi} \\\\sin(x)\\\\,dx\\n$$\\n\\n## Diagrams\\n\\n````md title=\\"Example Mermaid diagram\\"\\n```mermaid\\ngraph TD;\\n    A--\x3eB;\\n    A--\x3eC;\\n    B--\x3eD;\\n    C--\x3eD;\\n```\\n````\\n\\n```mermaid\\ngraph TD;\\n    A--\x3eB;\\n    A--\x3eC;\\n    B--\x3eD;\\n    C--\x3eD;\\n```\\n\\n## Code Block\\n\\n````md\\n```jsx title=\\"/src/components/HelloCodeTitle.js\\"\\nfunction HelloCodeTitle(props) {\\n  return <h1>Hello, {props.name}</h1>;\\n}\\n```\\n````\\n\\n```jsx title=\\"/src/components/HelloCodeTitle.js\\"\\nfunction HelloCodeTitle(props) {\\n  return <h1>Hello, {props.name}</h1>;\\n}\\n```\\n\\nSyntax highlighting for Other languages by `prism`: `sh`, `editorconfig`, etc.\\n\\n**editorconfig**:\\n\\n````md\\n```editorconfig title=\\"/etc/samba.conf\\"\\n[documents]\\npath = /data/documents\\nvalid users = @simon\\nguest ok = no\\nwritable = yes\\nbrowsable = yes\\n```\\n````\\n\\n**sh**:\\n\\n````md\\n```sh\\n$ ls /home\\n```\\n````\\n\\n\\n````md\\n```js\\nfunction HighlightSomeText(highlight) {\\n  if (highlight) {\\n    // highlight-next-line\\n    return \'This text is highlighted!\';\\n  }\\n\\n  return \'Nothing highlighted\';\\n}\\n\\nfunction HighlightMoreText(highlight) {\\n  // highlight-start\\n  if (highlight) {\\n    return \'This range is highlighted!\';\\n  }\\n  // highlight-end\\n\\n  return \'Nothing highlighted\';\\n}\\n```\\n````\\n\\n```js\\nfunction HighlightSomeText(highlight) {\\n  if (highlight) {\\n    // highlight-next-line\\n    return \'This text is highlighted!\';\\n  }\\n\\n  return \'Nothing highlighted\';\\n}\\n\\nfunction HighlightMoreText(highlight) {\\n  // highlight-start\\n  if (highlight) {\\n    return \'This range is highlighted!\';\\n  }\\n  // highlight-end\\n\\n  return \'Nothing highlighted\';\\n}\\n```\\n\\n````md\\n```jsx {1,4-6,11}\\nimport React from \'react\';\\n\\nfunction MyComponent(props) {\\n  if (props.isBar) {\\n    return <div>Bar</div>;\\n  }\\n\\n  return <div>Foo</div>;\\n}\\n\\nexport default MyComponent;\\n```\\n````\\n\\n\\n```jsx {1,4-6,11}\\nimport React from \'react\';\\n\\nfunction MyComponent(props) {\\n  if (props.isBar) {\\n    return <div>Bar</div>;\\n  }\\n\\n  return <div>Foo</div>;\\n}\\n\\nexport default MyComponent;\\n```\\n\\n\\n````md\\n```jsx {1,4-6,11} showLineNumbers\\nimport React from \'react\';\\n\\nfunction MyComponent(props) {\\n  if (props.isBar) {\\n    return <div>Bar</div>;\\n  }\\n\\n  return <div>Foo</div>;\\n}\\n\\nexport default MyComponent;\\n```\\n````\\n\\n```jsx {1,4-6,11} showLineNumbers\\nimport React from \'react\';\\n\\nfunction MyComponent(props) {\\n  if (props.isBar) {\\n    return <div>Bar</div>;\\n  }\\n\\n  return <div>Foo</div>;\\n}\\n\\nexport default MyComponent;\\n```\\n\\n\\n<Tabs>\\n<TabItem value=\\"js\\" label=\\"JavaScript\\">\\n\\n```js\\nfunction helloWorld() {\\n  console.log(\'Hello, world!\');\\n}\\n```\\n\\n</TabItem>\\n<TabItem value=\\"py\\" label=\\"Python\\">\\n\\n```py\\ndef hello_world():\\n  print(\\"Hello, world!\\")\\n```\\n\\n</TabItem>\\n<TabItem value=\\"java\\" label=\\"Java\\">\\n\\n```java\\nclass HelloWorld {\\n  public static void main(String args[]) {\\n    System.out.println(\\"Hello, World\\");\\n  }\\n}\\n```\\n\\n</TabItem>\\n</Tabs>\\n\\n## Importing Code \\n\\n```sh\\nnpm install --save raw-loader\\n```\\n\\n```mdx title=\\"docs/mdx-features.mdx\\"\\nimport CodeBlock from \'@theme/CodeBlock\';\\nimport MyComponentSource from \'!!raw-loader!./myComponent\';\\n\\n<CodeBlock language=\\"jsx\\">{MyComponentSource}</CodeBlock>\\n```\\n\\nimport CodeBlock from \'@theme/CodeBlock\';\\nimport MyComponentSource from \'!!raw-loader!./myComponent\';\\n\\n<CodeBlock language=\\"jsx\\">{MyComponentSource}</CodeBlock>\\n\\n## Importing Markdown\\n\\n```mdx title=\\"docs/mdx-features.mdx\\"\\nimport PartialExample from \'./_markdown-partial-example.mdx\';\\n\\n<PartialExample name=\\"Sebastien\\" />\\n```\\n\\nimport PartialExample from \'./_markdown-partial-example.mdx\';\\n\\n<PartialExample name=\\"Sebastien\\" />\\n\\n```mdx title=\\"docs/mdx-features.mdx\\"\\nimport PartialExample1 from \'./wiki-skia.md\';\\n\\n<PartialExample1 />\\n```\\n\\nIt imports file from [wiki-skia.md](./wiki-skia.md):\\n\\nimport PartialExample1 from \'./wiki-skia.md\';\\n\\n<PartialExample1 />\\n\\n## Import Code Snippets from GitHub Repositories\\n\\n[A Docusaurus v2 plugin that supports referencing code examples from public GitHub repositories.](https://github.com/saucelabs/docusaurus-theme-github-codeblock)\\n\\n```js reference\\nhttps://github.com/saucelabs/docusaurus-theme-github-codeblock/blob/main/src/theme/ReferenceCodeBlock/index.tsx#L105-L108\\n```\\n\\n```js reference\\nhttps://github.com/liviaerxin/liviaerxin.github.io/blob/560ce03e8dbf5d32b197ccf307ca36af25b5dacd/code-snippets/XKeyIn.cpp#L55-L72\\n```"},{"id":"/ffmpeg-command-samples","metadata":{"permalink":"/blog/ffmpeg-command-samples","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/ffmpeg-command-samples.md","source":"@site/../../blog/ffmpeg-command-samples.md","title":"FFmpeg Command Samples","description":"Learn FFmpeg","date":"2023-07-06T00:00:00.000Z","formattedDate":"July 6, 2023","tags":[{"label":"cheat-sheet","permalink":"/blog/tags/cheat-sheet"},{"label":"ffmpeg","permalink":"/blog/tags/ffmpeg"}],"readingTime":5.76,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Docs Docusaurus Template","description":"Creates Docusaurus docs/slip","filepath":"docs/wiki-ffmpeg.md"},"authors":["frank"],"description":"Learn FFmpeg","keywords":["learn","ffmpeg"],"image":"https://i.imgur.com/mErPwqL.png","tags":["cheat-sheet","ffmpeg"],"date":"2023-07-06T00:00:00.000Z"},"prevItem":{"title":"MDX Features of Docusaurus","permalink":"/blog/docusaurus-mdx-features"},"nextItem":{"title":"Wiki NVIDIA Driver and CUDA Library","permalink":"/blog/wiki-cuda"}},"content":"A list of FFmpeg command samples for quick lookup!\\n\\n## Overview\\n\\nExamples of Container and Codec lists in Chrome[^chrome]:\\n\\nVideo Container Format:\\n\\n- MP4 [`.mp4` file extension]\\n- Ogg\\n- WebM\\n- WAV\\n- HLS [`.m3u8` file extension]\\n\\n\x3c!--truncate--\x3e\\n\\nVideo Codec Format:\\n\\n- VP8\\n- VP9\\n- H.264 [Chrome only]\\n- H.265 [Chrome only and also only with the underlying OS support]\\n- MPEG-4 [Chrome OS only, aka **Xvid**, **DivX**]\\n\\n## About FFmpeg Command\\n\\nThe common patter of `ffmpeg` looks like:\\n\\n```sh\\nffmpeg [input_options] -i input.mp4 [output_options] output.mp4\\n```\\n\\nIn short:\\n\\n- The `[input_options]` before `-i input.mp4` are options used for decoding the video\\n- The `[output_options]` before `output.mp4` are options used for encoding the video\\n\\n## FFmpeg Command Examples\\n\\nIt\'s note worthing to look over FFmpeg Wiki [^ffmpeg]\\n\\n### List all available `container` formats\\n\\n```sh\\nffmpeg -formats\\n```\\n\\n### List all available `codec` formats\\n\\n```sh\\nffmpeg -codecs\\n```\\n\\n### List all available `encoder` or `decoder`\\n\\n```sh\\nffmpeg -encoders\\nffmpeg -decoders\\n```\\n\\n```sh\\n# Show available `presets`\\nffmpeg -h encoder=h264_nvenc\\n```\\n\\n### List all frames timestamp\\n\\n```sh\\nffprobe -select_streams v -show_entries frame=pict_type,pts_time -of csv=p=0 -i input.mp4\\n```\\n\\n### List all keyframe(I-frame) timestamp\\n\\n```sh\\nffprobe -select_streams v -show_entries frame=pict_type,pts_time -of csv=p=0 -skip_frame nokey -i input.mp4\\n```\\n\\n### Read video information json output\\n\\n```sh\\nffprobe -v quiet -show_streams -select_streams v:0 -print_format json video.mp4\\n```\\n\\n### Transcode video\\n\\nThere are three possible and reasonable methods for transcoding:\\n\\n- software decoding and software encoding\\n- software decoding and hardware encoding\\n- hardware decoding and hardware encoding\\n\\nyou can convert either the `container formats` or the `codecs formats`, such as:\\n\\n```sh\\n# To `mp4` container and `h.264` codecs(the lower crf, the higher quality)\\nffmpeg -i input.avi -c:v libx264 -preset fast -crf 23 output.mp4\\n\\n# To `mp4` container and `mpeg4` codecs\\nffmpeg -i input.avi -c:v libxvid -preset fast output.mp4\\n\\n# To be friendly for streaming, adding necessary metadata to begin playback faster! \\nffmpeg -i input.avi -c:v libx264 -preset fast -crf 23 -movflags +faststart output.mp4\\n\\n# Remove audio\\nffmpeg -i input.avi -c:v libx264 -preset fast -crf 23 -an output.mp4\\n\\n# Use NVIDIA GPU\\nffmpeg -i input.avi -c:v h264_nvenc -preset fast output.avi\\n\\n# keep quality\\nffmpeg -i input.avi -c:v h264_nvenc -preset fast -rc constqp -cq 19 output.avi\\n```\\n\\n### Set keyframe interval\\n\\n```sh\\n# mpeg4\\nffmpeg -i input.avi -vcodec libxvid -preset fast -g 10 -keyint_min 10 -sc_threshold 0 output.avi \\n\\n# NVIDIA GPU\\n# This sets the I-frame interval at 10 and ensures that no I-frames will be inserted in scene changes\\nffmpeg -i input.avi -vcodec h264_nvenc -preset fast -g 10 -keyint_min 10 -sc_threshold 0 output.avi\\n```\\n\\n### Clip video\\n\\n```sh\\n# Fast clip with stream copy and faster seeking(700x)\\nffmpeg -ss 00:00:10 -i video.mp4 -to 00:00:50 -c:v copy output.mp4\\n\\n# Fast clip with stream copy and slower seeking(600x)\\nffmpeg -i video.mp4 -ss 00:00:10 -to 00:00:50 -c:v copy output.mp4\\n\\n# Slow clip with re-encoding and faster seeking(1x)\\nffmpeg -ss 00:00:10 -i video.mp4 -to 00:00:50 -c:v libx264 output.mp4\\n```\\n\\nUse filter(Slow)\\n\\n```sh\\nffmpeg -y -i input.mp4 -an -c:v libx264 -filter:v \\"trim=start=10:end=30\\" output.mp4\\n# remove the black video\\nffmpeg -y -i input.mp4 -an -c:v libx264 -filter:v \\"trim=start=10:end=30,setpts=PTS-STARTPTS\\" output.mp4\\n```\\n\\n>NOTE: Cutting video with stream copy will lead the start frame is not precise!\\n\\n### Slow down/Speed up video\\n\\n```sh\\n# Slow down to 1/2x in fast way\\nffmpeg -y -itsscale 2 -i video.mp4 -c:v copy output.mp4\\n\\n# Speed up to 2x in fast way\\nffmpeg -y -itsscale 0.5 -i video.mp4 -c:v copy output.mp4\\n\\n# Speed up to 2x with re-encoding in slow way\\nffmpeg -y -itsscale 0.5 -i video.mp4 -c:v libx264 output.mp4\\n\\n# Speed up to 2x with `setpts filter`(which requires re-encoding) in slow way\\nffmpeg -i video.mp4 -filter:v \\"setpts=0.5*PTS\\" output.mp4\\n\\n# Change fps to slow down/speed up but keeping duration\\nffmpeg -i video.mp4 -filter:v \\"fps=30\\" output.mp4\\n```\\n\\n### Draw region of interest(ROI) on a video\\n\\n```sh\\n# Draw one drawbox\\n\\nffmpeg -i input.mp4 -filter:v \\"drawbox=x=100:y=100:w=200:h=150:color=red@0.5\\" output.mp4\\n\\nffmpeg -i input.mp4 -filter:v \\"drawbox=x=100:y=100:w=200:h=150:color=red@0.5,drawtext=text=\'Test Text\':x=100:y=100:fontsize=24:fontcolor=yellow:box=1:boxcolor=yellow\\" output.mp4\\n\\nffmpeg -y -ss 30 -noaccurate_seek -i input.mp4 -t 10 -c:v libx264 -filter:v \\"drawbox=x=100:y=100:w=200:h=150:color=red@0.5,drawtext=text=\'Test Text\':x=100:y=(100-text_h):fontsize=24:fontcolor=black:box=1:boxcolor=red:boxborderw=2\\" output.mp4\\n# Trim video and draw box\\nffmpeg -y -i input.mp4 -an -c:v libx264 -filter:v \\"trim=start=10:end=30,drawbox=x=100:y=100:w=200:h=150:color=red@0.5:enable=\'between(t,10,15)\',setpts=PTS-STARTPTS\\" output.mp4\\n\\nffmpeg -y -i input.mp4 -i overlay_video.mp4 -filter_complex \\"[0:v][1:v]overlay=0:0:enable=\'between(t,0,25)\'\\" output.mp4\\n```\\n\\n```sh\\n# Draw different `drawbox` at different time on video from a file(using `timeline` feature)\\n# See timeline: https://ffmpeg.org/ffmpeg-filters.html#Timeline-editing\\n# See expression: https://ffmpeg.org/ffmpeg-utils.html#Expression-Evaluation\\nffmpeg -i input.mp4 -filter_complex_script timeline.txt output.mp4\\n\\n# `timeline.txt` look like:\\n[0:v]drawbox=x=100:y=100:w=200:h=150:color=red@0.5:enable=\'between(t,0,21)\'[box1];\\n[box1]drawbox=x=300:y=200:w=150:h=100:color=green@0.5:t=:enable=\'between(t,21,40)\'[box2];\\n[box2]drawbox=x=50:y=300:w=300:h=200:color=blue@0.5:t=:enable=\'between(t,41,60)\'\\n\\n\\n# or using `n`: sequential number of the input frame, starting from 0\\n[0:v]drawbox=x=100:y=100:w=200:h=150:color=red@0.5:n=0:600[box1];\\n[box1]drawbox=x=300:y=200:w=150:h=100:color=green@0.5:n=601:1200[box2];\\n[box2]drawbox=x=50:y=300:w=300:h=200:color=blue@0.5:n=1201:1800\\n```\\n\\n```sh\\n# Draw different `drawbox` at different time on video\\nffmpeg -i input.mp4 -filter_complex \\"[0:v]drawbox=x=100:y=100:w=200:h=150:color=red:t=8:enable=\'between(t,0,21)\'[box1];[box1]drawbox=x=300:y=200:w=150:h=100:color=green:t=8:enable=\'between(t,21,40)\'[box2];[box2]drawbox=x=50:y=300:w=300:h=200:color=blue:t=8:enable=\'between(t,41,60)\'\\" output.mp4\\n```\\n\\n### Pipe ffmpeg\\n\\nThe `FFmpeg Pipe` is very useful in **IPC** for communicating `FFmpeg` with another `process`. For instance, an application generates images to `Pipe` stdin which `FFmpeg` reads and encodes into a video.\\n\\n**A real-life scenario that FFmpeg read from Pipe**:\\nAn application applied `OpenCV` to process images for object detection, and it will draw ROI but lacks ability to encode a video as efficiently as `FFmpeg` does. So it\'s somewhat ideal to pipe these images to `FFmpeg` that can encode the video by leveraging hardware acceleration(GPU) capability.\\n\\nHowever, FFmpeg can also **write to a Pipe**.\\n\\n```sh\\n# It works in Linux and Windows(`cmd`, does not work in `PS`)\\nffmpeg -ss 00:00:10 -i video.mp4 -to 00:00:20 -an -c:v copy -f h264 pipe: | ffmpeg -y -i pipe: -filter:v \\"drawbox=x=100:y=100:w=200:h=150:color=red\\" output.mp4\\n\\nffmpeg -i input.mp4 -c:v rawvideo -pix_fmt bgr24 -r 60 -f rawvideo pipe: | ffmpeg -y -f rawvideo -pix_fmt bgr24 -s 1920x1080 -r 60 -i pipe: -pix_fmt yuv420p -c:v h264_nvenc foo.mp4\\nffmpeg -i input.mp4 -pix_fmt yuv420p -r 60 -f rawvideo pipe: | ffmpeg -y -f rawvideo -pix_fmt yuv420p -s 1920x1080 -r 60 -i pipe: -c:v h264_nvenc foo.mp4\\nffmpeg -i input.mp4 -an -f h264 pipe: | ffmpeg -y -f h264 -i pipe: -c:v h264_nvenc foo.mp4\\n```\\n\\n### Use testsrc\\n\\n```sh\\nffmpeg -y -f lavfi -i testsrc=duration=10:size=1920x1080:rate=60 -c:v libx264 -pix_fmt yuv420p testsrc.mp4\\n```\\n\\n### Split and Concatenate\\n\\n```sh\\nffmpeg -y -i input.mp4 -ss 0 -to 10 -c:v copy part1.mp4\\nffmpeg -y -i input.mp4 -ss 10 -to 15 -c:v copy part2.mp4\\nffmpeg -y -i input.mp4 -ss 15 -c:v copy part3.mp4\\n```\\n\\n```sh\\nffmpeg -y -i part2.mp4 -filter:v \\"drawbox=x=100:y=100:w=200:h=150:color=red@0.5\\" part2-draw.mp4\\n```\\n\\nSlow,\\n\\n```sh\\nffmpeg -y -i part1.mp4 -i part2-draw.mp4 -i part3.mp4 -filter_complex \\"[0:v][1:v][2:v]concat=n=3:v=1:a=0[outv]\\" -map \\"[outv]\\" output.mp4\\n```\\n\\nFast(Concat protocol),\\n\\n```sh\\nffmpeg -i part1.mp4 -c copy part1.ts\\nffmpeg -i part2-draw.mp4 -c copy part2-draw.ts\\nffmpeg -i part3.mp4 -c copy part3.ts\\n\\nffmpeg -y -i \\"concat:part1.ts|part2-draw.ts|part3.ts\\" -c:v copy output.mp4\\n```\\n\\nFast(Concat demuxer),\\n\\n```sh\\nffmpeg -y -f concat -i concat.txt -c:v copy output.mp4\\n# concat.txt\\nfile \'part1.mp4\'\\nfile \'part2-draw.mp4\'\\nfile \'part3.mp4\'\\n\\n# Or avoid creating the input file\\n# bash\\nffmpeg -y -f concat -safe 0 -i <(echo \\"file \'$PWD/part1.mp4\'\\";echo \\"file \'$PWD/part2-draw.mp4\'\\";echo \\"file \'$PWD/part3.mp4\'\\";) -c:v copy output.mp4\\n# cmd\\nffmpeg -y -f concat -safe 0 -i <(@echo \\"file \'$PWD/part1.mp4\'\\";@echo \\"file \'$PWD/part2-draw.mp4\'\\";@echo \\"file \'$PWD/part3.mp4\'\\";) -c:v copy output.mp4\\n```\\n\\nhttps://trac.ffmpeg.org/wiki/Concatenate\\n\\n## References\\n\\n[^ffmpeg]: [FFmpeg Wiki](https://trac.ffmpeg.org/wiki)\\n[^chrome]: [Chrome Audio/Video Support](https://www.chromium.org/audio-video/)"},{"id":"/wiki-cuda","metadata":{"permalink":"/blog/wiki-cuda","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-cuda.mdx","source":"@site/../../blog/wiki-cuda.mdx","title":"Wiki NVIDIA Driver and CUDA Library","description":"Learn CUDA","date":"2023-06-29T00:00:00.000Z","formattedDate":"June 29, 2023","tags":[{"label":"nvidia","permalink":"/blog/tags/nvidia"},{"label":"gpu","permalink":"/blog/tags/gpu"},{"label":"cuda","permalink":"/blog/tags/cuda"},{"label":"wsl","permalink":"/blog/tags/wsl"},{"label":"ubuntu","permalink":"/blog/tags/ubuntu"}],"readingTime":3.245,"hasTruncateMarker":true,"authors":[{"name":"frank"}],"frontMatter":{"foam_template":{"name":"Docs Docusaurus Template","description":"Creates Docusaurus docs/slip","filepath":"docs/wiki-cuda.md"},"sidebar_label":"Learn CUDA","description":"Learn CUDA","keywords":["wiki","cuda"],"image":"https://i.imgur.com/mErPwqL.png","tags":["nvidia","gpu","cuda","wsl","ubuntu"],"date":"2023-06-29T00:00:00.000Z","author":"frank"},"prevItem":{"title":"FFmpeg Command Samples","permalink":"/blog/ffmpeg-command-samples"},"nextItem":{"title":"C++ Package Management","permalink":"/blog/c-package-management"}},"content":"Ecosystem:\\n\\nHardware:\\n\\n- NVIDIA GPU(Hardware)\\n\\nSoftware:\\n\\n- NVIDIA Driver(GPU, Graphics Card)\\n  - libnvidia-encode.so\\n- CUDA Toolkit\\n  - libnvcuvid.so\\n  - libcuda.so\\n- cuDNN library\\n- NVIDIA Container Toolkit\\n  - libnvidia-container.so\\n\\n\x3c!--truncate--\x3e\\n\\n![CUDA Components](https://docs.nvidia.com/deploy/cuda-compatibility/graphics/CUDA-components.png)\\n\\n\\n## NVIDIA Driver on Ubuntu\\n\\n### Find out whether the host machine have NVIDIA GPU hardware\\n\\n```sh\\n$ lspci | grep VGA\\n0000:ac:00.0 VGA compatible controller: NVIDIA Corporation Device 2233 (rev a1)\\n```\\n\\nor,\\n\\n```sh\\n$ sudo lshw -C display\\n  *-display\\n       description: VGA compatible controller\\n       product: NVIDIA Corporation\\n       vendor: NVIDIA Corporation\\n       physical id: 0\\n       bus info: pci@0000:ac:00.0\\n       logical name: /dev/fb0\\n       version: a1\\n       width: 64 bits\\n       clock: 33MHz\\n       capabilities: pm msi pciexpress vga_controller bus_master cap_list rom fb\\n       configuration: depth=32 driver=nouveau latency=0 resolution=1920,1080\\n       resources: iomemory:204f0-204ef iomemory:204f0-204ef irq:68 memory:99000000-99ffffff memory:204fe0000000-204fefffffff memory:204ff0000000-204ff1ffffff ioport:3000(size=128) memory:9a080000-9a0fffff\\n```\\n\\nor,\\n\\n```sh\\n$ hwinfo --gfxcard --short\\ngraphics card:\\n                       nVidia VGA compatible controller\\n\\nPrimary display adapter: #94\\n```\\n\\n### Check which NVIDIA driver being used\\n\\nUbuntu is using **open-source Nouveau drivers**\\n\\n```sh\\n$ lsmod | grep nouveau\\nnouveau              2306048  1\\nmxm_wmi                16384  1 nouveau\\ni2c_algo_bit           16384  1 nouveau\\ndrm_ttm_helper         16384  1 nouveau\\nttm                    86016  2 drm_ttm_helper,nouveau\\ndrm_kms_helper        311296  1 nouveau\\ndrm                   622592  5 drm_kms_helper,drm_ttm_helper,ttm,nouveau\\nvideo                  65536  2 dell_wmi,nouveau\\nwmi                    32768  7 dell_wmi_sysman,dell_wmi,wmi_bmof,dell_smbios,dell_wmi_descriptor,mxm_wmi,nouveau\\n```\\n\\nUbuntu is not using the **proprietary NVIDIA drivers**\\n\\n```sh\\n$ lsmod | grep nvidia\\n```\\n\\n### Install the NVIDIA driver\\n\\n[Ubuntu Linux Install Nvidia Driver (Latest Proprietary Driver)](https://www.cyberciti.biz/faq/ubuntu-linux-install-nvidia-driver-latest-proprietary-driver)\\n\\n[Install Nvidia Beta Drivers via PPA Repository](https://phoenixnap.com/kb/install-nvidia-drivers-ubuntu#ftoc-heading-11)\\n\\n### Verify the NVIDIA driver\\n\\n```sh\\nnvidia-smi\\n\\nnvidia-smi --query-gpu=driver_version --format=csv\\n```\\n\\n```sh\\ndconfig -p | grep nvidia\\n```\\n\\n### Reload NVIDIA driver\\n\\nGet related drivers,\\n\\n```sh\\nlsmod | grep nvidia\\n```\\n\\nUnload drivers,\\n\\n```sh\\nsudo rmmod nvidia_drm\\nsudo rmmod nvidia_modeset\\nsudo rmmod nvidia_uvm\\n```\\n\\n```sh\\nsudo rmmod nvidia\\n```\\n\\nLoad NVIDIA driver again,\\n\\n```sh\\nnvidia-smi\\n```\\n\\n\\n[cuda - Nvidia NVML Driver/library version mismatch - Stack Overflow](https://stackoverflow.com/questions/43022843/nvidia-nvml-driver-library-version-mismatch#comment73133147_43022843)\\n\\nPrevent updating NVIDIA driver,\\n\\n```sh\\nsudo apt-mark hold nvidia-driver-535\\nsudo apt-mark hold nvidia-dkms-535\\nsudo apt-mark hold nvidia-utils-535\\n```\\n\\n[updates - How to prevent updating of a specific package? - Ask Ubuntu](https://askubuntu.com/questions/18654/how-to-prevent-updating-of-a-specific-package)\\n\\n## NVIDIA CUDA Toolkit on WSL\\n\\nNVIDIA CUDA software stack on WSL 2:\\n\\n![NVIDIA CUDA software stack on WSL 2](https://docs.nvidia.com/cuda/wsl-user-guide/_images/wsl-launch-upt-0625-rz.png)\\n\\n## NVIDIA CUDA Toolkit on Ubuntu\\n\\n[Official documentation: CUDA installation](https://docs.nvidia.com/cuda/)\\n\\n[How to Install CUDA on Ubuntu 22.04 LTS](https://linuxhint.com/install-cuda-on-ubuntu-22-04-lts)\\n\\n## NVIDIA Container Toolkit\\n\\nBuild and run containers leveraging NVIDIA GPUs, already including **CUDA Toolkit**.\\n\\n![NVIDIA Container Toolkit](https://cloud.githubusercontent.com/assets/3028125/12213714/5b208976-b632-11e5-8406-38d379ec46aa.png)\\n\\n[](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/user-guide.html)\\n\\nPrerequisites on Host Machine:\\n\\n- [Nvidia GPU driver](#nvidia-gpu-driver-on-ubuntu)\\n- [Nvidia CUDA Container Toolkit](#nvidia-cuda-container-toolkit)\\n- Docker\\n\\nRunning a docker container `ubuntu`,\\n\\n[Specialized Configurations with Docker \u2014 container-toolkit 1.14.1 documentation](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html#)\\n\\n```sh\\n$ docker run --rm --gpus all ubuntu nvidia-smi\\n\\n$ docker run --rm --gpus all ubuntu ldconfig -p | grep nvidia\\n        libnvidia-ptxjitcompiler.so.1 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.1\\n        libnvidia-pkcs11-openssl3.so.535.86.05 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libnvidia-pkcs11-openssl3.so.535.86.05\\n        libnvidia-opencl.so.1 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.1\\n        libnvidia-nvvm.so.4 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libnvidia-nvvm.so.4\\n        libnvidia-ml.so.1 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1\\n        libnvidia-cfg.so.1 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libnvidia-cfg.so.1\\n        libnvidia-allocator.so.1 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libnvidia-allocator.so.1\\n\\n$ docker run --rm -e NVIDIA_DRIVER_CAPABILITIES=video --gpus all ubuntu ldconfig -p | grep nvidia\\n        libnvidia-ptxjitcompiler.so.1 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.1\\n        libnvidia-pkcs11-openssl3.so.535.86.05 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libnvidia-pkcs11-openssl3.so.535.86.05\\n        libnvidia-opticalflow.so.1 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libnvidia-opticalflow.so.1\\n        libnvidia-opencl.so.1 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.1\\n        libnvidia-nvvm.so.4 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libnvidia-nvvm.so.4\\n        libnvidia-encode.so.1 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libnvidia-encode.so.1\\n        libnvidia-allocator.so.1 (libc6,x86-64) => /usr/lib/x86_64-linux-gnu/libnvidia-allocator.so.1\\n```\\n\\nRunning a docker container `nvidia/cuda`,\\n\\n:::info\\nMake sure the version of **CUDA container** `nvidia/cuda:xx.x.x-base-ubuntu22.04` such as `12.2.0` in following must be compatible with the version of the **Nvidia GPU driver** on the host platform such as `>525.60.13`.\\n:::\\n\\n```sh\\ndocker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi\\n```\\n\\n```sh\\ndocker run --rm \\\\\\n    --gpus all \\\\\\n    -e NVIDIA_VISIBLE_DEVICES=all \\\\\\n    -e NVIDIA_DRIVER_CAPABILITIES=compute,video,utility,graphics \\\\\\n    nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi\\n```\\n\\nMore `Dockerfile` examples:\\n\\n- [Dockerfile](../code-snippets/dockerfile/nvidia-cuda-ffmpeg/Dockerfile)\\n- [docker compose](../code-snippets/docker-compose/nvidia-cuda/docker-compose.yml)\\n\\n## FFmpeg in NVIDIA CUDA container\\n\\nhttps://developer.nvidia.com/ffmpeg\\n\\nhttps://docs.nvidia.com/video-technologies/video-codec-sdk/12.0/ffmpeg-with-nvidia-gpu/index.html#compiling-for-linux\\n\\nhttps://developer.nvidia.com/blog/nvidia-ffmpeg-transcoding-guide/\\n\\n[Install FFmpeg on Nvidia CUDA Container](./ffmpeg-on-cuda-container.mdx)\\n\\n## Known issues\\n\\nAfter random long running time, in Nvidia docker the FFmpeg encoding stops and error comes out: `CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected`.  \\n[[Issue]: NVidia Docker transcoding randomly stops working after 5 minutes to 4 hours later. \xb7 Issue #9287 \xb7 jellyfin/jellyfin \xb7 GitHub](https://github.com/jellyfin/jellyfin/issues/9287)\\n\\n## References\\n\\n[CUDA And Nvidia Graphics Driver](https://docs.nvidia.com/deploy/cuda-compatibility/index.html)\\n\\n[CUDA on WSL User Guide](https://docs.nvidia.com/cuda/wsl-user-guide/index.html)"},{"id":"/c-package-management","metadata":{"permalink":"/blog/c-package-management","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/c-package-management.md","source":"@site/../../blog/c-package-management.md","title":"C++ Package Management","description":"C++ Package Management","date":"2023-06-26T00:00:00.000Z","formattedDate":"June 26, 2023","tags":[{"label":"c++","permalink":"/blog/tags/c"},{"label":"vcpkg","permalink":"/blog/tags/vcpkg"},{"label":"conan","permalink":"/blog/tags/conan"}],"readingTime":0.02,"hasTruncateMarker":false,"authors":[{"name":"frank"}],"frontMatter":{"foam_template":{"name":"Docs Docusaurus Template","description":"Creates Docusaurus docs/slip","filepath":"docs/c++-package-management.md"},"sidebar_label":"C++ Package Management","description":"C++ Package Management","keywords":["c++ package","vcpkg","conan"],"image":"https://i.imgur.com/mErPwqL.png","tags":["c++","vcpkg","conan"],"date":"2023-06-26T00:00:00.000Z","author":"frank"},"prevItem":{"title":"Wiki NVIDIA Driver and CUDA Library","permalink":"/blog/wiki-cuda"},"nextItem":{"title":"Code Snippet Management","permalink":"/blog/code-snippet-management"}},"content":"vcpkg\\n\\n[[wiki vcpkg]](./wiki-vcpkg.mdx)\\n\\nconan"},{"id":"/code-snippet-management","metadata":{"permalink":"/blog/code-snippet-management","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/code-snippet-management.md","source":"@site/../../blog/code-snippet-management.md","title":"Code Snippet Management","description":"Code Snippet Management","date":"2023-06-26T00:00:00.000Z","formattedDate":"June 26, 2023","tags":[{"label":"code snippet","permalink":"/blog/tags/code-snippet"}],"readingTime":0.595,"hasTruncateMarker":true,"authors":[{"name":"frank"}],"frontMatter":{"foam_template":{"name":"Docs Docusaurus Template","description":"Creates Docusaurus docs/slip","filepath":"docs/code-snippet-management.md"},"sidebar_label":"Code Snippet Management","description":"Code Snippet Management","keywords":["code snippet manager"],"image":"https://i.imgur.com/mErPwqL.png","tags":["code snippet"],"date":"2023-06-26T00:00:00.000Z","author":"frank"},"prevItem":{"title":"C++ Package Management","permalink":"/blog/c-package-management"},"nextItem":{"title":"Dotfiles Guide","permalink":"/blog/dotfiles-guide"}},"content":"\x3c!--truncate--\x3e\\n\\n```plantuml\\n@startuml\\nskinparam linetype polyline\\nskinparam linetype ortho\\ncomponent \\"Code Snippet Manager App\\" as CSMA {\\n    component \\"Categories\\" as C\\n    component \\"Search\\" as S\\n    component \\"Comments and Documentation\\" as CD\\n    component \\"Version Control\\" as VC\\n    component \\"Share and Collaborate\\" as SC\\n    C -[hidden]- S\\n    S -[hidden]- CD\\n    CD -[hidden]- VC\\n    VC -[hidden]- SC\\n}\\n\\ncomponent \\"IDE with Code Snippet Manager Extension\\" as IDE {\\n    component \\"View Feature\\" as IDE.V\\n    component \\"Write/Update Feature\\" as IDE.W\\n    component \\"AI-Assisted Code Completion\\" as IDE.A\\n}\\ndatabase \\"Local Database\\" as DB\\ncloud \\"Cloud Storage\\" as CS\\n\\nCS <--\x3e DB: sync data\\n\\nDB -l-> CSMA: read\\nDB <-- CSMA: write\\nDB --\x3e IDE.V: read\\nIDE.V --\x3e IDE.A: read\\nDB <-- IDE.W: write\\n\\n@enduml\\n```"},{"id":"/dotfiles-guide","metadata":{"permalink":"/blog/dotfiles-guide","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/dotfiles-guide.md","source":"@site/../../blog/dotfiles-guide.md","title":"Dotfiles Guide","description":"Dotfiles Guide","date":"2023-06-26T00:00:00.000Z","formattedDate":"June 26, 2023","tags":[{"label":"dotfiles","permalink":"/blog/tags/dotfiles"}],"readingTime":0.145,"hasTruncateMarker":false,"authors":[{"name":"frank"}],"frontMatter":{"sidebar_label":"Dotfiles Guide","description":"Dotfiles Guide","keywords":["dotfiles"],"image":"https://i.imgur.com/mErPwqL.png","tags":["dotfiles"],"date":"2023-06-26T00:00:00.000Z","author":"frank"},"prevItem":{"title":"Code Snippet Management","permalink":"/blog/code-snippet-management"},"nextItem":{"title":"Python Package Management","permalink":"/blog/python-package-management"}},"content":"[Tutorials - dotfiles.github.io](http://dotfiles.github.io/tutorials/)\\n\\n[Getting started with dotfilesFrontend Ramblings RSS feedThe content of this website on GitHubMy Mastodon profileMy Twitter profileShare this article on TwitterShare this article on Hacker News](https://www.webpro.nl/articles/getting-started-with-dotfiles)"},{"id":"/python-package-management","metadata":{"permalink":"/blog/python-package-management","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/python-package-management.md","source":"@site/../../blog/python-package-management.md","title":"Python Package Management","description":"Python Package Management","date":"2023-06-26T00:00:00.000Z","formattedDate":"June 26, 2023","tags":[{"label":"blog","permalink":"/blog/tags/blog"},{"label":"docusaurus","permalink":"/blog/tags/docusaurus"}],"readingTime":0.64,"hasTruncateMarker":true,"authors":[{"name":"frank"}],"frontMatter":{"foam_template":{"name":"Docs Docusaurus Template","description":"Creates Docusaurus docs/slip","filepath":"docs/python-package-management.md"},"sidebar_label":"Python Package Management","description":"Python Package Management","keywords":["docs","docusaurus"],"image":"https://i.imgur.com/mErPwqL.png","tags":["blog","docusaurus"],"date":"2023-06-26T00:00:00.000Z","author":"frank"},"prevItem":{"title":"Dotfiles Guide","permalink":"/blog/dotfiles-guide"},"nextItem":{"title":"Wiki PowerShell","permalink":"/blog/wiki-powershell"}},"content":"Foam includes note templates!\\nThis allows you to easily create notes that have similar structure without having to use copy/paste :)\\n\\nTemplates support the [VS Code\'s Snippet Syntax](https://code.visualstudio.com/docs/editor/userdefinedsnippets#_snippet-syntax), which means you can:\\n\\n- add variables to the newly created note\\n- add tabstop to automatically navigate to the key parts of the note, just like a form\\nBelow you can see an example showing a todo list and a timestamp.\\n\\n\x3c!--truncate--\x3e\\n\\n\\n## Todo List\\n\\n1. First tabstop\\n2. A second tabstop\\n3. A third tabstop\\n\\nNote Created: 2023-06-26\\n\\n---\\n\\nTry out the above example by running the `Foam: Create New Note From Template` command and selecting the `your-first-template` template. Notice what happens when your new note is created!\\n\\nTo remove this template, simply delete the `.foam/templates/your-first-template.md` file.\\n\\nEnjoy!"},{"id":"/wiki-powershell","metadata":{"permalink":"/blog/wiki-powershell","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-powershell.mdx","source":"@site/../../blog/wiki-powershell.mdx","title":"Wiki PowerShell","description":"Learn PowerShell","date":"2023-06-26T00:00:00.000Z","formattedDate":"June 26, 2023","tags":[{"label":"powershell","permalink":"/blog/tags/powershell"},{"label":"learn","permalink":"/blog/tags/learn"}],"readingTime":0.15,"hasTruncateMarker":true,"authors":[{"name":"frank"}],"frontMatter":{"foam_template":{"name":"Docs Docusaurus Template","description":"Creates Docusaurus docs/slip","filepath":"docs/wiki-powershell.md"},"sidebar_label":"Learn PowerShell","description":"Learn PowerShell","keywords":["wiki","powershell"],"image":"https://i.imgur.com/mErPwqL.png","tags":["powershell","learn"],"date":"2023-06-26T00:00:00.000Z","author":"frank"},"prevItem":{"title":"Python Package Management","permalink":"/blog/python-package-management"},"nextItem":{"title":"Learn CMake","permalink":"/blog/wiki-cmake"}},"content":"Set environment variables permanently\\n\\n```powershell\\n[Environment]::SetEnvironmentVariable(\\"VCPKG_ROOT\\", \\"Whatever you need it to be\\", \\"Machine\\")\\n```\\n\\n\x3c!--truncate--\x3e\\n\\nGet environment variables\\n\\n```powershell\\n# Get all variables\\n[Environment]::GetEnvironmentVariable()\\n\\n# Get specific variable\\n[Environment]::GetEnvironmentVariable(\\"VCPKG_ROOT\\")\\n```"},{"id":"/wiki-cmake","metadata":{"permalink":"/blog/wiki-cmake","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-cmake.mdx","source":"@site/../../blog/wiki-cmake.mdx","title":"Learn CMake","description":"Learn CMake","date":"2023-06-25T00:00:00.000Z","formattedDate":"June 25, 2023","tags":[{"label":"cmake","permalink":"/blog/tags/cmake"},{"label":"wiki","permalink":"/blog/tags/wiki"}],"readingTime":3.41,"hasTruncateMarker":true,"authors":[{"name":"frank"}],"frontMatter":{"sidebar_label":"Learn CMake","description":"Learn CMake","keywords":["cmake","project structure"],"image":"https://i.imgur.com/mErPwqL.png","tags":["cmake","wiki"],"date":"2023-06-25T00:00:00.000Z","author":"frank"},"prevItem":{"title":"Wiki PowerShell","permalink":"/blog/wiki-powershell"},"nextItem":{"title":"Wiki vcpkg","permalink":"/blog/wiki-vcpkg"}},"content":"In brief, **CMake** is all about **targets** and **properties**\\n\\n\x3c!--truncate--\x3e\\n\\n## CMake Project Structure\\n\\nA typical **CMake** project can be regarded to has three `Tree`:\\n\\n**Source Tree**:\\n\\n```sh\\nproject_root\\n\u251c\u2500\u2500 CMakeLists.txt\\n\u251c\u2500\u2500 simple_example.cpp\\n\u251c\u2500\u2500 simple_lib.cpp\\n\u2514\u2500\u2500 simple_lib.hpp\\n```\\n\\n**Build Tree**:\\n\\n```sh\\nproject_root\\n\u251c\u2500\u2500 CMakeLists.txt\\n\u251c\u2500\u2500 simple_example.cpp\\n\u251c\u2500\u2500 simple_lib.cpp\\n\u251c\u2500\u2500 simple_lib.hpp\\n\u2514\u2500\u2500 build\\n    \u2514\u2500\u2500 CMakeCache.txt\\n```\\n\\n**Install Tree**:\\n\\nThis tree is located in the `CMAKE_INSTALL_PREFIX`, of which default value is platform-dependent. By default, it is set to `/usr/local` on Unix-like systems (Linux, macOS) and `C:/Program Files/<Project Name>` on Windows..\\n\\nTo change it, you can pass `-DCMAKE_INSTALL_PREFIX` argument during CMake `configuration` step, like this:\\n\\n```sh\\ncmake -B build -S . -DCMAKE_INSTALL_PREFIX=/my/custom/installation/path\\n```\\n\\nAlternatively, you can change it by passing `--prefix`(it can be relative path) argument during CMake `install` step, like this:\\n\\n```sh\\ncmake --install build --prefix \\"/my/custom/installation/path\\"\\n```\\n\\nIt\'s recommended to use a default install layout as `GNUInstallDirs`.\\n\\nA **install tree** will look like as below if you\'d like all things to be installed inside the project via `cmake --install build --prefix \\"./install`.\\n\\n```sh\\nproject_root\\n\u251c\u2500\u2500 CMakeLists.txt\\n\u251c\u2500\u2500 simple_example.cpp\\n\u251c\u2500\u2500 simple_lib.cpp\\n\u251c\u2500\u2500 simple_lib.hpp\\n\u251c\u2500\u2500 build\\n\u2502   \u2514\u2500\u2500 CMakeCache.txt\\n\u2514\u2500\u2500 install\\n    \u251c\u2500\u2500 bin\\n    \u2502   \u2514\u2500\u2500 executables\\n    \u251c\u2500\u2500 sbin\\n    \u2502   \u2514\u2500\u2500 sysadmin executables\\n    \u251c\u2500\u2500 lib\\n    \u2502   \u251c\u2500\u2500 compiled libraries (*.so (unix) or *.dll (windows))\\n    \u2502   \u2514\u2500\u2500 library archive files (*.lib (windows))\\n    \u251c\u2500\u2500 libexec\\n    \u2502   \u2514\u2500\u2500 executables not directly invoked by user\\n    \u251c\u2500\u2500 include\\n    \u2502   \u2514\u2500\u2500 header files\\n    \u2514\u2500\u2500 doc\\n       \u2514\u2500\u2500 documentation\\n```\\n\\n## How CMake Works\\n\\nA typical workflow of CMake includes `Configure`, `Build` and `Install` steps, combined with the above mentioned `Trees` concepts.\\n\\n1. `Configure` step will generate a sort of configuration files, the most important ones among them are `CMakeCache.txt`, `cmake_install.cmake` and `Makefile` if using `Make` as building system. With these generated configuration files, the later steps `Build` and `Install` will run according to them.\\n2. `Build` step will generate the build binary directory.\\n3. `Install` step will generate the install binary directory.\\n\\n## How to make your package be found by others by `find_package()`\\n\\npackage configuration files: `find_package`\\n\\n[Title](https://cmake.org/cmake/help/latest/guide/importing-exporting/index.html#importing-targets)\\n\\n## RPATH in CMake\\n\\n[^rpath]\\n\\n## CMake Variables\\n\\nThere are some useful and important CMake variables that will be introduced here:\\n\\n`CMAKE_PREFIX_PATH`\\n\\n`CMAKE_IGNORE_PATH`\\n\\n## `clang` FAQ\\n\\n### Find out `clang` include search path\\n\\n```sh\\n\u276f clang -x c -v -E /dev/null\\n...\\n#include \\"...\\" search starts here:\\n#include <...> search starts here:\\n /opt/homebrew/Cellar/llvm/17.0.1/lib/clang/17/include\\n /Library/Developer/CommandLineTools/SDKs/MacOSX14.sdk/usr/include\\n /Library/Developer/CommandLineTools/SDKs/MacOSX14.sdk/System/Library/Frameworks (framework directory)\\nEnd of search list.\\n# 1 \\"/dev/null\\"\\n# 1 \\"<built-in>\\" 1\\n# 1 \\"<built-in>\\" 3\\n# 420 \\"<built-in>\\" 3\\n# 1 \\"<command line>\\" 1\\n# 1 \\"<built-in>\\" 2\\n# 1 \\"/dev/null\\" 2\\n```\\n\\n### Add include search path to `clang`\\n\\nUse environment variables `C_INCLUDE_PATH` for `c` and `CPLUS_INCLUDE_PATH` for `c++`.\\n\\n`clang`:\\n\\n```sh\\n\u276f C_INCLUDE_PATH=/opt/homebrew/include clang -x c -v -E /dev/null\\n...\\n#include \\"...\\" search starts here:\\n#include <...> search starts here:\\n /usr/local/include\\n /opt/homebrew/include\\n /Library/Developer/CommandLineTools/usr/lib/clang/15.0.0/include\\n /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include\\n /Library/Developer/CommandLineTools/usr/include\\n /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/System/Library/Frameworks (framework directory)\\n```\\n\\n`clang++`:\\n\\n```sh\\n\u276f CPLUS_INCLUDE_PATH=/opt/homebrew/include clang -x c++ -v -E /dev/null\\n...\\n#include \\"...\\" search starts here:\\n#include <...> search starts here:\\n /usr/local/include\\n /opt/homebrew/include\\n /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1\\n /Library/Developer/CommandLineTools/usr/lib/clang/15.0.0/include\\n /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include\\n /Library/Developer/CommandLineTools/usr/include\\n /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/System/Library/Frameworks (framework directory)\\n```\\n\\nUse `-I` flag,\\n\\n```sh\\n\u276f clang -x c -I/opt/homebrew/include -v -E /dev/null\\n...\\n#include \\"...\\" search starts here:\\n#include <...> search starts here:\\n /opt/homebrew/include\\n /usr/local/include\\n /Library/Developer/CommandLineTools/usr/lib/clang/15.0.0/include\\n /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include\\n /Library/Developer/CommandLineTools/usr/include\\n /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/System/Library/Frameworks (framework directory)\\n```\\n\\n### Find out `clang` library search paths\\n\\n```sh\\n\u276f clang -Xlinker -v\\n...\\nLibrary search paths:\\n\\t/usr/local/lib\\nFramework search paths:\\nld: Undefined symbols:\\n  _main, referenced from:\\n      <initial-undefines>\\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\\n```\\n\\n### Add library search path to `clang`\\n\\nUse environment variables `LIBRARY_PATH`,\\n\\n```sh\\n\u276f LIBRARY_PATH=$LIBRARY_PATH:/usr/lib clang -Xlinker -v\\n...\\nLibrary search paths:\\n\\t.\\n\\t/usr/lib\\n\\t/usr/local/lib\\nFramework search paths:\\nld: Undefined symbols:\\n  _main, referenced from:\\n      <initial-undefines>\\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\\n```\\n\\nUse `-L` flag:\\n\\n```sh\\n\u276f clang -L/opt/homebrew/lib -Xlinker -v\\n```\\n\\nhttps://langui.sh/2015/07/24/osx-clang-include-lib-search-paths/\\n\\n## What is the difference? clang++ | clang -std=c++11\\n\\n## CMake FAQ\\n\\n### Add library search path to `CMake` globally in project\\n\\n1. `set(CMAKE_LIBRARY_PATH ${CMAKE_LIBRARY_PATH} /opt/local/lib)`\\n2. `LINK_DIRECTORIES(/opt/local/lib)`\\n\\n## Resources\\n\\n[CMake hands-on workshop \u2014 CMake Workshop](https://enccs.github.io/cmake-workshop/)\\n[^rpath]: [RPATH handling from official cmake](https://gitlab.kitware.com/cmake/community/-/wikis/doc/cmake/RPATH-handling)"},{"id":"/wiki-vcpkg","metadata":{"permalink":"/blog/wiki-vcpkg","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wiki-vcpkg.mdx","source":"@site/../../blog/wiki-vcpkg.mdx","title":"Wiki vcpkg","description":"learn vcpkg","date":"2023-06-23T00:00:00.000Z","formattedDate":"June 23, 2023","tags":[{"label":"wiki","permalink":"/blog/tags/wiki"},{"label":"vcpkg","permalink":"/blog/tags/vcpkg"}],"readingTime":2.97,"hasTruncateMarker":true,"authors":[{"name":"frank"}],"frontMatter":{"sidebar_label":"learn vcpkg","description":"learn vcpkg","keywords":["docs","docusaurus"],"image":"https://i.imgur.com/mErPwqL.png","tags":["wiki","vcpkg"],"date":"2023-06-23T00:00:00.000Z","author":"frank"},"prevItem":{"title":"Learn CMake","permalink":"/blog/wiki-cmake"},"nextItem":{"title":"FastAPI Best Practices","permalink":"/blog/fastapi-best-practices"}},"content":"`vcpkg` is cross-platform **C/C++ package manager**, and its peers include `conan`.\\n\\nThe most common type of package is a C/C++ library consisting of headers, source code, and binaries.\\n\\nSome useful folders in `VCPKG_ROOT=/path/to/vcpkg` in `vcpkg`:\\n\\nHow `vcpkg` install `fmt` library when calling `vcpkg install fmt` in classic mode?\\n\\n1. Download the source code `fmt.tar.gz` into `%VCPKG_ROOT%/downloads/` directory.\\n2. **build tree** -> `%VCPKG_ROOT%/buildtrees`:\\n    1. Put the source code under `%VCPKG_ROOT%/buildtrees/fmt/src/xxxx-xxxx.clean/` directory.\\n    2. Create building directory: `%VCPKG_ROOT%/buildtrees/fmt/arm64-osx-dynamic-rel/`(`triplet`+`release/debug`) and then start building\\n3. **package tree** -> `%VCPKG_ROOT%/package`:\\n    1. Package `fmt` built library like `fmt.dylib`, its `header` files and `binaries`(tools) in **build tree** into `%VCPKG_ROOT%/packages/fmt_arm64-osx-dynamic/`\\n4. **install tree** -> `%VCPKG_ROOT%/installed`:\\n    1. Install `fmt`\'s `libs`, `headers` and `tools` in **package tree** into `%VCPKG_ROOT%/installed/arm64-osx-dynamic/lib`, `%VCPKG_ROOT%/installed/arm64-osx-dynamic/include` and `%VCPKG_ROOT%/installed/arm64-osx-dynamic/tools` respectively.\\n\\nAs it outlines, `vcpkg` builds each package separately in **build tree** and **package tree** stages and finally in **install tree** stage `reduce` all packages into the central set in `%VCPKG_ROOT%/installed/arm64-osx-dynamic/`.\\n\\n\x3c!--truncate--\x3e\\n\\n## Classic mode\\n\\nOfficial saying: In Classic mode, vcpkg maintains a central **installed tree** inside the vcpkg instance built up by individual `vcpkg install` and `vcpkg remove` commands. This central set of packages can then be shared by any number of projects.\\n\\nAll packages are installed in a common `%VCPKG_ROOT%/installed` directory.\\n\\n### Classic mode how-to\\n\\nJust run `vcpkg install %package%` to use **classic mode** as the package will be installed into `%VCPKG_ROOT%/installed/`.\\n\\n## Manifest mode\\n\\nOfficial saying: In Manifest mode, vcpkg creates separate **installed trees** for each project and configuration. This allows separate projects to use different versions of libraries. The `vcpkg.json` file and optional `vcpkg-configuration.json` file form a project\'s manifest. The manifest declares the project\'s direct dependencies, version constraints, and registries used.\\n\\nAll packages are installed in their own `${project}/vcpkg_installed` directory inside the `${project}` directory.\\n\\n### Manifest mode how-to\\n\\nCreate `vcpkg.json` in the project, then run `vcpkg install` to use **manifest mode** as all the packages declared in `vcpkg.json` will be installed into `${project}/vcpkg_installed/`.\\n\\n## Useful environment variables for development\\n\\n`CURRENT_INSTALLED_DIR`\\n`CURRENT_PACKAGES_DIR`\\n\\n```sh\\nset(VCPKG_RELEASE_LIBDIR \\"${CURRENT_INSTALLED_DIR}/lib\\")\\nset(VCPKG_DEBUG_LIBDIR \\"${CURRENT_INSTALLED_DIR}/debug/lib\\")\\nset(VCPKG_TOOLS_DIR \\"${CURRENT_INSTALLED_DIR}/tools\\")\\nset(VCPKG_SHARE_DIR \\"${CURRENT_INSTALLED_DIR}/share\\")\\nset(VCPKG_INCLUDE_DIR \\"${CURRENT_INSTALLED_DIR}/include\\")\\n```\\n\\n## Tips and Tricks\\n\\n### How to specify a compiler fof `vcpkg install`?\\n\\nAs `vcpkg` just use `cmake` toolchain to do install, how to set a specific compile is `cmake` things.\\n\\nA fast way is use `CC` and `CXX` environment variables.\\n\\n```sh\\nexport CC=gcc-4.2\\nexport CXX=/usr/bin/g++-4.2\\n```\\n\\nSee more ways at [iar - How to specify a compiler in CMake? - Stack Overflow](https://stackoverflow.com/questions/45933732/how-to-specify-a-compiler-in-cmake)\\n\\n### Install `*-osx-dynamic`\\n\\n```sh\\nvcpkg install libpq --host-triplet=arm64-osx-dynamic --triplet=arm64-osx-dynamic\\n```\\n\\n### Reinstall packages without caching\\n\\n```sh\\nvcpkg remove icu --host-triplet=arm64-osx-dynamic --triplet=arm64-osx-dynamic\\nvcpkg install icu --host-triplet=arm64-osx-dynamic --triplet=arm64-osx-dynamic --no-binarycaching\\nvcpkg install libpq --host-triplet=arm64-osx-dynamic --triplet=arm64-osx-dynamic --binarysource=clear\\nvcpkg remove libpq --host-triplet=arm64-osx-dynamic --triplet=arm64-osx-dynamic\\n\\nvcpkg remove \\"qtbase[gui,widgets]\\" --host-triplet=arm64-osx-dynamic --triplet=arm64-osx-dynamic\\nvcpkg install \\"qtbase[gui,widgets]\\" --host-triplet=arm64-osx-dynamic --triplet=arm64-osx-dynamic --no-binarycaching\\nvcpkg install \\"qtbase[gui,widgets]\\" --host-triplet=arm64-osx-dynamic --triplet=arm64-osx-dynamic --binarysource=clear\\n```\\n\\n### Clean up all packages\\n\\n```sh\\nrm -rf /opt/vcpkg/installed/\\nrm -rf /opt/vcpkg/packages/\\nrm -rf /opt/vcpkg/buildtrees/\\n```\\n\\n### Clean up all caching packages\\n\\n```sh\\nrm -rf ~/.cache/vcpkg/archives/\\n```\\n\\n### `INSTALL_RPATH_USE_LINK_PATH` different behaviours in **manifest mode** and **classic mode**\\n\\n`INSTALL_RPATH_USE_LINK_PATH` will not work properly when being used in the **manifest mode**, because `CMake` will don\'t handle libraries located in `buildtree`:\\n\\n```sh\\nset_target_properties(${PROJECT_NAME} PROPERTIES\\n    INSTALL_RPATH \\"@executable_path/../Frameworks\\"\\n    INSTALL_RPATH_USE_LINK_PATH ON\\n)\\n```\\n\\nAfter `${PROJECT_NAME}` installed, in the **manifest mode**:\\n\\n```sh\\n\u276f otoolll /Users/frankchen/Documents/vcpkg-qt-app/install/./helloworld.app/Contents/MacOS/helloworld\\n          cmd LC_RPATH\\n      cmdsize 48\\n         path @executable_path/../Frameworks (offset 12)\\n```\\n\\nAfter `${PROJECT_NAME}` installed, in the **classic mode**:\\n\\n```sh\\n\u276f otoolll /Users/frankchen/Documents/vcpkg-qt-app/install/./helloworld.app/Contents/MacOS/helloworld\\n          cmd LC_RPATH\\n      cmdsize 56\\n         path /opt/vcpkg/installed/arm64-osx-dynamic/lib (offset 12)\\nLoad command 27\\n      cmd LC_FUNCTION_STARTS\\n--\\n          cmd LC_RPATH\\n      cmdsize 48\\n         path @executable_path/../Frameworks (offset 12)\\n```\\n\\n[wiki-cmake.mdx#RPATH in CMake](./wiki-cmake.mdx#RPATH in CMake)\\n\\n## Resources\\n\\nTODO: Fix qtbase tools/config in release/debug osx  \\n\\nhttps://github.com/microsoft/vcpkg/tree/master/ports/qtbase\\n\\nhttps://learn.microsoft.com/en-us/vcpkg/maintainers/functions/vcpkg_cmake_config_fixup"},{"id":"/fastapi-best-practices","metadata":{"permalink":"/blog/fastapi-best-practices","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/fastapi-best-practices.mdx","source":"@site/../../blog/fastapi-best-practices.mdx","title":"FastAPI Best Practices","description":"Lock Endpoint Request At A Time","date":"2023-06-21T00:00:00.000Z","formattedDate":"June 21, 2023","tags":[{"label":"fastapi","permalink":"/blog/tags/fastapi"},{"label":"python","permalink":"/blog/tags/python"},{"label":"http","permalink":"/blog/tags/http"}],"readingTime":0.83,"hasTruncateMarker":false,"authors":[{"name":"frank"}],"frontMatter":{"foam_template":{"name":"Docs Docusaurus Template","description":"Creates Docusaurus docs/slip","filepath":"docs/lock-http-request.md"},"sidebar_label":"Lock Http Request","description":"Lock Endpoint Request At A Time","keywords":["limit only one access to endpoint at a time","lock access to endpoint at a time"],"image":"https://i.imgur.com/mErPwqL.png","tags":["fastapi","python","http"],"date":"2023-06-21T00:00:00.000Z","author":"frank"},"prevItem":{"title":"Wiki vcpkg","permalink":"/blog/wiki-vcpkg"},"nextItem":{"title":"Communication Between Docker Containers","permalink":"/blog/docker-containers-communication"}},"content":"## Limit Only One Access to Endpoint at a Time\\n\\nLimit only one access to an endpoint at a time with `asyncio.Lock` in `asyncio` in **FastAPI**.\\n\\nimport CodeBlock from \'@theme/CodeBlock\';\\nimport CodeSource from \'!!raw-loader!../code-snippets/python/app_request_lock.py\';\\n\\n<CodeBlock language=\\"python\\" title=\\"../code-snippets/python/app_request_lock.py\\">{CodeSource}</CodeBlock>\\n\\n> NOTE: The `asyncio.Lock` only take effect in the `asyncio` loop level, if using `unicorn` to run server in multiple processes, it can not lock the request! \\n\\nNo limitation.\\n\\nimport CodeSource1 from \'!!raw-loader!../code-snippets/python/app_request_nolock.py\';\\n\\n<CodeBlock language=\\"python\\" title=\\"../code-snippets/python/app_request_nolock.py\\">{CodeSource1}</CodeBlock>\\n\\n\\nLimit only one access to an endpoint at a time with `thread.Lock`\\n\\nLimit only one access to an endpoint at a time with `process.Lock`\\n\\n## Attach A Background Service Into the Application\\n\\nRun a background service behind the FastAPI server:\\n\\n- share the same `asyncio` main loop with the server\\n- the service start when the server starts and stop when the server stops\\n- it should be light-weight and non-CPU heavy workload\\n\\n[Coroutines and Tasks \u2014 Python 3.11.4 documentation](https://docs.python.org/3/library/asyncio-task.html#asyncio.Task.cancel)\\n[Event Loop \u2014 Python 3.11.4 documentation](https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.loop.create_task)\\n\\nimport CodeSourceAppBackgroundService from \'!!raw-loader!../code-snippets/python/app_background_service.py\';\\n\\n<CodeBlock language=\\"python\\" title=\\"../code-snippets/python/app_background_service.py\\">{CodeSourceAppBackgroundService}</CodeBlock>"},{"id":"/docker-containers-communication","metadata":{"permalink":"/blog/docker-containers-communication","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/docker-containers-communication.mdx","source":"@site/../../blog/docker-containers-communication.mdx","title":"Communication Between Docker Containers","description":"Communication Between Docker Containers","date":"2023-06-08T00:00:00.000Z","formattedDate":"June 8, 2023","tags":[{"label":"docker","permalink":"/blog/tags/docker"},{"label":"docker-network","permalink":"/blog/tags/docker-network"},{"label":"postgres","permalink":"/blog/tags/postgres"},{"label":"dev-ops","permalink":"/blog/tags/dev-ops"}],"readingTime":2.155,"hasTruncateMarker":true,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"authors":["frank"],"description":"Communication Between Docker Containers","image":"https://i.imgur.com/mErPwqL.png","tags":["docker","docker-network","postgres","dev-ops"],"date":"2023-06-08T00:00:00.000Z","draft":false},"prevItem":{"title":"FastAPI Best Practices","permalink":"/blog/fastapi-best-practices"},"nextItem":{"title":"Inspect Shared Library","permalink":"/blog/inspect-shared-library"}},"content":"Sometimes between docker containers, we need connect container B from container A to do fast test, etc. For most well-known example, we have `FastAPI` app container connect to `postgres` db container. In addition, it\'s likely to do some sql test on `PostgreSQL` db container in a third container.\\n\\nHere some methods we can use.\\n\\n\x3c!--truncate--\x3e\\n\\n## Using `--link` flag(Legacy)\\n\\nStart a `postgres db` container:\\n\\n```sh\\ndocker run --rm --name postgres-db --detach -e POSTGRES_PASSWORD=mysecretpassword postgres\\n```\\n\\nRun a `postgres client` container to connect the `db` container with user `postgres` and password `mysecretpassword`:\\n\\n```sh\\ndocker run -it --rm --link postgres-db:db postgres psql -h db -U postgres\\npsql (14.3)\\nType \\"help\\" for help.\\n\\npostgres=# SELECT 1;\\n ?column? \\n----------\\n        1\\n(1 row)\\n```\\n\\nOr run a utility container:\\n\\n```sh\\ndocker run -it --rm --link postgres-db:db busybox sh\\n# in `busybox`\\nping db\\n```\\n\\n## Using Default Bridge Network\\n\\nIf you are running your container without specifying attached `network`, it will use the docker `default bridge network`.\\n\\nHowever The `default bridge network` allows container-to-container communication by `IP address` only. To use `hostname` or `alias name` in connecting rather than IP address, see the following methods.\\n\\n> So before connecting, we need get the container IP address by `docker inspect`.\\n\\nStart a `postgres db` container:\\n\\n```sh\\ndocker run --rm --name postgres-db --detach -e POSTGRES_PASSWORD=mysecretpassword postgres\\n```\\n\\nGet the IP address of the `postgres db` container:\\n\\n```sh\\ndocker inspect mynginx | grep IPAddress\\n            \\"IPAddress\\": \\"172.17.0.2\\",\\n```\\n\\nRun a `postgres client` container to connect the `db` container:\\n\\n```sh\\ndocker run -it --rm postgres psql -h \\"172.17.0.2\\" -U postgres\\npsql (14.3)\\nType \\"help\\" for help.\\n\\npostgres=# SELECT 1;\\n ?column? \\n----------\\n        1\\n(1 row)\\n```\\n\\n## Using Private Defined Bridge Network\\n\\nThe `private defined bridge network` will give you more privacy that it only allows only containers belonging to it can talk to each other.\\n\\nMoreover, you can use `hostname` or `alias name` to connect without regard of `IP address` changing due to re-start.\\n\\nCreate a `private bridge network`:\\n\\n```sh\\ndocker network create postgres-net\\n```\\n\\nStart a `postgres db` container:\\n\\n```sh\\ndocker run --rm --net postgres-net --name postgres-db --detach -e POSTGRES_PASSWORD=mysecretpassword postgres\\n```\\n\\nRun a `postgres client` container to connect the `db` container:\\n\\n```sh\\ndocker run -it --rm --net postgres-net postgres psql -h postgres-db -U postgres\\npsql (14.3)\\nType \\"help\\" for help.\\n\\npostgres=# SELECT 1;\\n ?column? \\n----------\\n        1\\n(1 row)\\n```\\n\\n## Use Case in Docker Compose\\n\\nActually, `docker compose` will create its `private bridge network`, and when it start containers, containers will be attached to that network in default.\\n\\nimport CodeBlock from \'@theme/CodeBlock\';\\nimport CodeSource from \'!!raw-loader!./docker-compose-postgres.yml\';\\n\\n<CodeBlock language=\\"yaml\\" title=\\"docker-compose-postgres.yml\\">{CodeSource}</CodeBlock>"},{"id":"/inspect-shared-library","metadata":{"permalink":"/blog/inspect-shared-library","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/inspect-shared-library.md","source":"@site/../../blog/inspect-shared-library.md","title":"Inspect Shared Library","description":"Test Dynamic Library","date":"2023-06-02T00:00:00.000Z","formattedDate":"June 2, 2023","tags":[{"label":"debug","permalink":"/blog/tags/debug"},{"label":"shared library","permalink":"/blog/tags/shared-library"},{"label":"osx","permalink":"/blog/tags/osx"},{"label":"windows","permalink":"/blog/tags/windows"},{"label":"linux","permalink":"/blog/tags/linux"}],"readingTime":1.955,"hasTruncateMarker":false,"authors":[{"name":"Frank Chen","title":"Maintainer of Docusaurus","url":"https://github.com/liviaerxin","imageURL":"https://github.com/liviaerxin.png","key":"frank"}],"frontMatter":{"foam_template":{"name":"Blog Docusaurus Template","description":"Creates Docusaurus blog/slip","filepath":"blog/test-dynamic-library.md"},"authors":["frank"],"description":"Test Dynamic Library","keywords":["debug","dynamic library","shared library"],"image":"https://i.imgur.com/mErPwqL.png","tags":["debug","shared library","osx","windows","linux"],"date":"2023-06-02T00:00:00.000Z","draft":false,"enableComments":true},"prevItem":{"title":"Communication Between Docker Containers","permalink":"/blog/docker-containers-communication"},"nextItem":{"title":"WiFi AutoSwitch Windows","permalink":"/blog/wifi-autoswitch-windows"}},"content":"Concepts:\\n\\n- Show shared libraries dependencies(detect what shared libraries an executable or a another shared libraries depend on)\\n- Check/Test dependent shared libraries loaded successfully\\n\\n## Using `ldd` Command\\n\\nAvailable in Linux:\\n\\n```sh\\nldd /usr/bin/vim\\n\\tlinux-vdso.so.1 (0x00007ffc75fb1000)\\n\\tlibgtk-3.so.0 => /usr/lib/libgtk-3.so.0 (0x00007fa4dcb5e000)\\n\\tlibgdk-3.so.0 => /usr/lib/libgdk-3.so.0 (0x00007fa4dca64000)\\t\\n\\tlibXau.so.6 => /usr/lib/libXau.so.6 (0x00007fa4db7a9000)\\n        ....\\n\\tliblzma.so.5 => /usr/lib/liblzma.so.5 (0x00007fa4db63f000)\\n\\tliblz4.so.1 => /usr/lib/liblz4.so.1 (0x00007fa4db61d000)\\n\\tlibgcrypt.so.20 => /usr/lib/libgcrypt.so.20 (0x00007fa4db4ff000)\\n\\tlibgpg-error.so.0 => /usr/lib/libgpg-error.so.0 (0x00007fa4db4d8000)\\n```\\n\\n## Using `objdump` Command\\n\\nAvailable in Linux:\\n\\n```sh\\nobjdump -p /usr/bin/vim | grep \'NEEDED\'\\n  NEEDED               libpython3.7m.so.1.0\\n  NEEDED               libcrypt.so.2\\n  NEEDED               libpthread.so.0\\n  NEEDED               libdl.so.2\\n  NEEDED               libutil.so.1\\n  NEEDED               libm.so.6\\n  NEEDED               libselinux.so.1\\n  NEEDED               libtinfo.so.6\\n  NEEDED               libacl.so.1\\n  NEEDED               libgpm.so.2\\n  NEEDED               libc.so.6\\n```\\n\\n## Using `readelf` Command\\n\\nAvailable in Linux:\\n\\n```sh\\nreadelf --dynamic /usr/bin/vim | grep NEEDED\\n 0x0000000000000001 (NEEDED)             Shared library: [libpython3.7m.so.1.0]\\n 0x0000000000000001 (NEEDED)             Shared library: [libcrypt.so.2]\\n 0x0000000000000001 (NEEDED)             Shared library: [libpthread.so.0]\\n 0x0000000000000001 (NEEDED)             Shared library: [libdl.so.2]\\n 0x0000000000000001 (NEEDED)             Shared library: [libutil.so.1]\\n 0x0000000000000001 (NEEDED)             Shared library: [libm.so.6]\\n 0x0000000000000001 (NEEDED)             Shared library: [libselinux.so.1]\\n 0x0000000000000001 (NEEDED)             Shared library: [libtinfo.so.6]\\n 0x0000000000000001 (NEEDED)             Shared library: [libacl.so.1]\\n 0x0000000000000001 (NEEDED)             Shared library: [libgpm.so.2]\\n 0x0000000000000001 (NEEDED)             Shared library: [libc.so.6]\\n```\\n\\n## Using `otool` Command\\n\\nAvailable in OSX:\\n\\n```sh\\notool -L libOpenCvSharpExtern.dylib\\n```\\n\\n## Reading the `/proc/<pid>/maps` File\\n\\nAvailable in Linux:\\n\\n```sh\\ncat /proc/179015/maps \\n...\\n7f2cb67c3000-7f2cb67c6000 r--p 00000000 08:13 3810274                    /usr/lib/libnss_files-2.31.so\\n7f2cb67c6000-7f2cb67cd000 r-xp 00003000 08:13 3810274                    /usr/lib/libnss_files-2.31.so\\n..\\n7f2cb6a89000-7f2cb6a8a000 r--p 00002000 08:13 3810903                    /usr/lib/libutil-2.31.so\\n7f2cb6a8a000-7f2cb6a8b000 r--p 00002000 08:13 3810903                    /usr/lib/libutil-2.31.so\\n...\\n7f2cb9802000-7f2cb9803000 rw-p 00000000 00:00 0 \\n7ffe77658000-7ffe7767a000 rw-p 00000000 00:00 0                          [stack]\\n7ffe776c8000-7ffe776cc000 r--p 00000000 00:00 0                          [vvar]\\n7ffe776cc000-7ffe776ce000 r-xp 00000000 00:00 0                          [vdso]\\nffffffffff600000-ffffffffff601000 --xp 00000000 00:00 0                  [vsyscall]\\n```\\n\\n```sh\\nawk \'$NF!~/\\\\.so/{next} {$0=$NF} !a[$0]++\' /proc/179015/maps\\n...\\n/usr/lib/libpython3.8.so.1.0\\n/usr/lib/libgpg-error.so.0.29.0\\n/usr/lib/libgcrypt.so.20.2.5\\n/usr/lib/liblz4.so.1.9.2\\n/usr/lib/liblzma.so.5.2.5\\n/usr/lib/libsystemd.so.0.28.0\\n/usr/lib/libogg.so.0.8.4\\n/usr/lib/libvorbis.so.0.4.8\\n/usr/lib/libblkid.so.1.1.0\\n/usr/lib/libXdmcp.so.6.0.0\\n/usr/lib/libXau.so.6.0.0\\n/usr/lib/libdatrie.so.1.3.5\\n...\\n```\\n\\n## Using `vmmap` Command\\n\\n## Using `ctypes` in Python\\n\\n```py\\nimport ctypes\\nctypes.cdll.LoadLibrary(\\"libOpenCvSharpExtern.so\\")\\nctypes.CDLL(\\"libOpenCvSharpExtern.so\\")\\n```\\n\\n```c\\ndlopen()\\nDYLD_PRINT_LIBRARIES=1 dlopen_test.out /opt/vcpkg/installed/arm64-osx-dynamic/lib/libpng16.dylib\\n```\\n\\n```sh\\nobjdump -p /usr/local/lib/libOpenCvSharpExtern.so\\n```\\n\\n### Using `nm`\\n\\nShow list of symbols:\\n\\n```sh\\n\u276f nm -g /opt/vcpkg/installed/arm64-osx-dynamic/lib/libintl.8.dylib\\n                 U _CFArrayGetCount\\n                 U _CFArrayGetValueAtIndex\\n                 U _CFGetTypeID\\n                 U _CFLocaleCopyPreferredLanguages\\n                 U _CFPreferencesCopyAppValue\\n                 U _CFRelease\\n                 U _CFStringGetCString\\n                 U _CFStringGetTypeID\\n                 U __DefaultRuneLocale\\n                 U ___CFConstantStringClassReference\\n```\\n\\n### Using `dumpbin`\\n\\nAvailable in Windows\\n\\nShow dependent dynamic libraries(`DLL`):\\n\\n```powershell\\ndumpbin /dependents your_dll_file.dll\\n```\\n\\n### Using `Microsoft.PowerShell`\\n\\n```powershell\\n(Get-Command \\"C:\\\\Path\\\\To\\\\Thing.dll\\").FileVersionInfo\\n(Get-Item \\"C:\\\\Windows\\\\System32\\\\nvcuda.dll\\").VersionInfo\\n```\\n\\n## Useful Environment Variables\\n\\nOSX:\\n\\n- `DYLD_LIBRARY_PATH`\\n- `DYLD_PRINT_LIBRARIES`\\n- `DYLD_PRINT_STATISTICS`\\n\\nLinux:\\n\\n- `LD_LIBRARY_PATH`\\n- `LD_DEBUG=libs`\\n\\n## References\\n\\n[Additional MSVC Build Tools](https://learn.microsoft.com/en-us/cpp/build/reference/c-cpp-build-tools)\\n\\n[How to Show All Shared Libraries Used by Executables in Linux](https://www.baeldung.com/linux/show-shared-libraries-executables)"},{"id":"/wifi-autoswitch-windows","metadata":{"permalink":"/blog/wifi-autoswitch-windows","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/wifi-autoswitch-windows.md","source":"@site/../../blog/wifi-autoswitch-windows.md","title":"WiFi AutoSwitch Windows","description":"WiFi AutoSwitch Windows","date":"2023-06-01T00:00:00.000Z","formattedDate":"June 1, 2023","tags":[{"label":"autoswitch","permalink":"/blog/tags/autoswitch"},{"label":"wifi","permalink":"/blog/tags/wifi"},{"label":"windows","permalink":"/blog/tags/windows"}],"readingTime":0.855,"hasTruncateMarker":false,"authors":[{"name":"frank"}],"frontMatter":{"foam_template":{"name":"Docs Docusaurus Template","description":"Creates Docusaurus docs/slip","filepath":"docs/wifi-autoswitch-windows.md"},"sidebar_label":"WiFi AutoSwitch Windows","description":"WiFi AutoSwitch Windows","keywords":["autoswitch","wifi","windows"],"image":"https://i.imgur.com/mErPwqL.png","tags":["autoswitch","wifi","windows"],"date":"2023-06-01T00:00:00.000Z","author":"frank"},"prevItem":{"title":"Inspect Shared Library","permalink":"/blog/inspect-shared-library"},"nextItem":{"title":"Hello from Docusaurus","permalink":"/blog/doc-with-tags"}},"content":"If **autoSwitch** is turned on, it allows Windows to continue looking for other auto-connected wireless networks while connected to the current wireless network. If a higher priority auto-connected wireless network than the currently connected wireless network comes in range, Windows will automatically connect to it instead.\\n\\nIt also needs to work along with `priority` setting.\\n\\nFor example:\\n\\nThere\'re 3 networks of profile name: `TP-Link-1`, `TP-Link-2` and `TP-Link-3`. PC(windows) will try to connect `TP-Link-3` if it\'s in range when it\'s already connected to `TP-Link-1` or `TP-Link-2`.\\n\\n1. Setup `autoswitch`:\\n\\n```sh\\nnetsh wlan set profileparameter name=\\"TP-Link-1\\" autoswitch=Yes\\nnetsh wlan set profileparameter name=\\"TP-Link-2\\" autoswitch=Yes\\nnetsh wlan set profileparameter name=\\"TP-Link-3\\" autoswitch=No\\n```\\n\\n2. Setup `priority`:\\n\\n```sh\\nnetsh wlan set profileorder name=\\"TP-Link-1\\" interface=\\"Wi-Fi\\" priority=3\\nnetsh wlan set profileorder name=\\"TP-Link-2\\" interface=\\"Wi-Fi\\" priority=2\\nnetsh wlan set profileorder name=\\"TP-Link-3\\" interface=\\"Wi-Fi\\" priority=1\\n```\\n\\nother tools:\\n\\nList profile name:\\n\\n```sh\\nnetsh wlan show profiles\\n```\\n\\nList connected WiFi:\\n\\n```sh\\nnetsh wlan show interfaces\\n```\\n\\n[Enable Auto Switch for Wireless Network Connection in Windows 10](https://winaero.com/enable-auto-switch-for-wireless-network-connection-in-windows-10/)\\n\\n[Change WiFi network priority in Windows 10](https://winaero.com/change-wifi-network-priority-in-windows-10/)"},{"id":"doc-with-tags","metadata":{"permalink":"/blog/doc-with-tags","editUrl":"https://github.com/liviaerxin/liviaerxin.github.io/edit/master/_ssg/docusaurus/../../blog/greeting.md","source":"@site/../../blog/greeting.md","title":"Hello from Docusaurus","description":"Create a doc page with rich content.","date":"2023-05-30T00:00:00.000Z","formattedDate":"May 30, 2023","tags":[{"label":"Demo","permalink":"/blog/tags/demo"},{"label":"Getting started","permalink":"/blog/tags/getting-started"}],"readingTime":0.555,"hasTruncateMarker":false,"authors":[{"name":"custom author name"}],"frontMatter":{"description":"Create a doc page with rich content.","slug":"doc-with-tags","tags":["Demo","Getting started"],"date":"2023-05-30T00:00:00.000Z","author":"custom author name"},"prevItem":{"title":"WiFi AutoSwitch Windows","permalink":"/blog/wifi-autoswitch-windows"}},"content":"Are you ready to create the documentation site for your open source project?\\n\\n## Headers\\n\\nwill show up on the table of contents on the upper right\\n\\nSo that your users will know what this page is all about without scrolling down or even without reading too much.\\n\\n## Only h2 and h3 will be in the TOC by default.\\n\\nYou can configure the TOC heading levels either per-document or in the theme configuration.\\n\\nThe headers are well-spaced so that the hierarchy is clear.\\n\\n- lists will help you\\n- present the key points\\n- that you want your users to remember\\n  - and you may nest them\\n    - multiple times"}]}')}}]);