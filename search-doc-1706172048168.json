[{"title":"Awesome Troubleshooting","type":0,"sectionRef":"#","url":"/blog/awesome-troubleshooting","content":"A curated collection of troubleshooting practices: How we spent two weeks hunting an NFS bug in the Linux kernel","keywords":"best-practice troubleshooting"},{"title":"C/C++ Build System","type":0,"sectionRef":"#","url":"/blog/c-build-system","content":"","keywords":"practice avalonia"},{"title":"Build System​","type":1,"pageTitle":"C/C++ Build System","url":"/blog/c-build-system#build-system","content":"Make Ninja MSBuild "},{"title":"Build System Generator​","type":1,"pageTitle":"C/C++ Build System","url":"/blog/c-build-system#build-system-generator","content":"CMake Meson "},{"title":"CI​","type":1,"pageTitle":"C/C++ Build System","url":"/blog/c-build-system#ci","content":""},{"title":"C++ Package Management","type":0,"sectionRef":"#","url":"/blog/c-package-management","content":"vcpkg [wiki vcpkg] conan","keywords":"c++ package vcpkg conan"},{"title":"Generate self-signed SSL/TLS certificate for local IP address or local domain","type":0,"sectionRef":"#","url":"/blog/certificate-sign","content":"","keywords":"Self Signed Certificate"},{"title":"Create root Certificate Authority(CA)​","type":1,"pageTitle":"Generate self-signed SSL/TLS certificate for local IP address or local domain","url":"/blog/certificate-sign#create-root-certificate-authorityca","content":"Generate RootCA.key and RootCA.crt: openssl req -x509 -nodes -new -sha256 -days 1024 -newkey rsa:2048 -keyout RootCA.key -out RootCA.crt -subj &quot;/C=US/CN=Example-Root-CA&quot;  You can change Example-Root-CA to others or add more fields to CA. "},{"title":"Create local server certificate​","type":1,"pageTitle":"Generate self-signed SSL/TLS certificate for local IP address or local domain","url":"/blog/certificate-sign#create-local-server-certificate","content":"Next, we should apply the local CA to sign a certificate for our local server, which will be accessed through the localhost or 127.0.0.1 from our local machine. "},{"title":"Generate Certificate Signing Request(CSR)​","type":1,"pageTitle":"Generate self-signed SSL/TLS certificate for local IP address or local domain","url":"/blog/certificate-sign#generate-certificate-signing-requestcsr","content":"Set up custom DNS in /etc/hosts, /etc/hosts 127.0.0.1 localhost 127.0.0.1 fake1.local 127.0.0.1 fake2.local  Prepare a localhost.conf, localhost.conf [req] default_bits = 2048 distinguished_name = req_distinguished_name req_extensions = req_ext x509_extensions = v3_req prompt = no [req_distinguished_name] countryName = XX stateOrProvinceName = N/A localityName = N/A organizationName = Self-signed certificate commonName = 127.0.0.1: Self-signed certificate [req_ext] subjectAltName = @alt_names [v3_req] subjectAltName = @alt_names [alt_names] IP.1 = 127.0.0.1 DNS.1 = localhost DNS.2 = fake1.local DNS.3 = fake2.local  Generates localhost.key and localhost.csr: openssl req -new -nodes -newkey rsa:2048 -keyout localhost.key -out localhost.csr -config localhost.conf # Or input from line # openssl req -new -nodes -newkey rsa:2048 -keyout localhost.key -out localhost.csr -subj &quot;/C=US/ST=YourState/L=YourCity/O=Example-Certificates/CN=localhost.local&quot;  Verify the Certificate Signing Request(CSR) localhost.csr: openssl req -text -noout -verify -in localhost.csr  "},{"title":"Get local server certificate signed by root CA​","type":1,"pageTitle":"Generate self-signed SSL/TLS certificate for local IP address or local domain","url":"/blog/certificate-sign#get-local-server-certificate-signed-by-root-ca","content":"Submit CSR to the root CA to let the root CA to sign a certificate for our locahost server. Generates localhost.crt by using CSR localhost.csr with extensions, openssl x509 -req -sha256 -days 1024 -in localhost.csr -CA RootCA.crt -CAkey RootCA.key -CAcreateserial -extensions req_ext -extfile localhost.conf -out localhost.crt  View the localhost.crt: openssl x509 -text -noout -in localhost.crt  Verify the localhost.crt: openssl verify -verbose -CAfile RootCA.crt localhost.crt  danger If X509 extensions(subjectAltName) are missing from the certificate, the browser will still report security issues. note Using the CA and Subject as the same one, the step of creating the local CA can be skipped. openssl req -x509 -nodes -days 730 -newkey rsa:2048 -keyout localhost.key -out localhost.crt -config localhost.conf  "},{"title":"Use the server certificate​","type":1,"pageTitle":"Generate self-signed SSL/TLS certificate for local IP address or local domain","url":"/blog/certificate-sign#use-the-server-certificate","content":"Run up a node https server to use the generated local server certificate. npx http-server -p 8082 --ssl --cert localhost.crt --key localhost.key  Then visit: https://127.0.0.1:8082/https://localhost:8082/ The browser will give you security warning as the local root CA is not trusted in default. "},{"title":"Trust the root CA​","type":1,"pageTitle":"Generate self-signed SSL/TLS certificate for local IP address or local domain","url":"/blog/certificate-sign#trust-the-root-ca","content":"Install CA certificate RootCA.crt into each system trust store or each browser. Windows system trust storeUbuntu system trust storemacOS system trust store Then visit again, the browser will show green! "},{"title":"Troubleshooting​","type":1,"pageTitle":"Generate self-signed SSL/TLS certificate for local IP address or local domain","url":"/blog/certificate-sign#troubleshooting","content":""},{"title":"Chrome red security warning​","type":1,"pageTitle":"Generate self-signed SSL/TLS certificate for local IP address or local domain","url":"/blog/certificate-sign#chrome-red-security-warning","content":"Go to Developer Tools.Click Security tab.Check Security overview issues. "},{"title":"Resources​","type":1,"pageTitle":"Generate self-signed SSL/TLS certificate for local IP address or local domain","url":"/blog/certificate-sign#resources","content":"How to create an HTTPS certificate for localhost domains · GitHub How to add X.509 extensions to certificate OpenSSL | GoLinuxCloud GitHub - FiloSottile/mkcert: A simple zero-config tool to make locally trusted development certificates with any names you'd like. "},{"title":"ARM64/AArch64 Assembly Cheat Sheet","type":0,"sectionRef":"#","url":"/blog/cheatsheet-assembly-arm64","content":"","keywords":"AArch64 ARM64 Cheat sheet"},{"title":"Registers​","type":1,"pageTitle":"ARM64/AArch64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-arm64#registers","content":"Register\tLow 32-bits\tCalling conventionGeneral-purpose registers: x0\tw0 x1\tw1 x2\tw2 Special-purpose registers: xzr\twzr\tZero register sp\t-\tStack pointer "},{"title":"Data type​","type":1,"pageTitle":"ARM64/AArch64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-arm64#data-type","content":"Definition size\tDefinition instruction8 bit\tbyte 16 bit\thword 32 bit\tword 64 bit\tdword "},{"title":"Move​","type":1,"pageTitle":"ARM64/AArch64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-arm64#move","content":"movz + movk // Load the 64-bit integer `0x1a2b3c4d1a2b3c4d` from the immediate movz x1, #0x3c4d movk x1, #0x1a2b, lsl #16 movk x1, #0x3c4d, lsl #32 movk x1, #0x1a2b, lsl #48  "},{"title":"Load​","type":1,"pageTitle":"ARM64/AArch64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-arm64#load","content":"Load instruction\tPurposeldr x0, [x1]\tload 64-bit ldr w0, [x1]\tload 32-bit ldrh w0, [x1]\tload 16-bit ldrb w0, [x1]\tload 8-bit .data int32_var: .word 0x1a2b3c4d  adr adr x20, int32_var ldr x2, [x20]  adrp + add adrp x20, int32_var add x20, x20, :lo12:int32_var ldr x2, [x20]  in macOS m1, adrp x20, int32_var@PAGE add x20, x20, int32_var@PAGEOFF ldr x2, [x20]  "},{"title":"Store​","type":1,"pageTitle":"ARM64/AArch64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-arm64#store","content":""},{"title":"Resources​","type":1,"pageTitle":"ARM64/AArch64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-arm64#resources","content":"ios-resources/bits/arm64.md at master · Siguza/ios-resources · GitHub asm_book/section_1/regs/ldr.md at main · pkivolowitz/asm_book · GitHub Exploring AArch64 assembler – Chapter 5 https://peterdn.com/post/2020/08/22/hello-world-in-arm64-assembly/ https://gpanders.com/blog/exploring-mach-o-part-1/ https://iitd-plos.github.io/col718/ref/arm-instructionset.pdf https://modexp.wordpress.com/2018/10/30/arm64-assembly/#registers https://stackoverflow.com/questions/41906688/what-are-the-semantics-of-adrp-and-adrl-instructions-in-arm-assembly "},{"title":"x64 Assembly Cheat Sheet","type":0,"sectionRef":"#","url":"/blog/cheatsheet-assembly-x64","content":"","keywords":"x64 NASM cheat sheet"},{"title":"Registers​","type":1,"pageTitle":"x64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-x64#registers","content":"Register\tLow 32-bits\tLow 16-bits\tLow 8-bit\tHigh 8-bits\tCalling convention\tCallee-saved?General-purpose: %rax\t%eax\t%ax\t%al\t%ah\tReturn value\tNo %rbx\t%ebx\t%bx\t%bl\t%bh\t-\tYes %rcx\t%ecx\t%cx\t%cl\t%ch\t4th argument\tYes %rdx\t%edx\t%dx\t%dl\t%dh\t3th argument\tYes %rsi\t%esi\t%si\t%sil\t-\t2st argument\tNo %rdi\t%edi\t%di\t%dil\t-\t1st argument\tNo %r8\t%r8d\t%r8w\t%r8b\t-\t5th argument\tNo %r9\t%r9d\t%r9w\t%r9b\t-\t6th argument\tNo %r10\t%r10d\t%r10w\t%r10b\t-\t-\tNo %r11\t%r11d\t%r11w\t%r11b\t-\t-\tNo %r12\t%r12d\t%r12w\t%r12b\t-\t-\tYes %r13\t%r13d\t%r13w\t%r13b\t-\t-\tYes %r14\t%r14d\t%r14w\t%r14b\t-\t-\tYes %r15\t%r15d\t%r15w\t%r15b\t-\t-\tYes Special-purpose: %rsp\t%esp\t%sp\t%spl\t–\tStack pointer\tYes %rbp\t%ebp\t%bp\t%bpl\t–\tBase pointer\tYes %rip\t%eip\t%ip\t-\t–\tInstruction pointer\t- %rflags\t%eflags\t%flags\t-\t–\tFlags and condition codes\tNo "},{"title":"Data Type​","type":1,"pageTitle":"x64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-x64#data-type","content":"Definition size\tNASM\t-\tGAS\tsuffix8 bit\tdb\tBYTE\tbyte\tb 16 bit\tdw\tWORD\tshort/word/2byte\tw 32 bit\tdd\tDWORD\tlong/int/4byte\tl 64 bit\tddq/do\tQWORD\tquad/8byte\tq float\tdd\t-\t- double\tdq\t-\t- extended precision\tdt\t-\t- string\t-\t-\tascii/asciz\t- .data int8 .db 0x7f msg .db 0x7f, 'E', 'L', 'F', 1, 1, 1, 0  .data int8 .byte 0x7f msg .byte 0x7f, 'E', 'L', 'F', 1, 1, 1, 0 ms .asciz &quot;ELF&quot; ms .ascii &quot;ELF&quot;, 0x0  "},{"title":"Memory and Addressing Modes​","type":1,"pageTitle":"x64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-x64#memory-and-addressing-modes","content":"mov eax, [ebx] ; Move the 4 bytes in memory at the address contained in EBX into EAX mov [var], ebx ; Move the contents of EBX into the 4 bytes at memory address var. (Note, var is a 32-bit constant). mov eax, [esi-4] ; Move 4 bytes at memory address ESI + (-4) into EAX mov [esi+eax], cl ; Move the contents of CL into the byte at address ESI+EAX mov edx, [esi+4*ebx] ; Move the 4 bytes of data at address ESI+4*EBX into EDX  mov (%ebx), %eax /* Load 4 bytes from the memory address in EBX into EAX. */ mov %ebx, var(,1) /* Move the contents of EBX into the 4 bytes at memory address var. (Note, var is a 32-bit constant). */ mov -4(%esi), %eax /* Move 4 bytes at memory address ESI + (-4) into EAX. */ mov %cl, (%esi,%eax,1) /* Move the contents of CL into the byte at address ESI+EAX. */ mov (%esi,%ebx,4), %edx /* Move the 4 bytes of data at address ESI+4*EBX into EDX. */  "},{"title":"Size Directives in mov​","type":1,"pageTitle":"x64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-x64#size-directives-in-mov","content":"mov BYTE [ebx], 2 ; Move 2 into the single byte at the address stored in EBX. mov WORD [ebx], 2 ; Move the 16-bit integer representation of 2 into the 2 bytes starting at the address in EBX. mov DWORD [ebx], 2 ; Move the 32-bit integer representation of 2 into the 4 bytes starting at the address in EBX.  movb $2, (%ebx) /* Move 2 into the single byte at the address stored in EBX. */ movw $2, (%ebx) /* Move the 16-bit integer representation of 2 into the 2 bytes starting at the address in EBX. */ movl $2, (%ebx) /* Move the 32-bit integer representation of 2 into the 4 bytes starting at the address in EBX. */  movsbl %al, %edx # copy 1-byte %al, sign-extend into 4-byte %edx movzbl %al, %edx # copy 1-byte %al, zero-extend into 4-byte %edx  "},{"title":"Common instructions​","type":1,"pageTitle":"x64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-x64#common-instructions","content":""},{"title":"Mov and lea​","type":1,"pageTitle":"x64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-x64#mov-and-lea","content":"mov src, dst # general form of instruction dst = src mov $0, %eax # %eax = 0 movb %al, 0x409892 # write to address 0x409892 low-byte of %eax mov 8(%rsp), %eax # %eax = value read from address %rsp + 8 lea 0x20(%rsp), %rdi # %rdi = %rsp + 0x20 (no dereference!) lea (%rdi,%rdx,1), %rax # %rax = %rdi + %rdx  "},{"title":"Stack operation​","type":1,"pageTitle":"x64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-x64#stack-operation","content":"push %rbx # push value of %rbx onto stack pushq $0x3 # push immediate value 3 onto stack sub $0x10, %rsp # adjust stack pointer to set aside 16 more bytes pop %rax # pop topmost value from stack into register %rax add $0x10, %rsp # adjust stack point to remove topmost 16 bytes  "},{"title":"Calling Convention​","type":1,"pageTitle":"x64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-x64#calling-convention","content":"mov $0x3, %rdi # first arg is passed in %rdi mov $0x7, %rsi # second arg is passed in %rsi callq binky # transfers control to function binky  "},{"title":"Program structure​","type":1,"pageTitle":"x64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-x64#program-structure","content":"global &lt;entry&gt; -&gt; exposes entry pointextern &lt;function&gt; -&gt; declares a function in another linked .o file (e.g. C function, other asm file)section &lt;sectiontype&gt; -&gt; sets section, usually: .text -&gt; program code.data -&gt; data The program entry point of a standalone program is the label _start. When compiled with gcc, C provides _start, which inits and then jumps to main, which should then be implemented by the program. "},{"title":"Syscalls​","type":1,"pageTitle":"x64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-x64#syscalls","content":"put syscall number in EAX (e.g. on Linux: 60 for exit, 1 for write to stdout)put arguments in the registers (see above) like when calling a C functionexecute the syscall instruction "},{"title":"Calling C functions​","type":1,"pageTitle":"x64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-x64#calling-c-functions","content":""},{"title":"Assemble​","type":1,"pageTitle":"x64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-x64#assemble","content":"Assemble: nasm -felf64 -o &lt;object&gt; &lt;filename&gt;Link with ld: ld -o &lt;output&gt; &lt;object&gt;Link with gcc: gcc -o &lt;output&gt; &lt;object&gt; "},{"title":"Resources​","type":1,"pageTitle":"x64 Assembly Cheat Sheet","url":"/blog/cheatsheet-assembly-x64#resources","content":"Assembly 1: Basics – CS 61 2018 CS107 Guide to x86-64 x64 NASM Cheat Sheet · GitHub nasmtutorial gasexamples Guide to x86 Assembly "},{"title":"Docker Cheat Sheet","type":0,"sectionRef":"#","url":"/blog/cheatsheet-docker","content":"","keywords":"docker docker compose cheatsheet"},{"title":"Docker​","type":1,"pageTitle":"Docker Cheat Sheet","url":"/blog/cheatsheet-docker#docker","content":""},{"title":"Test image busybox​","type":1,"pageTitle":"Docker Cheat Sheet","url":"/blog/cheatsheet-docker#test-image-busybox","content":"Famous busybox image that provide many common UNIX utilities for testing. docker run -it --rm --privileged busybox sh  "},{"title":"Find the IP address of Docker container​","type":1,"pageTitle":"Docker Cheat Sheet","url":"/blog/cheatsheet-docker#find-the-ip-address-of-docker-container","content":"docker inspect \\ -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' \\ nfs  "},{"title":"Delete all containers(include all status of running, stopped, created)​","type":1,"pageTitle":"Docker Cheat Sheet","url":"/blog/cheatsheet-docker#delete-all-containersinclude-all-status-of-running-stopped-created","content":"docker rm -f $(docker ps -a -q)  "},{"title":"Delete the container by image name​","type":1,"pageTitle":"Docker Cheat Sheet","url":"/blog/cheatsheet-docker#delete-the-container-by-image-name","content":"docker rm -f $(docker ps -a -q --filter ancestor=&lt;image name here!&gt;)  drmi() { docker rm -f $(docker ps -a | awk -v i=&quot;^$1.*&quot; '{if($2~i){print$1}}'); }  "},{"title":"Delete all volumes​","type":1,"pageTitle":"Docker Cheat Sheet","url":"/blog/cheatsheet-docker#delete-all-volumes","content":"docker volume rm $(docker volume ls -q)  "},{"title":"Keep container running for for testing and debugging​","type":1,"pageTitle":"Docker Cheat Sheet","url":"/blog/cheatsheet-docker#keep-container-running-for-for-testing-and-debugging","content":"# Use -t(-tty) docker run --rm -d -t busybox  docker run --rm -d busybox tail -f /dev/null  docker run --rm -d busybox sleep infinity  "},{"title":"Docker Compose​","type":1,"pageTitle":"Docker Cheat Sheet","url":"/blog/cheatsheet-docker#docker-compose","content":""},{"title":"Check docker-compose.yml rendering​","type":1,"pageTitle":"Docker Cheat Sheet","url":"/blog/cheatsheet-docker#check-docker-composeyml-rendering","content":"docker compose --env-file .env --env-file .prod.env config  "},{"title":"Rebuild image and restart a service which you specified​","type":1,"pageTitle":"Docker Cheat Sheet","url":"/blog/cheatsheet-docker#rebuild-image-and-restart-a-service-which-you-specified","content":"docker-compose up --no-deps web-app -d  "},{"title":"Remove a service​","type":1,"pageTitle":"Docker Cheat Sheet","url":"/blog/cheatsheet-docker#remove-a-service","content":"docker-compose rm -s -v web-auth  "},{"title":"env_file in docker-compose.yml​","type":1,"pageTitle":"Docker Cheat Sheet","url":"/blog/cheatsheet-docker#env_file-in-docker-composeyml","content":"env_file equals environment functions.If you use both the env_file and environment attribute, environment variables set by environment take precedence.env_file not used for variables substitution in docker-compose.yml fileenv_file is not the same as --env-file used in docker-compose --env-file cli. --env-file .env.prod will be used for interpolation for docker-compose.yml file. Variables resolved from env_file but not taking effect in docker-compose.yaml docker compose --env-file .env --env-file .prod.env up -d  "},{"title":"Exclude sub folders when mounting a local folder​","type":1,"pageTitle":"Docker Cheat Sheet","url":"/blog/cheatsheet-docker#exclude-sub-folders-when-mounting-a-local-folder","content":"It's very useful when developing a node project. That will help only mount the local source codes while excluding the local node_modules folder only in the container. version: &quot;3&quot; services: node: image: &quot;node:16&quot; working_dir: /home/node/app volumes: - ./:/home/node/app - /home/node/app/node_modules expose: - &quot;8081&quot; command: &quot;npm start&quot;  "},{"title":"Code Snippet Management","type":0,"sectionRef":"#","url":"/blog/code-snippet-management","content":"","keywords":"code snippet manager"},{"title":"CIL(Common Intermediate Language)","type":0,"sectionRef":"#","url":"/blog/common-intermediate-language","content":"","keywords":""},{"title":"What is CIl/IL​","type":1,"pageTitle":"CIL(Common Intermediate Language)","url":"/blog/common-intermediate-language#what-is-cilil","content":"For C# or Java, the program is not directly compiled to machine code, but intermediate language code. For C#, the intermediate code is called Common Intermediate Language(CIL, or IL). So whether the *.dll or *.exe compiled from C#, is composed of IL code and its corresponding meta data. At runtime, the JIT(Just-In-Compiler) compile the IL code to the native machine code. "},{"title":"What is JIT​","type":1,"pageTitle":"CIL(Common Intermediate Language)","url":"/blog/common-intermediate-language#what-is-jit","content":"./ilasm ~/Documents/peggy-foam-wiki/docs/IL/test/test.il -dll ./ildasm ~/Documents/peggy-foam-wiki/docs/IL/test/test.dll -t dotnet myapp.dll  "},{"title":"Traefik Docker Cheat Sheet","type":0,"sectionRef":"#","url":"/blog/cheatsheet-traefik-docker","content":"","keywords":"Cheatsheet Traefik"},{"title":"Redirect root path / to a subpath​","type":1,"pageTitle":"Traefik Docker Cheat Sheet","url":"/blog/cheatsheet-traefik-docker#redirect-root-path--to-a-subpath","content":"The goal is to redirect root path / to sub path /mtr that's an ingress for a web service: http://127.0.0.1 -&gt; http://127.0.0.1/mtrhttp://127.0.0.1 -&gt; http://127.0.0.1/mtrhttps://127.0.0.1/something -&gt; no redirect It works for Traefik 2.0 services: traefik: image: traefik:v2.10 command: - --api.insecure=true - --providers.docker=true - --providers.docker.exposedbydefault=false - --entrypoints.web.address=:80 ports: - 80:80 - 8080:8080 # Web UI Port volumes: - /var/run/docker.sock:/var/run/docker.sock:ro labels: - traefik.enable=true # Redirection from `http://xxx.com` to `http://xxx.com/foo` - traefik.http.routers.domain.entrypoints=web - traefik.http.routers.domain.rule=Path(`/`) - traefik.http.routers.domain.service=noop@internal - traefik.http.routers.domain.middlewares=to-foo@docker - traefik.http.middlewares.to-foo.redirectregex.permanent=true - traefik.http.middlewares.to-foo.redirectregex.regex=^http://([^/]+)/?$ - traefik.http.middlewares.to-foo.redirectregex.replacement=http://$${1}/foo foo: image: traefik/whoami:v1.10 hostname: foo.com labels: - traefik.enable=true # just to ingress `http://xxx.com/foo` - traefik.http.routers.foo.entrypoints=web - traefik.http.routers.foo.rule=PathPrefix(`/foo`)  "},{"title":"Route a prefix to a service​","type":1,"pageTitle":"Traefik Docker Cheat Sheet","url":"/blog/cheatsheet-traefik-docker#route-a-prefix-to-a-service","content":"Match a request with a prefix /bar, strip the prefix and route it to the bar service, bar: image: traefik/whoami:v1.10 hostname: bar.com labels: - traefik.enable=true # ingress `http://xxx.com/bar/xyz` and send `http://xxx.com/xyz` to `bar` service - traefik.http.routers.bar.entrypoints=web - traefik.http.routers.bar.rule=PathPrefix(`/bar`) - traefik.http.routers.bar.middlewares=bar-strip-prefix@docker - traefik.http.middlewares.bar-strip-prefix.stripprefix.prefixes=/bar  "},{"title":"Specify a custom port for the container​","type":1,"pageTitle":"Traefik Docker Cheat Sheet","url":"/blog/cheatsheet-traefik-docker#specify-a-custom-port-for-the-container","content":"By default, Traefik used the first exposed port of a container, if a container exposes multiple ports, set traefik.http.services.xxx.loadbalancer.server.port to override that port. bar12345: image: traefik/whoami:v1.10 hostname: bar12345.com environment: WHOAMI_PORT_NUMBER: 12345 labels: - traefik.enable=true - traefik.http.routers.bar12345.entrypoints=web - traefik.http.routers.bar12345.rule=PathPrefix(`/bar12345`) - traefik.http.routers.bar12345.service=bar12345 # Tell Traefik to use the port 12345 to connect to `bar12345` service - traefik.http.services.bar12345.loadbalancer.server.port=12345  "},{"title":"Resources​","type":1,"pageTitle":"Traefik Docker Cheat Sheet","url":"/blog/cheatsheet-traefik-docker#resources","content":"URL Redirect abc.com to xyz.com - Traefik v2 (latest) - Traefik Labs Community Forum Traefik redirect / (root) to sub path with Docker labels · GitHub "},{"title":"Data Center","type":0,"sectionRef":"#","url":"/blog/data-center","content":"","keywords":""},{"title":"Economic Data​","type":1,"pageTitle":"Data Center","url":"/blog/data-center#economic-data","content":"FRED ECONOMIC DATA US inflation cpi "},{"title":"Tools","type":0,"sectionRef":"#","url":"/blog/diagram-tools","content":"","keywords":""},{"title":"Generic Tools​","type":1,"pageTitle":"Tools","url":"/blog/diagram-tools#generic-tools","content":"drawio: draw.io is a JavaScript, client-side editor for general diagramming and whiteboarding Intelligent Diagramming | Lucidchart The Visual Collaboration Platform for Every Team | Miro "},{"title":"Code as Diagram Tools​","type":1,"pageTitle":"Tools","url":"/blog/diagram-tools#code-as-diagram-tools","content":"GitHub - mermaid-js/mermaid: Generation of diagrams like flowcharts or sequence diagrams from text in a similar manner as markdown GitHub - plantuml/plantuml: Generate diagrams from textual description "},{"title":"ERD Diagram Tools​","type":1,"pageTitle":"Tools","url":"/blog/diagram-tools#erd-diagram-tools","content":""},{"title":"Hello from Docusaurus","type":0,"sectionRef":"#","url":"/blog/doc-with-tags","content":"","keywords":""},{"title":"Headers​","type":1,"pageTitle":"Hello from Docusaurus","url":"/blog/doc-with-tags#headers","content":"will show up on the table of contents on the upper right So that your users will know what this page is all about without scrolling down or even without reading too much. "},{"title":"Only h2 and h3 will be in the TOC by default.​","type":1,"pageTitle":"Hello from Docusaurus","url":"/blog/doc-with-tags#only-h2-and-h3-will-be-in-the-toc-by-default","content":"You can configure the TOC heading levels either per-document or in the theme configuration. The headers are well-spaced so that the hierarchy is clear. lists will help youpresent the key pointsthat you want your users to remember and you may nest them multiple times "},{"title":"Network Cheat Sheet","type":0,"sectionRef":"#","url":"/blog/cheatsheet-network","content":"","keywords":"Network Cheat Sheet"},{"title":"Get IP address​","type":1,"pageTitle":"Network Cheat Sheet","url":"/blog/cheatsheet-network#get-ip-address","content":"Linux rms@rms:~$ ip addr  Windows PS C:\\Users\\Frank&gt; ipconfig  PS C:\\Users\\Frank&gt; netsh interface ip show address  "},{"title":"Get IP address of a specific network interface​","type":1,"pageTitle":"Network Cheat Sheet","url":"/blog/cheatsheet-network#get-ip-address-of-a-specific-network-interface","content":"Linux rms@rms:~$ ip addr show enp0s31f6 5: enp0s31f6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 00:4e:01:fc:39:50 brd ff:ff:ff:ff:ff:ff inet 10.6.64.184/24 brd 10.6.64.255 scope global enp0s31f6 valid_lft forever preferred_lft forever inet6 fe80::24e:1ff:fefc:3950/64 scope link valid_lft forever preferred_lft forever  rms@rms:~$ hostname -I | awk '{print $1}' 10.6.64.184  Windows PS C:\\Users\\Frank&gt; netsh interface ip show address &quot;Ethernet&quot; Configuration for interface &quot;Ethernet&quot; DHCP enabled: Yes IP Address: 10.6.64.243 Subnet Prefix: 10.6.64.0/24 (mask 255.255.255.0) Default Gateway: 10.6.64.1 Gateway Metric: 0 InterfaceMetric: 25  PS C:\\Users\\Frank&gt; netsh interface ip show address &quot;Ethernet&quot; | findstr &quot;IP Address&quot;  "},{"title":"Show Routing Table​","type":1,"pageTitle":"Network Cheat Sheet","url":"/blog/cheatsheet-network#show-routing-table","content":"# linux route # osx netstat -rn  The -r flag means to show routes. The -n flag means to not resolve IPs to hostnames. "},{"title":"Find Gateway Used for Routing​","type":1,"pageTitle":"Network Cheat Sheet","url":"/blog/cheatsheet-network#find-gateway-used-for-routing","content":"# linux ip route get 8.8.8.8 # osx route get 8.8.8.8  "},{"title":"Show Routes across Network​","type":1,"pageTitle":"Network Cheat Sheet","url":"/blog/cheatsheet-network#show-routes-across-network","content":"traceroute # en0 interface traceroute -i en0  "},{"title":"Ping Through Specific Interface​","type":1,"pageTitle":"Network Cheat Sheet","url":"/blog/cheatsheet-network#ping-through-specific-interface","content":"# linux ping -I en0 sslvpn.astri.org # osx ping -b en0 sslvpn.astri.org  "},{"title":"Find Out Address Used by Which Process​","type":1,"pageTitle":"Network Cheat Sheet","url":"/blog/cheatsheet-network#find-out-address-used-by-which-process","content":"# osx netstat -avn -p tcp  "},{"title":"Add a Route​","type":1,"pageTitle":"Network Cheat Sheet","url":"/blog/cheatsheet-network#add-a-route","content":"# osx route -n add 10.0.0.0/24 10.0.0.1 # linux route -n add -net 10.0.0.0/24 gw 10.0.0.1  "},{"title":"FireWall Rule​","type":1,"pageTitle":"Network Cheat Sheet","url":"/blog/cheatsheet-network#firewall-rule","content":"osx: # show all information/stats sudo pfctl -sa # show rules sudo pfctl -sr # sanity check edited configuration file sudo pfctl -v -n -f /etc/pf.conf # load pf with new rules sudo pfctl -f /etc/pf.conf # enable pf sudo pfctl -e # disable pf sudo pfctl -d # add information on the fly sudo pfctl -t localsub -T add 127.0.0.0/24 # flush added rules later sudo pfctl -Fa -f /etc/pf.conf sudo pfctl -si sudo pfctl -q  "},{"title":"Get Geolocation of IP Address​","type":1,"pageTitle":"Network Cheat Sheet","url":"/blog/cheatsheet-network#get-geolocation-of-ip-address","content":"curl ipinfo.io/103.216.223.161  "},{"title":"Packet Analyzer​","type":1,"pageTitle":"Network Cheat Sheet","url":"/blog/cheatsheet-network#packet-analyzer","content":"# list which interfaces are available for capture tcpdump --list-interfaces # capture all packets in any interface sudo tcpdump --interface any # limit the number of packets captured then stop `-c number` sudo tcpdump -i any -c 5 # disable name resolution with using `-n` and port resolution with `-nn` sudo tcpdump -i any -c5 -nn # filter packets by protocol, only capture `ICMP` packets sudo tcpdump -i any -c5 icmp # capture packets related with host `8.8.8.8` sudo tcpdump -i any -c5 -nn host 8.8.8.8 # capture packets related with port `80` sudo tcpdump -i any -c5 -nn port 80 # capture packets with source address 192.168.0.1 sudo tcpdump -i any -c5 -nn src 192.168.0.1 # capture packets with destination address 8.8.8.8 sudo tcpdump -i any -c5 -nn dst 8.8.8.8  "},{"title":"USB Virtual Ethernet​","type":1,"pageTitle":"Network Cheat Sheet","url":"/blog/cheatsheet-network#usb-virtual-ethernet","content":"An explanation on the USB virtual ethernet "},{"title":"Access WSL 2 from local area network(LAN)​","type":1,"pageTitle":"Network Cheat Sheet","url":"/blog/cheatsheet-network#access-wsl-2-from-local-area-networklan","content":"After enabling systemd in WSL 2, I have to forward the Windows host port to the WSL 2 distribution. "},{"title":"Find WSL 2 IP address that can be reached from Windows host​","type":1,"pageTitle":"Network Cheat Sheet","url":"/blog/cheatsheet-network#find-wsl-2-ip-address-that-can-be-reached-from-windows-host","content":"$ ip addr show eth0 2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1420 qdisc mq state UP group default qlen 1000 link/ether 00:15:5d:98:b5:99 brd ff:ff:ff:ff:ff:ff inet 172.29.6.23/20 brd 172.29.15.255 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::215:5dff:fe98:b599/64 scope link valid_lft forever preferred_lft forever  "},{"title":"Add proxy​","type":1,"pageTitle":"Network Cheat Sheet","url":"/blog/cheatsheet-network#add-proxy","content":"netsh interface portproxy add v4tov4 listenport=8082 connectport=8082 connectaddress=172.29.6.23,127.0.0.1  "},{"title":"[Optional] Add firewall rule​","type":1,"pageTitle":"Network Cheat Sheet","url":"/blog/cheatsheet-network#optional-add-firewall-rule","content":"netsh advfirewall firewall add rule name= &quot;Open Port 8082&quot; dir=in action=allow protocol=TCP localport=8082  "},{"title":"Check current proxy​","type":1,"pageTitle":"Network Cheat Sheet","url":"/blog/cheatsheet-network#check-current-proxy","content":"netsh interface portproxy show all  "},{"title":"Clean up​","type":1,"pageTitle":"Network Cheat Sheet","url":"/blog/cheatsheet-network#clean-up","content":"netsh interface portproxy delete v4tov4 listenport=8082  netsh advfirewall firewall delete rule name=&quot;Open port 8082&quot;  "},{"title":"Share Data between Docker Containers","type":0,"sectionRef":"#","url":"/blog/docker-containers-data-sharing","content":"","keywords":"Docker Containters Data Sharing"},{"title":"Use a volume to bind a local folder​","type":1,"pageTitle":"Share Data between Docker Containers","url":"/blog/docker-containers-data-sharing#use-a-volume-to-bind-a-local-folder","content":"In default, the volume is created by Docker and its corresponding folder resides in Docker managed folder like /var/lib/docker/volumes/: $ docker create volume xxx  $ docker volume inspect xxx [ { &quot;CreatedAt&quot;: &quot;2023-07-19T14:41:18+08:00&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: {}, &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/xxx/_data&quot;, &quot;Name&quot;: &quot;xxx&quot;, &quot;Options&quot;: {}, &quot;Scope&quot;: &quot;local&quot; } ]  However, sometimes you would like to bind the volume into a specified local folder(like /data/volumes/testvol) in hosts(only available in Linux) $ docker volume create --opt type=none --opt o=bind --opt device=/data/volumes/testvol testvol  $ docker inspect testvol [ { &quot;CreatedAt&quot;: &quot;2023-07-13T04:36:16Z&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: {}, &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/testvol/_data&quot;, &quot;Name&quot;: &quot;testvol&quot;, &quot;Options&quot;: { &quot;device&quot;: &quot;/data/volumes/testvol&quot;, &quot;o&quot;: &quot;bind&quot;, &quot;type&quot;: &quot;none&quot; }, &quot;Scope&quot;: &quot;local&quot; }  In Docker compose yaml, services: frontend: image: node:lts volumes: - testvol:/home/node/app volumes: db-data: testvol: driver: local driver_opts: type: none o: bind device: /data/volumes/testvol  "},{"title":"Use NFS volume​","type":1,"pageTitle":"Share Data between Docker Containers","url":"/blog/docker-containers-data-sharing#use-nfs-volume","content":""},{"title":"Use Samba volume​","type":1,"pageTitle":"Share Data between Docker Containers","url":"/blog/docker-containers-data-sharing#use-samba-volume","content":""},{"title":"References​","type":1,"pageTitle":"Share Data between Docker Containers","url":"/blog/docker-containers-data-sharing#references","content":"Volumes | Docker Documentation "},{"title":"Communication Between Docker Containers","type":0,"sectionRef":"#","url":"/blog/docker-containers-communication","content":"","keywords":""},{"title":"Using --link flag(Legacy)​","type":1,"pageTitle":"Communication Between Docker Containers","url":"/blog/docker-containers-communication#using---link-flaglegacy","content":"Start a postgres db container: docker run --rm --name postgres-db --detach -e POSTGRES_PASSWORD=mysecretpassword postgres  Run a postgres client container to connect the db container with user postgres and password mysecretpassword: docker run -it --rm --link postgres-db:db postgres psql -h db -U postgres psql (14.3) Type &quot;help&quot; for help. postgres=# SELECT 1; ?column? ---------- 1 (1 row)  Or run a utility container: docker run -it --rm --link postgres-db:db busybox sh # in `busybox` ping db  "},{"title":"Using Default Bridge Network​","type":1,"pageTitle":"Communication Between Docker Containers","url":"/blog/docker-containers-communication#using-default-bridge-network","content":"If you are running your container without specifying attached network, it will use the docker default bridge network. However The default bridge network allows container-to-container communication by IP address only. To use hostname or alias name in connecting rather than IP address, see the following methods. So before connecting, we need get the container IP address by docker inspect. Start a postgres db container: docker run --rm --name postgres-db --detach -e POSTGRES_PASSWORD=mysecretpassword postgres  Get the IP address of the postgres db container: docker inspect mynginx | grep IPAddress &quot;IPAddress&quot;: &quot;172.17.0.2&quot;,  Run a postgres client container to connect the db container: docker run -it --rm postgres psql -h &quot;172.17.0.2&quot; -U postgres psql (14.3) Type &quot;help&quot; for help. postgres=# SELECT 1; ?column? ---------- 1 (1 row)  "},{"title":"Using Private Defined Bridge Network​","type":1,"pageTitle":"Communication Between Docker Containers","url":"/blog/docker-containers-communication#using-private-defined-bridge-network","content":"The private defined bridge network will give you more privacy that it only allows only containers belonging to it can talk to each other. Moreover, you can use hostname or alias name to connect without regard of IP address changing due to re-start. Create a private bridge network: docker network create postgres-net  Start a postgres db container: docker run --rm --net postgres-net --name postgres-db --detach -e POSTGRES_PASSWORD=mysecretpassword postgres  Run a postgres client container to connect the db container: docker run -it --rm --net postgres-net postgres psql -h postgres-db -U postgres psql (14.3) Type &quot;help&quot; for help. postgres=# SELECT 1; ?column? ---------- 1 (1 row)  "},{"title":"Use Case in Docker Compose​","type":1,"pageTitle":"Communication Between Docker Containers","url":"/blog/docker-containers-communication#use-case-in-docker-compose","content":"Actually, docker compose will create its private bridge network, and when it start containers, containers will be attached to that network in default. docker-compose-postgres.yml # Use below credentials to access in `adminer` web to access `db`, # server: db (db1, db2 are also available!) # user: postgres # password: example version: '3.1' services: db: image: postgres restart: always environment: # POSTGRES_USER: postgres # `postgres` in default. POSTGRES_PASSWORD: example networks: default: aliases: - db1 - db2 adminer: image: adminer restart: always ports: - 8080:8080  "},{"title":"Dotfiles Guide","type":0,"sectionRef":"#","url":"/blog/dotfiles-guide","content":"Tutorials - dotfiles.github.io Getting started with dotfilesFrontend Ramblings RSS feedThe content of this website on GitHubMy Mastodon profileMy Twitter profileShare this article on TwitterShare this article on Hacker News","keywords":"dotfiles"},{"title":"Set Up NFS Sever in Docker","type":0,"sectionRef":"#","url":"/blog/docker-setup-nfs-sever","content":"","keywords":"Setup NFS Sever"},{"title":"Start Up NFS Server​","type":1,"pageTitle":"Set Up NFS Sever in Docker","url":"/blog/docker-setup-nfs-sever#start-up-nfs-server","content":"Use docker image gists/nfs-server to start up a NFS server container. In OSX, it's critical to use volume mount and avoid using bind mount as we mentioned above. In Linux, it's okay to use either volume mount or bind mount. docker run --rm -d \\ --name nfs \\ --privileged \\ -p 2049:2049 \\ -v /tmp/volume:/nfs-share \\ -e NFS_DIR=/nfs-share \\ -e NFS_OPTION=&quot;rw,fsid=0,async,no_subtree_check,no_auth_nlm,insecure,no_root_squash&quot; \\ gists/nfs-server  note Before we use an old nfs server image itsthenetwork/nfs-server-alpine which was not maintained more than 4 years and not supported natively in platform linux/arm/v6. docker run -it --rm \\ --name nfs \\ --privileged \\ -v /tmp/volume:/nfs-share \\ -e SHARED_DIRECTORY=/nfs-share \\ -p 2049:2049 \\ itsthenetwork/nfs-server-alpine:latest  note In OSX, due to the docker desktop itself is running in VM, it will cause some error like Operation not supported when binding a local file folder via bind mount even you set 777 mask on the folder. So it's recommended to use volume to bind to /mnt in Samba server in OSX. Furthermore, the Samba server will log such message: error reading meta xattr: Not supported. Get the ip address of the NFS server, which will be used later to connect the NFS server when mounting in a Docker container client. If you only want to mount the NFS server from the host, you can just know the ip address of your host. docker inspect \\ -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' \\ nfs  Here the output is 172.17.0.2  "},{"title":"Use NFS Client in Docker​","type":1,"pageTitle":"Set Up NFS Sever in Docker","url":"/blog/docker-setup-nfs-sever#use-nfs-client-in-docker","content":"Let's make use of a Docker container to act in a NFS client to access shared data in the running-up NFS server. note run container as root by option --privileged or --cap-add SYS_ADMIN when permissions denied inside the container: docker run -it --rm --privileged busybox sh  Inside the container: note Due to the fsid=0 parameter set in the /etc/exports file, there's no need to specify the folder name when mounting from a client. For example, this works fine even though the folder being mounted and shared is /nfs-share: # In the container mkdir /mnt # nfs v4 mount -v -o vers=4,loud 172.17.0.2:/ /mnt # create a file to test echo &quot;some text here&quot; &gt; /mnt/file1.txt  Then go to the Host to list directory /data/volume/test, where you will find the file1.txt is sitting. # In the host cat /data/volume/test/file1.txt  "},{"title":"Use NFS Client With Volume Mount in Docker​","type":1,"pageTitle":"Set Up NFS Sever in Docker","url":"/blog/docker-setup-nfs-sever#use-nfs-client-with-volume-mount-in-docker","content":"Create a NFS volume in Docker docker volume create --driver local \\ --opt type=nfs \\ --opt o=addr=172.17.0.2,nfsvers=4 \\ --opt device=:/ \\ nfs-volume  docker inspect nfs-volume  Run the container with the created volume nfs-volume. docker run -it --rm \\ --privileged \\ --name nfs-test \\ -v nfs-volume:/mnt \\ busybox \\ sh  Alternative, you can use the combined one command which will create a volume nfsvolume, docker run -it --rm \\ --privileged \\ --name nfs-test \\ --mount 'type=volume,source=nfsvolume,volume-driver=local,volume-opt=type=nfs,volume-opt=device=:/,&quot;volume-opt=o=addr=172.17.0.2,rw,nfsvers=4,async&quot;,target=/mnt' \\ busybox \\ sh  "},{"title":"Setup a NFS Server and Mount NFS Volume int Docker Compose​","type":1,"pageTitle":"Set Up NFS Sever in Docker","url":"/blog/docker-setup-nfs-sever#setup-a-nfs-server-and-mount-nfs-volume-int-docker-compose","content":""},{"title":"About NFS Options​","type":1,"pageTitle":"Set Up NFS Sever in Docker","url":"/blog/docker-setup-nfs-sever#about-nfs-options","content":"Understanding the /etc/exports File – The Geek Diary "},{"title":".NET Finalizer","type":0,"sectionRef":"#","url":"/blog/dotnet-finalizer","content":"","keywords":""},{"title":"Tips​","type":1,"pageTitle":".NET Finalizer","url":"/blog/dotnet-finalizer#tips","content":"finalizers should not be accessing managed objects. "},{"title":"Set Up Samba Server in Docker","type":0,"sectionRef":"#","url":"/blog/docker-setup-samba-server","content":"","keywords":"Set Up Samba Server in Docker"},{"title":"Start Samba Server in Docker​","type":1,"pageTitle":"Set Up Samba Server in Docker","url":"/blog/docker-setup-samba-server#start-samba-server-in-docker","content":"Here, we use Samba server image from dperson/samba. Although there is an alternative from ghcr.io/servercontainers/samba or crazymax/samba In OSX, it's critical to use volume mount and avoid using bind mount as we mentioned above. note In OSX, due to the docker desktop itself is running in VM, it will cause some error like Operation not supported when binding a local file folder via bind mount even you set 777 mask on the folder. So it's recommended to use volume mount to bind to /mnt in Samba server in OSX. Furthermore, the Samba server will log such message: error reading meta xattr: Not supported. In Linux, it's okay to use either volume mount or bind mount. docker run -it --rm \\ --name samba \\ -p 139:139 -p 445:445 \\ -v mnt:/mnt:z \\ dperson/samba \\ -p -s &quot;Mount;/mnt;yes;no;yes&quot; -u &quot;bob;bobspasswd&quot; -g &quot;log level = 5&quot;  note -s &quot;&lt;Mount;/mnt&gt;;yes;no;yes&quot; means [browsable:yes;readonly:no;guest:yes]&quot;, which will allow the guest to read and the user to read/write! Get the samba server IP address: $ docker inspect \\ -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' \\ samba 172.17.0.2  "},{"title":"Start Samba Client in Docker​","type":1,"pageTitle":"Set Up Samba Server in Docker","url":"/blog/docker-setup-samba-server#start-samba-client-in-docker","content":"Use dperson/samba or busybox image, docker run -it --rm --privileged dperson/samba bash  or docker run -it --rm --privileged busybox sh  Inside the container: mkdir /smb_share # mount -t cifs //[server-ip]/[share-path] /[mount-point] mount -t cifs //172.17.0.2/Mount /smb_share -o rw,username=bob,password=bobspasswd # write file echo &quot;xxxx&quot; &gt; /smb_share/f.txt  "},{"title":"Start Samba Client which Create Volume in Docker​","type":1,"pageTitle":"Set Up Samba Server in Docker","url":"/blog/docker-setup-samba-server#start-samba-client-which-create-volume-in-docker","content":"Create a CIFS/Samba Volume docker volume create \\ --driver local \\ --opt type=cifs \\ --opt device=//172.17.0.2/Mount \\ --opt o=username=bob,password=bobspasswd \\ --name samba-volume  $ docker inspect samba-volume [ { &quot;CreatedAt&quot;: &quot;2023-08-13T16:24:03Z&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: null, &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/samba-volume/_data&quot;, &quot;Name&quot;: &quot;samba-volume&quot;, &quot;Options&quot;: { &quot;device&quot;: &quot;//172.17.0.2/Mount&quot;, &quot;o&quot;: &quot;addr=username=bob,password=bobspasswd&quot;, &quot;type&quot;: &quot;cifs&quot; }, &quot;Scope&quot;: &quot;local&quot; } ]  Start a container using the created volume samba-volume. docker run -it --rm \\ -v samba-volume:/mnt \\ busybox \\ sh  "},{"title":"Use Case in Docker Compose​","type":1,"pageTitle":"Set Up Samba Server in Docker","url":"/blog/docker-setup-samba-server#use-case-in-docker-compose","content":" docker-compose-samba.yml version: &quot;3&quot; # Inspired by https://github.com/dperson/samba/blob/master/docker-compose.yml services: samba: image: dperson/samba privileged: true environment: TZ: &quot;EST5EDT&quot; ports: - &quot;137:137/udp&quot; - &quot;138:138/udp&quot; - &quot;139:139/tcp&quot; - &quot;445:445/tcp&quot; volumes: - mnt:/mnt:z command: '-s &quot;Mount;/mnt;yes;no;yes&quot; -u &quot;bob;bobspasswd&quot; -p' # networks: # default: # ipv4_address: 172.28.0.20 samba-client: image: busybox restart: on-failure volumes: - samba-volume:/smb_share # tty: true command: sleep infinity depends_on: - samba # networks: # default: # ipv4_address: 172.28.0.21 # networks: # default: # driver: bridge # ipam: # config: # - subnet: 172.28.0.0/16 # gateway: 172.28.0.1 volumes: mnt: samba-volume: driver: local driver_opts: type: cifs # device: &quot;//172.28.0.20/Mount&quot; # o: &quot;username=bob,password=bobspasswd&quot; device: &quot;//localhost/Mount&quot; o: &quot;addr=localhost,username=bob,password=bobspasswd&quot;  "},{"title":"Troubleshooting​","type":1,"pageTitle":"Set Up Samba Server in Docker","url":"/blog/docker-setup-samba-server#troubleshooting","content":"When you mount an Samba Share in Linux, you may encounter error like failed: Invalid argument, bash-5.1# mount -t cifs //172.17.0.2/Mount /mnt/smb_share -o iocharset=utf8,rw,vers=1.0 mount: mounting //172.17.0.2/Mount on /mnt/smb_share failed: Invalid argument  You can use dmesg to debug, bash-5.1# dmesg [317258.750535] CIFS: Attempting to mount \\\\172.17.0.2\\Mount [317258.752956] CIFS: VFS: No username specified [317336.240984] cifs: Unknown parameter 'passwd' [317344.451345] CIFS: Attempting to mount \\\\172.17.0.2\\Mount  "},{"title":"FastAPI Best Practices","type":0,"sectionRef":"#","url":"/blog/fastapi-best-practices","content":"","keywords":"limit only one access to endpoint at a time lock access to endpoint at a time"},{"title":"Limit Only One Access to Endpoint at a Time​","type":1,"pageTitle":"FastAPI Best Practices","url":"/blog/fastapi-best-practices#limit-only-one-access-to-endpoint-at-a-time","content":"Limit only one access to an endpoint at a time with asyncio.Lock in asyncio in FastAPI. ../code-snippets/python/app_request_lock.py # main.py from fastapi import FastAPI import asyncio app = FastAPI() lock = asyncio.Lock() counter = 0 @app.post(&quot;/limit&quot;) async def func(): global counter async with lock: print(&quot;Hello&quot;) counter = counter + 1 await asyncio.sleep(2) print(&quot;bye&quot;) await asyncio.sleep(2) return {&quot;counter&quot;: counter} &quot;&quot;&quot; Make 2 requests at a time, output from server: INFO: 127.0.0.1:60228 - &quot;POST /limit HTTP/1.1&quot; 200 OK Hello bye INFO: 127.0.0.1:51010 - &quot;POST /limit HTTP/1.1&quot; 200 OK Hello bye INFO: 127.0.0.1:51022 - &quot;POST /limit HTTP/1.1&quot; 200 OK Request 1: ❯ curl -X 'POST' \\ 'http://127.0.0.1:8000/limit' \\ -H 'accept: application/json' \\ -d '' {&quot;counter&quot;:1}% Request 2: ❯ curl -X 'POST' \\ 'http://127.0.0.1:8000/limit' \\ -H 'accept: application/json' \\ -d '' {&quot;counter&quot;:2}% &quot;&quot;&quot;  NOTE: The asyncio.Lock only take effect in the asyncio loop level, if using unicorn to run server in multiple processes, it can not lock the request! No limitation. ../code-snippets/python/app_request_nolock.py # main.py from fastapi import FastAPI import asyncio app = FastAPI() lock = asyncio.Lock() counter = 0 @app.post(&quot;/limit&quot;) async def func(): global counter print(&quot;Hello&quot;) counter = counter + 1 await asyncio.sleep(2) print(&quot;bye&quot;) await asyncio.sleep(2) return {&quot;counter&quot;: counter} &quot;&quot;&quot; Make 2 requests at a time, output from server: Hello Hello bye bye INFO: 127.0.0.1:45160 - &quot;POST /limit HTTP/1.1&quot; 200 OK INFO: 127.0.0.1:45172 - &quot;POST /limit HTTP/1.1&quot; 200 OK Request 1: ❯ curl -X 'POST' \\ 'http://127.0.0.1:8000/limit' \\ -H 'accept: application/json' \\ -d '' {&quot;counter&quot;:2}% Request 2: ❯ curl -X 'POST' \\ 'http://127.0.0.1:8000/limit' \\ -H 'accept: application/json' \\ -d '' {&quot;counter&quot;:2}% &quot;&quot;&quot;  Limit only one access to an endpoint at a time with thread.Lock Limit only one access to an endpoint at a time with process.Lock "},{"title":"Attach A Background Service Into the Application​","type":1,"pageTitle":"FastAPI Best Practices","url":"/blog/fastapi-best-practices#attach-a-background-service-into-the-application","content":"Run a background service behind the FastAPI server: share the same asyncio main loop with the serverthe service start when the server starts and stop when the server stopsit should be light-weight and non-CPU heavy workload Coroutines and Tasks — Python 3.11.4 documentationEvent Loop — Python 3.11.4 documentation ../code-snippets/python/app_background_service.py from fastapi import FastAPI import asyncio import os app = FastAPI() class BackgroundService: def __init__(self, loop: asyncio.AbstractEventLoop, tasks: list): self.loop = loop self.running = False async def work(self): print(f&quot;Start background service&quot;) while True: print(f&quot;Run background service...&quot;) # Sleep for 1 second await asyncio.sleep(1) async def start(self): self.task = self.loop.create_task(self.work()) async def stop(self): self.task.cancel() try: await self.task except asyncio.CancelledError: print(&quot;Clean up background service&quot;) service = BackgroundService(asyncio.get_running_loop()) @app.on_event(&quot;startup&quot;) async def startup(): print(f&quot;PID[{os.getpid()}] app startup&quot;) # schedule a task on main loop await service.start() @app.on_event(&quot;shutdown&quot;) async def shutdown(): # close ProcessPoolExecutor print(f&quot;PID[{os.getpid()}] app shutdown&quot;) await service.stop() @app.post(&quot;/&quot;) async def hello(): return {&quot;value&quot;: f&quot;hello world [{service.task.done()}] [{service.task.get_name()}]&quot;}  "},{"title":"Install FFmpeg on Nvidia CUDA Container","type":0,"sectionRef":"#","url":"/blog/ffmpeg-on-cuda-container","content":"","keywords":"FFmpeg on CUDA Container"},{"title":"Prerequisites​","type":1,"pageTitle":"Install FFmpeg on Nvidia CUDA Container","url":"/blog/ffmpeg-on-cuda-container#prerequisites","content":"Make sure Nvidia GPU Driver is installed in your host machine! As it will be mounted into the container. Use ldconfig to check if the required Nvidia GPU driver libraries are available inside the container. Such as, ldconfig -p | grep libcuda  note When running in the nvidia/cuda Docker container, what Nvidia libraries(from the host machine) should be mounted inside the container are specified by the NVIDIA_DRIVER_CAPABILITIES env variable, see driver-capabilities. Here for FFmpeg to employ GPU, it should be included at least as NVIDIA_DRIVER_CAPABILITIES=video,utility. "},{"title":"Step by Step​","type":1,"pageTitle":"Install FFmpeg on Nvidia CUDA Container","url":"/blog/ffmpeg-on-cuda-container#step-by-step","content":"docker run --rm --runtime=nvidia \\ -e NVIDIA_VISIBLE_DEVICES=all \\ -e NVIDIA_DRIVER_CAPABILITIES=compute,utility \\ nvidia/cuda nvidia-smi  docker run --rm --runtime=nvidia \\ -e NVIDIA_VISIBLE_DEVICES=all \\ -e NVIDIA_DRIVER_CAPABILITIES=compute,utility \\ nvidia/cuda bash  "},{"title":"Complete Dockerfile​","type":1,"pageTitle":"Install FFmpeg on Nvidia CUDA Container","url":"/blog/ffmpeg-on-cuda-container#complete-dockerfile","content":"The source code is available at Dockerfile nvidia-cuda-ffmpeg/Dockerfile # pull official base image, NOTE to use `devel` FROM nvidia/cuda:12.2.0-devel-ubuntu20.04 # Set environment variables to prevent interactive prompts during installation ENV DEBIAN_FRONTEND=noninteractive # Install dependencies RUN apt-get update &amp;&amp; \\ apt-get install -y wget git make build-essential pkg-config yasm cmake libtool libc6 libc6-dev unzip libnuma1 libnuma-dev &amp;&amp; \\ apt-get clean &amp;&amp; \\ rm -rf /var/lib/apt/lists/* # Install FFmpeg 6.1 RUN mkdir -p /opt RUN cd /opt/ &amp;&amp; wget https://github.com/FFmpeg/nv-codec-headers/releases/download/n12.1.14.0/nv-codec-headers-12.1.14.0.tar.gz -O nv-codec-headers-12.1.14.0.tar.gz &amp;&amp; tar -xf nv-codec-headers-12.1.14.0.tar.gz RUN cd /opt/nv-codec-headers-12.1.14.0 &amp;&amp; \\ make install PREFIX=/usr RUN cd /opt &amp;&amp; wget https://ffmpeg.org/releases/ffmpeg-6.1.tar.xz -O ffmpeg-6.1.tar.xz &amp;&amp; tar -xf ffmpeg-6.1.tar.xz RUN cd /opt/ffmpeg-6.1 &amp;&amp; \\ ./configure --enable-cuda --enable-cuvid --enable-nvdec --enable-nvenc --enable-nonfree --enable-libnpp --extra-cflags=-I/usr/local/cuda/include --extra-ldflags=-L/usr/local/cuda/lib64 --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libfribidi --enable-filter=drawtext &amp;&amp; \\ make -j 8 &amp;&amp; \\ make install PREFIX=/usr CMD [&quot;ffmpeg&quot;, &quot;-version&quot;]  "},{"title":"Known issues​","type":1,"pageTitle":"Install FFmpeg on Nvidia CUDA Container","url":"/blog/ffmpeg-on-cuda-container#known-issues","content":"Nvidia Docker encoding stops after long running time with such error message: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. [Issue]: NVidia Docker transcoding randomly stops working after 5 minutes to 4 hours later. · Issue #9287 · jellyfin/jellyfin · GitHub Possible solution: Edit /etc/defautls/grub, GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet splash systemd.unified_cgroup_hierarchy=0&quot;  Then run update-grub and reboot. "},{"title":"FFmpeg Command Samples","type":0,"sectionRef":"#","url":"/blog/ffmpeg-command-samples","content":"","keywords":"learn ffmpeg"},{"title":"Overview​","type":1,"pageTitle":"FFmpeg Command Samples","url":"/blog/ffmpeg-command-samples#overview","content":"Examples of Container and Codec lists in Chromechrome: Video Container Format: MP4 [.mp4 file extension]OggWebMWAVHLS [.m3u8 file extension] Video Codec Format: VP8VP9H.264 [Chrome only]H.265 [Chrome only and also only with the underlying OS support]MPEG-4 [Chrome OS only, aka Xvid, DivX] "},{"title":"About FFmpeg Command​","type":1,"pageTitle":"FFmpeg Command Samples","url":"/blog/ffmpeg-command-samples#about-ffmpeg-command","content":"The common patter of ffmpeg looks like: ffmpeg [input_options] -i input.mp4 [output_options] output.mp4  In short: The [input_options] before -i input.mp4 are options used for decoding the videoThe [output_options] before output.mp4 are options used for encoding the video "},{"title":"FFmpeg Command Examples​","type":1,"pageTitle":"FFmpeg Command Samples","url":"/blog/ffmpeg-command-samples#ffmpeg-command-examples","content":"It's note worthing to look over FFmpeg Wiki ffmpeg "},{"title":"List all available container formats​","type":1,"pageTitle":"FFmpeg Command Samples","url":"/blog/ffmpeg-command-samples#list-all-available-container-formats","content":"ffmpeg -formats  "},{"title":"List all available codec formats​","type":1,"pageTitle":"FFmpeg Command Samples","url":"/blog/ffmpeg-command-samples#list-all-available-codec-formats","content":"ffmpeg -codecs  "},{"title":"List all available encoder or decoder​","type":1,"pageTitle":"FFmpeg Command Samples","url":"/blog/ffmpeg-command-samples#list-all-available-encoder-or-decoder","content":"ffmpeg -encoders ffmpeg -decoders  # Show available `presets` ffmpeg -h encoder=h264_nvenc  "},{"title":"List all frames timestamp​","type":1,"pageTitle":"FFmpeg Command Samples","url":"/blog/ffmpeg-command-samples#list-all-frames-timestamp","content":"ffprobe -select_streams v -show_entries frame=pict_type,pts_time -of csv=p=0 -i input.mp4  "},{"title":"List all keyframe(I-frame) timestamp​","type":1,"pageTitle":"FFmpeg Command Samples","url":"/blog/ffmpeg-command-samples#list-all-keyframei-frame-timestamp","content":"ffprobe -select_streams v -show_entries frame=pict_type,pts_time -of csv=p=0 -skip_frame nokey -i input.mp4  "},{"title":"Read video information json output​","type":1,"pageTitle":"FFmpeg Command Samples","url":"/blog/ffmpeg-command-samples#read-video-information-json-output","content":"ffprobe -v quiet -show_streams -select_streams v:0 -print_format json video.mp4  "},{"title":"Transcode video​","type":1,"pageTitle":"FFmpeg Command Samples","url":"/blog/ffmpeg-command-samples#transcode-video","content":"There are three possible and reasonable methods for transcoding: software decoding and software encodingsoftware decoding and hardware encodinghardware decoding and hardware encoding you can convert either the container formats or the codecs formats, such as: # To `mp4` container and `h.264` codecs(the lower crf, the higher quality) ffmpeg -i input.avi -c:v libx264 -preset fast -crf 23 output.mp4 # To `mp4` container and `mpeg4` codecs ffmpeg -i input.avi -c:v libxvid -preset fast output.mp4 # To be friendly for streaming, adding necessary metadata to begin playback faster! ffmpeg -i input.avi -c:v libx264 -preset fast -crf 23 -movflags +faststart output.mp4 # Remove audio ffmpeg -i input.avi -c:v libx264 -preset fast -crf 23 -an output.mp4 # Use NVIDIA GPU ffmpeg -i input.avi -c:v h264_nvenc -preset fast output.avi # keep quality ffmpeg -i input.avi -c:v h264_nvenc -preset fast -rc constqp -cq 19 output.avi  "},{"title":"Set keyframe interval​","type":1,"pageTitle":"FFmpeg Command Samples","url":"/blog/ffmpeg-command-samples#set-keyframe-interval","content":"# mpeg4 ffmpeg -i input.avi -vcodec libxvid -preset fast -g 10 -keyint_min 10 -sc_threshold 0 output.avi # NVIDIA GPU # This sets the I-frame interval at 10 and ensures that no I-frames will be inserted in scene changes ffmpeg -i input.avi -vcodec h264_nvenc -preset fast -g 10 -keyint_min 10 -sc_threshold 0 output.avi  "},{"title":"Clip video​","type":1,"pageTitle":"FFmpeg Command Samples","url":"/blog/ffmpeg-command-samples#clip-video","content":"# Fast clip with stream copy and faster seeking(700x) ffmpeg -ss 00:00:10 -i video.mp4 -to 00:00:50 -c:v copy output.mp4 # Fast clip with stream copy and slower seeking(600x) ffmpeg -i video.mp4 -ss 00:00:10 -to 00:00:50 -c:v copy output.mp4 # Slow clip with re-encoding and faster seeking(1x) ffmpeg -ss 00:00:10 -i video.mp4 -to 00:00:50 -c:v libx264 output.mp4  Use filter(Slow) ffmpeg -y -i input.mp4 -an -c:v libx264 -filter:v &quot;trim=start=10:end=30&quot; output.mp4 # remove the black video ffmpeg -y -i input.mp4 -an -c:v libx264 -filter:v &quot;trim=start=10:end=30,setpts=PTS-STARTPTS&quot; output.mp4  NOTE: Cutting video with stream copy will lead the start frame is not precise! "},{"title":"Slow down/Speed up video​","type":1,"pageTitle":"FFmpeg Command Samples","url":"/blog/ffmpeg-command-samples#slow-downspeed-up-video","content":"# Slow down to 1/2x in fast way ffmpeg -y -itsscale 2 -i video.mp4 -c:v copy output.mp4 # Speed up to 2x in fast way ffmpeg -y -itsscale 0.5 -i video.mp4 -c:v copy output.mp4 # Speed up to 2x with re-encoding in slow way ffmpeg -y -itsscale 0.5 -i video.mp4 -c:v libx264 output.mp4 # Speed up to 2x with `setpts filter`(which requires re-encoding) in slow way ffmpeg -i video.mp4 -filter:v &quot;setpts=0.5*PTS&quot; output.mp4 # Change fps to slow down/speed up but keeping duration ffmpeg -i video.mp4 -filter:v &quot;fps=30&quot; output.mp4  "},{"title":"Draw region of interest(ROI) on a video​","type":1,"pageTitle":"FFmpeg Command Samples","url":"/blog/ffmpeg-command-samples#draw-region-of-interestroi-on-a-video","content":"# Draw one drawbox ffmpeg -i input.mp4 -filter:v &quot;drawbox=x=100:y=100:w=200:h=150:color=red@0.5&quot; output.mp4 ffmpeg -i input.mp4 -filter:v &quot;drawbox=x=100:y=100:w=200:h=150:color=red@0.5,drawtext=text='Test Text':x=100:y=100:fontsize=24:fontcolor=yellow:box=1:boxcolor=yellow&quot; output.mp4 ffmpeg -y -ss 30 -noaccurate_seek -i input.mp4 -t 10 -c:v libx264 -filter:v &quot;drawbox=x=100:y=100:w=200:h=150:color=red@0.5,drawtext=text='Test Text':x=100:y=(100-text_h):fontsize=24:fontcolor=black:box=1:boxcolor=red:boxborderw=2&quot; output.mp4 # Trim video and draw box ffmpeg -y -i input.mp4 -an -c:v libx264 -filter:v &quot;trim=start=10:end=30,drawbox=x=100:y=100:w=200:h=150:color=red@0.5:enable='between(t,10,15)',setpts=PTS-STARTPTS&quot; output.mp4 ffmpeg -y -i input.mp4 -i overlay_video.mp4 -filter_complex &quot;[0:v][1:v]overlay=0:0:enable='between(t,0,25)'&quot; output.mp4  # Draw different `drawbox` at different time on video from a file(using `timeline` feature) # See timeline: https://ffmpeg.org/ffmpeg-filters.html#Timeline-editing # See expression: https://ffmpeg.org/ffmpeg-utils.html#Expression-Evaluation ffmpeg -i input.mp4 -filter_complex_script timeline.txt output.mp4 # `timeline.txt` look like: [0:v]drawbox=x=100:y=100:w=200:h=150:color=red@0.5:enable='between(t,0,21)'[box1]; [box1]drawbox=x=300:y=200:w=150:h=100:color=green@0.5:t=:enable='between(t,21,40)'[box2]; [box2]drawbox=x=50:y=300:w=300:h=200:color=blue@0.5:t=:enable='between(t,41,60)' # or using `n`: sequential number of the input frame, starting from 0 [0:v]drawbox=x=100:y=100:w=200:h=150:color=red@0.5:n=0:600[box1]; [box1]drawbox=x=300:y=200:w=150:h=100:color=green@0.5:n=601:1200[box2]; [box2]drawbox=x=50:y=300:w=300:h=200:color=blue@0.5:n=1201:1800  # Draw different `drawbox` at different time on video ffmpeg -i input.mp4 -filter_complex &quot;[0:v]drawbox=x=100:y=100:w=200:h=150:color=red:t=8:enable='between(t,0,21)'[box1];[box1]drawbox=x=300:y=200:w=150:h=100:color=green:t=8:enable='between(t,21,40)'[box2];[box2]drawbox=x=50:y=300:w=300:h=200:color=blue:t=8:enable='between(t,41,60)'&quot; output.mp4  "},{"title":"Pipe ffmpeg​","type":1,"pageTitle":"FFmpeg Command Samples","url":"/blog/ffmpeg-command-samples#pipe-ffmpeg","content":"The FFmpeg Pipe is very useful in IPC for communicating FFmpeg with another process. For instance, an application generates images to Pipe stdin which FFmpeg reads and encodes into a video. A real-life scenario that FFmpeg read from Pipe: An application applied OpenCV to process images for object detection, and it will draw ROI but lacks ability to encode a video as efficiently as FFmpeg does. So it's somewhat ideal to pipe these images to FFmpeg that can encode the video by leveraging hardware acceleration(GPU) capability. However, FFmpeg can also write to a Pipe. # It works in Linux and Windows(`cmd`, does not work in `PS`) ffmpeg -ss 00:00:10 -i video.mp4 -to 00:00:20 -an -c:v copy -f h264 pipe: | ffmpeg -y -i pipe: -filter:v &quot;drawbox=x=100:y=100:w=200:h=150:color=red&quot; output.mp4 ffmpeg -i input.mp4 -c:v rawvideo -pix_fmt bgr24 -r 60 -f rawvideo pipe: | ffmpeg -y -f rawvideo -pix_fmt bgr24 -s 1920x1080 -r 60 -i pipe: -pix_fmt yuv420p -c:v h264_nvenc foo.mp4 ffmpeg -i input.mp4 -pix_fmt yuv420p -r 60 -f rawvideo pipe: | ffmpeg -y -f rawvideo -pix_fmt yuv420p -s 1920x1080 -r 60 -i pipe: -c:v h264_nvenc foo.mp4 ffmpeg -i input.mp4 -an -f h264 pipe: | ffmpeg -y -f h264 -i pipe: -c:v h264_nvenc foo.mp4  "},{"title":"Use testsrc​","type":1,"pageTitle":"FFmpeg Command Samples","url":"/blog/ffmpeg-command-samples#use-testsrc","content":"ffmpeg -y -f lavfi -i testsrc=duration=10:size=1920x1080:rate=60 -c:v libx264 -pix_fmt yuv420p testsrc.mp4  "},{"title":"Split and Concatenate​","type":1,"pageTitle":"FFmpeg Command Samples","url":"/blog/ffmpeg-command-samples#split-and-concatenate","content":"ffmpeg -y -i input.mp4 -ss 0 -to 10 -c:v copy part1.mp4 ffmpeg -y -i input.mp4 -ss 10 -to 15 -c:v copy part2.mp4 ffmpeg -y -i input.mp4 -ss 15 -c:v copy part3.mp4  ffmpeg -y -i part2.mp4 -filter:v &quot;drawbox=x=100:y=100:w=200:h=150:color=red@0.5&quot; part2-draw.mp4  Slow, ffmpeg -y -i part1.mp4 -i part2-draw.mp4 -i part3.mp4 -filter_complex &quot;[0:v][1:v][2:v]concat=n=3:v=1:a=0[outv]&quot; -map &quot;[outv]&quot; output.mp4  Fast(Concat protocol), ffmpeg -i part1.mp4 -c copy part1.ts ffmpeg -i part2-draw.mp4 -c copy part2-draw.ts ffmpeg -i part3.mp4 -c copy part3.ts ffmpeg -y -i &quot;concat:part1.ts|part2-draw.ts|part3.ts&quot; -c:v copy output.mp4  Fast(Concat demuxer), ffmpeg -y -f concat -i concat.txt -c:v copy output.mp4 # concat.txt file 'part1.mp4' file 'part2-draw.mp4' file 'part3.mp4' # Or avoid creating the input file # bash ffmpeg -y -f concat -safe 0 -i &lt;(echo &quot;file '$PWD/part1.mp4'&quot;;echo &quot;file '$PWD/part2-draw.mp4'&quot;;echo &quot;file '$PWD/part3.mp4'&quot;;) -c:v copy output.mp4 # cmd ffmpeg -y -f concat -safe 0 -i &lt;(@echo &quot;file '$PWD/part1.mp4'&quot;;@echo &quot;file '$PWD/part2-draw.mp4'&quot;;@echo &quot;file '$PWD/part3.mp4'&quot;;) -c:v copy output.mp4  https://trac.ffmpeg.org/wiki/Concatenate "},{"title":"References​","type":1,"pageTitle":"FFmpeg Command Samples","url":"/blog/ffmpeg-command-samples#references","content":"Chrome Audio/Video Support↩FFmpeg Wiki↩ "},{"title":"MDX Features of Docusaurus","type":0,"sectionRef":"#","url":"/blog/docusaurus-mdx-features","content":"","keywords":"mdx features in docusaurus"},{"title":"React Component​","type":1,"pageTitle":"MDX Features of Docusaurus","url":"/blog/docusaurus-mdx-features#react-component","content":"Code as: docs/mdx-features.mdx export const Highlight = ({children, color}) =&gt; ( &lt;span style={{ backgroundColor: color, borderRadius: '2px', color: '#fff', padding: '0.2rem', }}&gt; {children} &lt;/span&gt; ); &lt;Highlight color=&quot;#25c2a0&quot;&gt;Docusaurus green&lt;/Highlight&gt; and &lt;Highlight color=&quot;#1877F2&quot;&gt;Facebook blue&lt;/Highlight&gt; are my favorite colors.  Render as: Docusaurus green and Facebook blue are my favorite colors.    Code as: src/components/Highlight import React from 'react'; export default function SharedHighlight({children, color}) { return ( &lt;span style={{ backgroundColor: color, borderRadius: '2px', color: '#fff', padding: '0.2rem', }}&gt; {children} &lt;/span&gt; ); }  With: docs/mdx-features.mdx import SharedHighlight from '@site/src/components/Highlight'; &lt;SharedHighlight color=&quot;#25c2a0&quot;&gt;Docusaurus green&lt;/SharedHighlight&gt; I can write **Markdown** alongside my _JSX_!  Render as: Docusaurus green I can write Markdown alongside my JSX! "},{"title":"Tabs​","type":1,"pageTitle":"MDX Features of Docusaurus","url":"/blog/docusaurus-mdx-features#tabs","content":"Code as: docs/mdx-features.mdx import Tabs from '@theme/Tabs'; import TabItem from '@theme/TabItem'; &lt;Tabs&gt; &lt;TabItem value=&quot;apple&quot; label=&quot;Apple&quot; default&gt; This is an apple 🍎 &lt;/TabItem&gt; &lt;TabItem value=&quot;orange&quot; label=&quot;Orange&quot;&gt; This is an orange 🍊 &lt;/TabItem&gt; &lt;TabItem value=&quot;banana&quot; label=&quot;Banana&quot;&gt; This is a banana 🍌 &lt;/TabItem&gt; &lt;/Tabs&gt;  Render as: AppleOrangeBanana This is an apple 🍎 "},{"title":"NOTES​","type":1,"pageTitle":"MDX Features of Docusaurus","url":"/blog/docusaurus-mdx-features#notes","content":"docs/mdx-features.mdx &lt;!-- Prettier doesn't change this --&gt; :::note Hello world :::  note Hello world &lt;!-- Prettier changes this --&gt; :::note Hello world :::  &lt;!-- to this --&gt; ::: note Hello world:::  docs/mdx-features.mdx :::note Your Title Some **content** with _Markdown_ `syntax`. :::  Your Title Some content with Markdown syntax. docs/mdx-features.mdx :::tip Use tabs in admonitions &lt;Tabs&gt; &lt;TabItem value=&quot;apple&quot; label=&quot;Apple&quot;&gt;This is an apple 🍎&lt;/TabItem&gt; &lt;TabItem value=&quot;orange&quot; label=&quot;Orange&quot;&gt;This is an orange 🍊&lt;/TabItem&gt; &lt;TabItem value=&quot;banana&quot; label=&quot;Banana&quot;&gt;This is a banana 🍌&lt;/TabItem&gt; &lt;/Tabs&gt; :::  Use tabs in admonitions AppleOrangeBanana This is an apple 🍎 "},{"title":"Math​","type":1,"pageTitle":"MDX Features of Docusaurus","url":"/blog/docusaurus-mdx-features#math","content":"docs/mdx-features.mdx Let $f\\colon[a,b]\\to\\R$ be Riemann integrable. Let $F\\colon[a,b]\\to\\R$ be $F(x)=\\int_{a}^{x} f(t)\\,dt$. Then $F$ is continuous, and at all $x$ such that $f$ is continuous at $x$, $F$ is differentiable at $x$ with $F'(x)=f(x)$.  Let f ⁣:[a,b]→Rf\\colon[a,b]\\to\\Rf:[a,b]→R be Riemann integrable. Let F ⁣:[a,b]→RF\\colon[a,b]\\to\\RF:[a,b]→R beF(x)=∫axf(t) dtF(x)=\\int_{a}^{x} f(t)\\,dtF(x)=∫ax​f(t)dt. Then FFF is continuous, and at all xxx such thatfff is continuous at xxx, FFF is differentiable at xxx with F′(x)=f(x)F'(x)=f(x)F′(x)=f(x). docs/mdx-features.mdx $$ I = \\int_0^{2\\pi} \\sin(x)\\,dx $$  I=∫02πsin⁡(x) dxI = \\int_0^{2\\pi} \\sin(x)\\,dxI=∫02π​sin(x)dx "},{"title":"Diagrams​","type":1,"pageTitle":"MDX Features of Docusaurus","url":"/blog/docusaurus-mdx-features#diagrams","content":"Example Mermaid diagram ```mermaid graph TD; A--&gt;B; A--&gt;C; B--&gt;D; C--&gt;D; ```  "},{"title":"Code Block​","type":1,"pageTitle":"MDX Features of Docusaurus","url":"/blog/docusaurus-mdx-features#code-block","content":"```jsx title=&quot;/src/components/HelloCodeTitle.js&quot; function HelloCodeTitle(props) { return &lt;h1&gt;Hello, {props.name}&lt;/h1&gt;; } ```  /src/components/HelloCodeTitle.js function HelloCodeTitle(props) { return &lt;h1&gt;Hello, {props.name}&lt;/h1&gt;; }  Syntax highlighting for Other languages by prism: sh, editorconfig, etc. editorconfig: ```editorconfig title=&quot;/etc/samba.conf&quot; [documents] path = /data/documents valid users = @simon guest ok = no writable = yes browsable = yes ```  sh: ```sh $ ls /home ```  ```js function HighlightSomeText(highlight) { if (highlight) { // highlight-next-line return 'This text is highlighted!'; } return 'Nothing highlighted'; } function HighlightMoreText(highlight) { // highlight-start if (highlight) { return 'This range is highlighted!'; } // highlight-end return 'Nothing highlighted'; } ```  function HighlightSomeText(highlight) { if (highlight) { return 'This text is highlighted!'; } return 'Nothing highlighted'; } function HighlightMoreText(highlight) { if (highlight) { return 'This range is highlighted!'; } return 'Nothing highlighted'; }  ```jsx {1,4-6,11} import React from 'react'; function MyComponent(props) { if (props.isBar) { return &lt;div&gt;Bar&lt;/div&gt;; } return &lt;div&gt;Foo&lt;/div&gt;; } export default MyComponent; ```  import React from 'react'; function MyComponent(props) { if (props.isBar) { return &lt;div&gt;Bar&lt;/div&gt;; } return &lt;div&gt;Foo&lt;/div&gt;; } export default MyComponent;  ```jsx {1,4-6,11} showLineNumbers import React from 'react'; function MyComponent(props) { if (props.isBar) { return &lt;div&gt;Bar&lt;/div&gt;; } return &lt;div&gt;Foo&lt;/div&gt;; } export default MyComponent; ```  import React from 'react'; function MyComponent(props) { if (props.isBar) { return &lt;div&gt;Bar&lt;/div&gt;; } return &lt;div&gt;Foo&lt;/div&gt;; } export default MyComponent;  JavaScriptPythonJava function helloWorld() { console.log('Hello, world!'); }  "},{"title":"Importing Code​","type":1,"pageTitle":"MDX Features of Docusaurus","url":"/blog/docusaurus-mdx-features#importing-code","content":"npm install --save raw-loader  docs/mdx-features.mdx import CodeBlock from '@theme/CodeBlock'; import MyComponentSource from '!!raw-loader!./myComponent'; &lt;CodeBlock language=&quot;jsx&quot;&gt;{MyComponentSource}&lt;/CodeBlock&gt;  /** * Copyright (c) Facebook, Inc. and its affiliates. * * This source code is licensed under the MIT license found in the * LICENSE file in the root directory of this source tree. */ import React, { useState } from 'react'; export default function MyComponent() { const [bool, setBool] = useState(false); return ( &lt;div&gt; &lt;p&gt;MyComponent rendered !&lt;/p&gt; &lt;p&gt;bool={bool ? 'true' : 'false'}&lt;/p&gt; &lt;p&gt; &lt;button onClick={() =&gt; setBool((b) =&gt; !b)}&gt;toggle bool&lt;/button&gt; &lt;/p&gt; &lt;/div&gt; ); }  "},{"title":"Importing Markdown​","type":1,"pageTitle":"MDX Features of Docusaurus","url":"/blog/docusaurus-mdx-features#importing-markdown","content":"docs/mdx-features.mdx import PartialExample from './_markdown-partial-example.mdx'; &lt;PartialExample name=&quot;Sebastien&quot; /&gt;  Hello Sebastien This is text some content from _markdown-partial-example.mdx. docs/mdx-features.mdx import PartialExample1 from './wiki-skia.md'; &lt;PartialExample1 /&gt;  It imports file from wiki-skia.md: What the difference between SkImage/SkPicture/SkCanvas/SkSurface? SkBitmap based SkCanvas very slow... How to improve draw speeds? How to move SkImage from CPU to GPU? How to control the SkImage GPU back cache size? As far as I understand when I load SkImage from file or SkBitmap the SkImage lives in CPU side memory. Then the moment I draw this SkImage on a GPU backed canvas it will make a copy of the CPU data into a GPU backed texture. So now we technically have two copies available on the SkImage. Then each time I draw that SkImage it will do it quickly cause it's already in the GPU side. "},{"title":"Import Code Snippets from GitHub Repositories​","type":1,"pageTitle":"MDX Features of Docusaurus","url":"/blog/docusaurus-mdx-features#import-code-snippets-from-github-repositories","content":"A Docusaurus v2 plugin that supports referencing code examples from public GitHub repositories. src/theme/ReferenceCodeBlock/index.tsx loading... See full example on GitHub code-snippets/XKeyIn.cpp loading... See full example on GitHub "},{"title":"Git Best Practices","type":0,"sectionRef":"#","url":"/blog/git-best-practices","content":"","keywords":"Git Submodules"},{"title":"Git SSH Key​","type":1,"pageTitle":"Git Best Practices","url":"/blog/git-best-practices#git-ssh-key","content":"How to Authenticate Your Git to GitHub with SSH Keys "},{"title":"Git Credentials​","type":1,"pageTitle":"Git Best Practices","url":"/blog/git-best-practices#git-credentials","content":"Store username/password instead of ssh for multiple remotes To enable git credentials # local git config credential.helper store # global git config --global credential.helper store  Each credential is stored in ~/.git-credentials file on its own line as a URL like: https://&lt;USERNAME&gt;:&lt;PASSWORD&gt;@github.com  Configure credentials, # Global git config --global credential.https://github.com.username &lt;your_username&gt; # Or git config --local user.name &lt;your_username&gt; git config --local user.email &lt;your_useremail&gt; # Then git pull or git push to let it cache your username/password after it prompt you to input password in the first time  Alternatively, we can directly edit our global Git config file ~/.gitconfig, [credential &quot;https://github.com&quot;] username = &lt;username&gt;  Git - Config Username &amp; Password - Store Credentials - ShellHacks Configuring Git Credentials "},{"title":"Git Submodules​","type":1,"pageTitle":"Git Best Practices","url":"/blog/git-best-practices#git-submodules","content":"Pull the repo and its all submodules in the first time. git clone http://10.6.64.66:30000/mtr/mtr.git cd mtr git submodule update --init --recursive --progress  Or just one command to clone with all the submodules. git clone --recursive http://10.6.64.66:30000/mtr/mtr.git  Pull the repo and its all submodules later git submodule update --recursive --progress  Enter each sub repository to pull its own latest of main per repository, when the parent repo does point to the latest branch of its submodules! Sometimes, it is very annoying to keep the parent repository up to date on the latest reference of its every sub repository! This approach give you the flexibility while being like a shortcut. git submodule foreach git checkout main  git submodule foreach git pull  git submodule foreach git pull origin main  git submodule update --recursive --remote  "},{"title":"Discard local commits​","type":1,"pageTitle":"Git Best Practices","url":"/blog/git-best-practices#discard-local-commits","content":"Assume your local repo has 10 commits ahead of the origin/main, and you want to move back to the origin/main. git reset --hard origin/main  "},{"title":"Frequently Asked Questions","type":0,"sectionRef":"#","url":"/blog/frequently-asked-questions","content":"","keywords":""},{"title":"Links/Graphs/BackLinks don't work. How do I enable them?​","type":1,"pageTitle":"Frequently Asked Questions","url":"/blog/frequently-asked-questions#linksgraphsbacklinks-dont-work-how-do-i-enable-them","content":"Ensure that you have all the [[recommended-extensions]] installed in Visual Studio CodeReload Visual Studio Code by running Cmd + Shift + P (Ctrl + Shift + P for Windows), type &quot;reload&quot; and run the Developer: Reload Window command to for the updated extensions take effectCheck the formatting rules for links on [[foam-file-format]] and [[wikilinks]] "},{"title":"I don't want Foam enabled for all my workspaces​","type":1,"pageTitle":"Frequently Asked Questions","url":"/blog/frequently-asked-questions#i-dont-want-foam-enabled-for-all-my-workspaces","content":"Any extension you install in Visual Studio Code is enabled by default. Given the philosophy of Foam, it works out of the box without doing any configuration upfront. In case you want to disable Foam for a specific workspace, or disable Foam by default and enable it for specific workspaces, it is advised to follow the best practices as documented by Visual Studio Code "},{"title":"I want to publish the graph view to GitHub pages or Vercel​","type":1,"pageTitle":"Frequently Asked Questions","url":"/blog/frequently-asked-questions#i-want-to-publish-the-graph-view-to-github-pages-or-vercel","content":"If you want a different front-end look to your published foam and a way to see your graph view, we'd recommend checking out these templates: foam-gatsby by Mathieu Dutourfoam-gatsby-kb by hikerpig "},{"title":"IoC","type":0,"sectionRef":"#","url":"/blog/ioc","content":"Introduction IoC, DIP, DI and IoC Container Lazily resolving services to fix circular dependencies in .NET Core - Thomas Levesque's .NET Blog Dealing With Circular Dependency Injection References - .NET Core Tutorials","keywords":""},{"title":"Keyboard Shortcut Collection","type":0,"sectionRef":"#","url":"/blog/keyboard-shortcut-collection","content":"VS Code Keyboard Shortcuts Macos VS Code Keyboard Shortcuts Windows","keywords":"Keyboard Shortcut Collection"},{"title":"Graphical User Interface(GUI)","type":0,"sectionRef":"#","url":"/blog/graphical-user-interface","content":"","keywords":""},{"title":"Android graphics​","type":1,"pageTitle":"Graphical User Interface(GUI)","url":"/blog/graphical-user-interface#android-graphics","content":"two core pieces: SurfaceFlingerSkia Graphics | Android Open Source ProjectAndroid Graphics Internals - Stack Overflow "},{"title":"WayLand​","type":1,"pageTitle":"Graphical User Interface(GUI)","url":"/blog/graphical-user-interface#wayland","content":"What is Wayland? · Writing Wayland clients The Hello Wayland Tutorial | FLOSS &amp; Cia How to use Wayland with C to make a Linux app | by Sergey Bugaev | Medium "},{"title":"How to mount ISO image file","type":0,"sectionRef":"#","url":"/blog/how-to-mount-iso-file","content":"","keywords":"How to mount ISO file"},{"title":"Mount ISO file on Linux​","type":1,"pageTitle":"How to mount ISO image file","url":"/blog/how-to-mount-iso-file#mount-iso-file-on-linux","content":""},{"title":"Mount ISO file on macOS​","type":1,"pageTitle":"How to mount ISO image file","url":"/blog/how-to-mount-iso-file#mount-iso-file-on-macos","content":"Attaching as a block device # the '-nomount' option avoids the 'mount failed' error ❯ hdiutil attach -nomount mantic-mini-iso-amd64.iso /dev/disk6 GUID_partition_scheme /dev/disk6s1 Microsoft Basic Data /dev/disk6s2 EFI /dev/disk6s3 Microsoft Basic Data  ❯ diskutil info /dev/disk6s2 Device Identifier: disk6s2 Device Node: /dev/disk6s2 Whole: No Part of Whole: disk6 Volume Name: ESP Mounted: No Partition Type: EFI File System Personality: MS-DOS FAT12 Type (Bundle): msdos Name (User Visible): MS-DOS (FAT12)  [Optional] Load CD9660 # Load the kext module ❯ sudo kmutil load -p /System/Library/Extensions/cd9660.kext  Mount the disk with cd9660 (aka ISO9660) file system # create mount point ❯ mkdir -p /tmp/ubuntu-mantic-iso # mount the disk ❯ mount -t cd9660 /dev/disk6 /tmp/ubuntu-mantic-iso  View the iso files, ❯ tree -h -L 3 /tmp/ubuntu-mantic-iso [2.0K] /tmp/ubuntu-mantic-iso ├── [2.0K] EFI │ └── [2.0K] boot │ ├── [938K] bootx64.efi │ ├── [2.2M] grubx64.efi │ └── [841K] mmx64.efi ├── [2.0K] boot │ └── [2.0K] grub │ ├── [2.0K] fonts │ ├── [ 169] grub.cfg │ ├── [ 38K] i386-pc │ └── [ 36K] x86_64-efi ├── [2.0K] boot.catalog └── [2.0K] casper ├── [ 56M] initrd └── [ 13M] vmlinuz 9 directories, 7 files  Umount the disk ❯ umount /dev/disk6  Detach the disk ❯ hdiutil detach /dev/disk6  "},{"title":"Linux Boot Process","type":0,"sectionRef":"#","url":"/blog/linux-boot-process","content":"https://www.freecodecamp.org/news/the-linux-booting-process-6-steps-described-in-detail/ https://www.baeldung.com/linux/boot-process https://www.thegeekstuff.com/2011/02/linux-boot-process/ https://opensource.com/article/18/1/analyzing-linux-boot-process","keywords":"Linux Boot Process"},{"title":"Inspect Shared Library","type":0,"sectionRef":"#","url":"/blog/inspect-shared-library","content":"","keywords":"debug dynamic library shared library"},{"title":"Using ldd Command​","type":1,"pageTitle":"Inspect Shared Library","url":"/blog/inspect-shared-library#using-ldd-command","content":"Available in Linux: ldd /usr/bin/vim linux-vdso.so.1 (0x00007ffc75fb1000) libgtk-3.so.0 =&gt; /usr/lib/libgtk-3.so.0 (0x00007fa4dcb5e000) libgdk-3.so.0 =&gt; /usr/lib/libgdk-3.so.0 (0x00007fa4dca64000) libXau.so.6 =&gt; /usr/lib/libXau.so.6 (0x00007fa4db7a9000) .... liblzma.so.5 =&gt; /usr/lib/liblzma.so.5 (0x00007fa4db63f000) liblz4.so.1 =&gt; /usr/lib/liblz4.so.1 (0x00007fa4db61d000) libgcrypt.so.20 =&gt; /usr/lib/libgcrypt.so.20 (0x00007fa4db4ff000) libgpg-error.so.0 =&gt; /usr/lib/libgpg-error.so.0 (0x00007fa4db4d8000)  "},{"title":"Using objdump Command​","type":1,"pageTitle":"Inspect Shared Library","url":"/blog/inspect-shared-library#using-objdump-command","content":"Available in Linux: objdump -p /usr/bin/vim | grep 'NEEDED' NEEDED libpython3.7m.so.1.0 NEEDED libcrypt.so.2 NEEDED libpthread.so.0 NEEDED libdl.so.2 NEEDED libutil.so.1 NEEDED libm.so.6 NEEDED libselinux.so.1 NEEDED libtinfo.so.6 NEEDED libacl.so.1 NEEDED libgpm.so.2 NEEDED libc.so.6  "},{"title":"Using readelf Command​","type":1,"pageTitle":"Inspect Shared Library","url":"/blog/inspect-shared-library#using-readelf-command","content":"Available in Linux: readelf --dynamic /usr/bin/vim | grep NEEDED 0x0000000000000001 (NEEDED) Shared library: [libpython3.7m.so.1.0] 0x0000000000000001 (NEEDED) Shared library: [libcrypt.so.2] 0x0000000000000001 (NEEDED) Shared library: [libpthread.so.0] 0x0000000000000001 (NEEDED) Shared library: [libdl.so.2] 0x0000000000000001 (NEEDED) Shared library: [libutil.so.1] 0x0000000000000001 (NEEDED) Shared library: [libm.so.6] 0x0000000000000001 (NEEDED) Shared library: [libselinux.so.1] 0x0000000000000001 (NEEDED) Shared library: [libtinfo.so.6] 0x0000000000000001 (NEEDED) Shared library: [libacl.so.1] 0x0000000000000001 (NEEDED) Shared library: [libgpm.so.2] 0x0000000000000001 (NEEDED) Shared library: [libc.so.6]  "},{"title":"Using otool Command​","type":1,"pageTitle":"Inspect Shared Library","url":"/blog/inspect-shared-library#using-otool-command","content":"Available in OSX: otool -L libOpenCvSharpExtern.dylib  "},{"title":"Reading the /proc/<pid>/maps File​","type":1,"pageTitle":"Inspect Shared Library","url":"/blog/inspect-shared-library#reading-the-procpidmaps-file","content":"Available in Linux: cat /proc/179015/maps ... 7f2cb67c3000-7f2cb67c6000 r--p 00000000 08:13 3810274 /usr/lib/libnss_files-2.31.so 7f2cb67c6000-7f2cb67cd000 r-xp 00003000 08:13 3810274 /usr/lib/libnss_files-2.31.so .. 7f2cb6a89000-7f2cb6a8a000 r--p 00002000 08:13 3810903 /usr/lib/libutil-2.31.so 7f2cb6a8a000-7f2cb6a8b000 r--p 00002000 08:13 3810903 /usr/lib/libutil-2.31.so ... 7f2cb9802000-7f2cb9803000 rw-p 00000000 00:00 0 7ffe77658000-7ffe7767a000 rw-p 00000000 00:00 0 [stack] 7ffe776c8000-7ffe776cc000 r--p 00000000 00:00 0 [vvar] 7ffe776cc000-7ffe776ce000 r-xp 00000000 00:00 0 [vdso] ffffffffff600000-ffffffffff601000 --xp 00000000 00:00 0 [vsyscall]  awk '$NF!~/\\.so/{next} {$0=$NF} !a[$0]++' /proc/179015/maps ... /usr/lib/libpython3.8.so.1.0 /usr/lib/libgpg-error.so.0.29.0 /usr/lib/libgcrypt.so.20.2.5 /usr/lib/liblz4.so.1.9.2 /usr/lib/liblzma.so.5.2.5 /usr/lib/libsystemd.so.0.28.0 /usr/lib/libogg.so.0.8.4 /usr/lib/libvorbis.so.0.4.8 /usr/lib/libblkid.so.1.1.0 /usr/lib/libXdmcp.so.6.0.0 /usr/lib/libXau.so.6.0.0 /usr/lib/libdatrie.so.1.3.5 ...  "},{"title":"Using vmmap Command​","type":1,"pageTitle":"Inspect Shared Library","url":"/blog/inspect-shared-library#using-vmmap-command","content":""},{"title":"Using ctypes in Python​","type":1,"pageTitle":"Inspect Shared Library","url":"/blog/inspect-shared-library#using-ctypes-in-python","content":"import ctypes ctypes.cdll.LoadLibrary(&quot;libOpenCvSharpExtern.so&quot;) ctypes.CDLL(&quot;libOpenCvSharpExtern.so&quot;)  dlopen() DYLD_PRINT_LIBRARIES=1 dlopen_test.out /opt/vcpkg/installed/arm64-osx-dynamic/lib/libpng16.dylib  objdump -p /usr/local/lib/libOpenCvSharpExtern.so  "},{"title":"Using nm​","type":1,"pageTitle":"Inspect Shared Library","url":"/blog/inspect-shared-library#using-nm","content":"Show list of symbols: ❯ nm -g /opt/vcpkg/installed/arm64-osx-dynamic/lib/libintl.8.dylib U _CFArrayGetCount U _CFArrayGetValueAtIndex U _CFGetTypeID U _CFLocaleCopyPreferredLanguages U _CFPreferencesCopyAppValue U _CFRelease U _CFStringGetCString U _CFStringGetTypeID U __DefaultRuneLocale U ___CFConstantStringClassReference  "},{"title":"Using dumpbin​","type":1,"pageTitle":"Inspect Shared Library","url":"/blog/inspect-shared-library#using-dumpbin","content":"Available in Windows Show dependent dynamic libraries(DLL): dumpbin /dependents your_dll_file.dll  "},{"title":"Using Microsoft.PowerShell​","type":1,"pageTitle":"Inspect Shared Library","url":"/blog/inspect-shared-library#using-microsoftpowershell","content":"(Get-Command &quot;C:\\Path\\To\\Thing.dll&quot;).FileVersionInfo (Get-Item &quot;C:\\Windows\\System32\\nvcuda.dll&quot;).VersionInfo  "},{"title":"Useful Environment Variables​","type":1,"pageTitle":"Inspect Shared Library","url":"/blog/inspect-shared-library#useful-environment-variables","content":"OSX: DYLD_LIBRARY_PATHDYLD_PRINT_LIBRARIESDYLD_PRINT_STATISTICS Linux: LD_LIBRARY_PATHLD_DEBUG=libs "},{"title":"References​","type":1,"pageTitle":"Inspect Shared Library","url":"/blog/inspect-shared-library#references","content":"Additional MSVC Build Tools How to Show All Shared Libraries Used by Executables in Linux "},{"title":"LevelDB","type":0,"sectionRef":"#","url":"/blog/leveldb","content":"Principle and use of leveldb - Birost SSTable and Log Structured Storage: LevelDB - igvita.com LevelDB Benchmarks","keywords":""},{"title":"Your markdown including PlantUML code block","type":0,"sectionRef":"#","url":"/blog/markdown-plantuml","content":"@startuml :User: --&gt; (Use) &quot;Main Admin&quot; as Admin &quot;Use the application&quot; as (Use) Admin --&gt; (Admin the application) @enduml ","keywords":""},{"title":"OpenCV tips","type":0,"sectionRef":"#","url":"/blog/opencv-tips","content":"Q: Whether the image/frame from VideoCapture is in BGR or YUV pixels format? A: VideoCapture will convert the image automatically to BGR colorspace. you can disable this conversion (and receive YUV) by setting the CAP_PROP_CONVERT_RGB property to false.","keywords":""},{"title":"Database Migration Using Alembic in Python","type":0,"sectionRef":"#","url":"/blog/python-alembic","content":"","keywords":"Python Alembic"},{"title":"Resources​","type":1,"pageTitle":"Database Migration Using Alembic in Python","url":"/blog/python-alembic#resources","content":""},{"title":"Python Benchmark","type":0,"sectionRef":"#","url":"/blog/python-benchmark","content":"Ok, here is the cost of acquiring and releasing an uncontended lock under Linux, with Python 3.2: $ ./python -m timeit \\ -s &quot;from threading import Lock; l=Lock(); a=l.acquire; r=l.release&quot; \\ &quot;a(); r()&quot; 10000000 loops, best of 3: 0.127 usec per loop And here is the cost of calling a dummy Python function: $ ./python -m timeit -s &quot;def a(): pass&quot; &quot;a(); a()&quot; 1000000 loops, best of 3: 0.221 usec per loop And here is the cost of calling a trivial C function (which returns the False singleton): $ ./python -m timeit -s &quot;a=bool&quot; &quot;a(); a()&quot; 10000000 loops, best of 3: 0.164 usec per loop Also, note that using the lock as a context manager is actually slower, not faster as you might imagine: $ ./python -m timeit -s &quot;from threading import Lock; l=Lock()&quot; \\ &quot;with l: pass&quot; 1000000 loops, best of 3: 0.242 usec per loop At least under Linux, there doesn't seem to be a lot of room for improvement in lock performance, to say the least. PS: RLock is now as fast as Lock: $ ./python -m timeit \\ -s &quot;from threading import RLock; l=RLock(); a=l.acquire; r=l.release&quot; \\ &quot;a(); r()&quot; 10000000 loops, best of 3: 0.114 usec per loop ","keywords":""},{"title":"Python C Library","type":0,"sectionRef":"#","url":"/blog/python-c-library","content":"","keywords":"Python C"},{"title":"Python int object​","type":1,"pageTitle":"Python C Library","url":"/blog/python-c-library#python-int-object","content":"Python uses a variable-size integer representation, Overhead size: 24 bytes, including Python header objectData size: 4 or 8 bytes, storing smaller int using 4 bytes and bigger int using 8 bytes. &gt;&gt;&gt; sys.getsizeof(0x560f7ab1e1c0) 32 &gt;&gt;&gt; sys.getsizeof(0xc0) 28  "},{"title":"Resources​","type":1,"pageTitle":"Python C Library","url":"/blog/python-c-library#resources","content":""},{"title":"Python Module","type":0,"sectionRef":"#","url":"/blog/python-module","content":"","keywords":""},{"title":"Python Module Search Path​","type":1,"pageTitle":"Python Module","url":"/blog/python-module#python-module-search-path","content":"The Module Search Path Introduction to Python module search path "},{"title":"Python Package Management","type":0,"sectionRef":"#","url":"/blog/python-package-management","content":"","keywords":"docs docusaurus"},{"title":"Todo List​","type":1,"pageTitle":"Python Package Management","url":"/blog/python-package-management#todo-list","content":"First tabstopA second tabstopA third tabstop Note Created: 2023-06-26  Try out the above example by running the Foam: Create New Note From Template command and selecting the your-first-template template. Notice what happens when your new note is created! To remove this template, simply delete the .foam/templates/your-first-template.md file. Enjoy! "},{"title":"Python Celery","type":0,"sectionRef":"#","url":"/blog/python-celery-workflow","content":"","keywords":"Python Celery"},{"title":"Construct a workflow​","type":1,"pageTitle":"Python Celery","url":"/blog/python-celery-workflow#construct-a-workflow","content":""},{"title":"Avoid running synchronous subtasks within a task​","type":1,"pageTitle":"Python Celery","url":"/blog/python-celery-workflow#avoid-running-synchronous-subtasks-within-a-task","content":""},{"title":"Asynchronous tasks with a task​","type":1,"pageTitle":"Python Celery","url":"/blog/python-celery-workflow#asynchronous-tasks-with-a-task","content":"@app.task(bind=True) def update_page_info(self, url): # fetch_page -&gt; parse_page -&gt; store_page chain = fetch_page.s(url) | parse_page.s() | store_page_info.s(url) # chain() self.replace(chain) @app.task() def fetch_page(url): return myhttplib.get(url) @app.task() def parse_page(page): return myparser.parse_document(page) @app.task(ignore_result=True) def store_page_info(info, url): PageInfo.objects.create(url=url, info=info)  "},{"title":"Monitor the workflow​","type":1,"pageTitle":"Python Celery","url":"/blog/python-celery-workflow#monitor-the-workflow","content":""},{"title":"Resources​","type":1,"pageTitle":"Python Celery","url":"/blog/python-celery-workflow#resources","content":"Designing Dynamic Workflows with Celery and Python | by Marin Aglić | Data Engineer Things The Curious Case of Celery Work-flows Celery ETA Tasks Demystified. At Instawork, we use Celery to queue… | by Oleg Pesok | Instawork Engineering Canvas: Designing Work-flows — Celery 5.3.6 documentation "},{"title":"Celery","type":0,"sectionRef":"#","url":"/blog/python-celery","content":"","keywords":"celery"},{"title":"Celery worker​","type":1,"pageTitle":"Celery","url":"/blog/python-celery#celery-worker","content":"Celery worker Mechanism: To start a Celery worker will start a main process that will spawn child processes or threads(based on the --pool option): the main process will handle receiving task/sending task result the and these child processes/threads(a.k.a execution pool) execute the actual tasks. To increase the number of child processes/threads(via --concurrency option) will increase the number of tasks the Celery worker can process in parallel. More processes are usually better. However, in reality, there are some situations in following modes: Run N workers with M child processes each.Run 1 worker with N*M child processes.Run N workers with only 1 main process each.Run N workers with M child threads each.Run 1 worker with N*M child threads. Whether to use processes or threads depends on what your tasks will actually do and whether they are GPU bound or IO bound. "},{"title":"Worker procedure​","type":1,"pageTitle":"Celery","url":"/blog/python-celery#worker-procedure","content":"from celery import Celery app = Celery(...) @app.task() def add(x, y): return x + y @app.task() def mul(x, y): return x * y  The @app.task decoration will use Task class in default if you don't specify explicitly. When a worker start by celery -A tasks worker, Worker will spawn child Processes, the number of child Processes is based on CPU cores in default.Each child Process will initialize a Task instance for every decorated function. Here add() has its own Task instance and mul() also has its own Task instance respectively. When a client call add.delay(1, 2), Worker receive a Task in Queue.Worker assign the Task to a child Process, which will determine to use which Task instance to execute. A Task instance is initialized in each decorated function and registered with a task name using function name in default(such as add, mul). Here is the Task instance with name add() should be picked up to run the task.When be decorated in add(), the Task instance run() method will be add() original function body. The child Process will use the Task instance's __call__() method to run task, and __call__() will invoke the run() within itself.  "},{"title":"Option --pool=prefork​","type":1,"pageTitle":"Celery","url":"/blog/python-celery#option---poolprefork","content":"It spawns multiple processes. When start a Celery worker via celery -A tasks worker --loglevel INFO --concurrency 3 --pool=prefork, what will happen underneath? Celery start a main process.The main process will then spawn 3 child processes. The default concurrency is based on the number of CPU available on the machine. The default pool is prefork which uses multiprocessing library from Python.These child processes will execute the tasks assigned from the main process. "},{"title":"Option --pool=eventlet or --pool=gevent​","type":1,"pageTitle":"Celery","url":"/blog/python-celery#option---pooleventlet-or---poolgevent","content":"It creates multiple threads. When start a Celery worker via celery -A tasks worker --loglevel INFO --concurrency 3 --pool=eventlet "},{"title":"Option --pool=solo​","type":1,"pageTitle":"Celery","url":"/blog/python-celery#option---poolsolo","content":"It will not create any child process or thread to run task. The tasks will be executed in main process, which causes the main process to be blocked. It seems as: Run 1 worker with 1 process, however --concurrency will not take any effect when --pool=solo! When coming to a microservices environment, this option becomes useful and practical especially running CPU intensive tasks. The container manager such as Docker can increase the task processing capabilities through managing the number of worker containers instead of managing the number of pool processes per worker. When start a Celery worker via celery -A tasks worker --loglevel INFO --pool=solo "},{"title":"Celery Task​","type":1,"pageTitle":"Celery","url":"/blog/python-celery#celery-task","content":"What's the lifecycle of a Celery task from the time it's created to the it's done? Here we analyze a simple task with all Celery configuration in default and use Redis as broker and backend @app.task(acks_late=True) def wait(secs: float) -&gt; str: print(f&quot;wait() - Start, secs[{secs}]s&quot;) time.sleep(secs) print(f&quot;wait() - Done, secs[{secs}]s&quot;) return f&quot;wait() - Done, secs[{secs}]s&quot;  When a client call wait.delay(60), this task is added to a default queue named celery in Redis.Celery worker polls the queue and pulls the task, then it removes the task from the queue and moves it a special queue named unacked in Redis.The worker holds on to the task(prefetch), until it has abilities to process the task.Once after The worker successfully processes the task, it acks now (acks_late=True) that it removes the task from the unacked queue in Redis. If acks_late=False, the worker acks before processing the task. Let's get more concrete understanding in practices. First, let's enter a redis-cli interactive mode with the newly launched application, 127.0.0.1:6379&gt; KEYS * 1) &quot;_kombu.binding.email_service&quot; 2) &quot;_kombu.binding.ml_service&quot; 3) &quot;_kombu.binding.celery.pidbox&quot; 4) &quot;_kombu.binding.celeryev&quot; 5) &quot;_kombu.binding.celery&quot;  At the beginning, you can see that the celery key and the unacked key do not exist in Redis. Then, let's call wait.delay(60) multiple times at the same time, 127.0.0.1:6379&gt; KEYS * 1) &quot;unacked_index&quot; 2) &quot;_kombu.binding.email_service&quot; 3) &quot;_kombu.binding.celery.pidbox&quot; 4) &quot;celery-task-meta-3d6b2028-6ee6-4e2c-85f1-cbeba644aca5&quot; 5) &quot;celery&quot; 6) &quot;_kombu.binding.celeryev&quot; 7) &quot;_kombu.binding.celery&quot; 8) &quot;_kombu.binding.ml_service&quot; 9) &quot;celery-task-meta-e5a1b7db-f1ad-4d3e-b2b9-3b7de8f8c87e&quot; 10) &quot;unacked&quot; 127.0.0.1:6379&gt; TYPE unacked hash 127.0.0.1:6379&gt; TYPE celery list  After we create tasks, the celery key of list type and the unacked key of hash type are both created in Redis. 127.0.0.1:6379&gt; LRANGE celery 0 -1 1) &quot;{\\&quot;body\\&quot;: \\&quot;W1s2MC4wXSwge30sIHsiY2FsbGJhY2tzIjogbnVsbCwgImVycmJhY2tzIjogbnVsbCwgImNoYWluIjogbnVsbCwgImNob3JkIjogbnVsbH1d\\&quot;, \\&quot;content-encoding\\&quot;: \\&quot;utf-8\\&quot;, \\&quot;content-type\\&quot;: \\&quot;application/json\\&quot;, \\&quot;headers\\&quot;: {\\&quot;lang\\&quot;: \\&quot;py\\&quot;, \\&quot;task\\&quot;: \\&quot;app.celery_app.tasks.wait\\&quot;, \\&quot;id\\&quot;: \\&quot;da959152-1f45-4846-99e4-5205d30c1be7\\&quot;, \\&quot;shadow\\&quot;: null, \\&quot;eta\\&quot;: null, \\&quot;expires\\&quot;: null, \\&quot;group\\&quot;: null, \\&quot;group_index\\&quot;: null, \\&quot;retries\\&quot;: 0, \\&quot;timelimit\\&quot;: [null, null], \\&quot;root_id\\&quot;: \\&quot;da959152-1f45-4846-99e4-5205d30c1be7\\&quot;, \\&quot;parent_id\\&quot;: null, \\&quot;argsrepr\\&quot;: \\&quot;(60.0,)\\&quot;, \\&quot;kwargsrepr\\&quot;: \\&quot;{}\\&quot;, \\&quot;origin\\&quot;: \\&quot;gen11@a840cdd15b13\\&quot;, \\&quot;ignore_result\\&quot;: false}, \\&quot;properties\\&quot;: {\\&quot;correlation_id\\&quot;: \\&quot;da959152-1f45-4846-99e4-5205d30c1be7\\&quot;, \\&quot;reply_to\\&quot;: \\&quot;4b0f2f2d-aee2-3349-81ab-e95a1f0e9f02\\&quot;, \\&quot;delivery_mode\\&quot;: 2, \\&quot;delivery_info\\&quot;: {\\&quot;exchange\\&quot;: \\&quot;\\&quot;, \\&quot;routing_key\\&quot;: \\&quot;celery\\&quot;}, \\&quot;priority\\&quot;: 0, \\&quot;body_encoding\\&quot;: \\&quot;base64\\&quot;, \\&quot;delivery_tag\\&quot;: \\&quot;d657c66d-4e4b-483d-9fbe-fe4b5b9541e7\\&quot;}}&quot; 2) &quot;{\\&quot;body\\&quot;: \\&quot;W1s2MC4wXSwge30sIHsiY2FsbGJhY2tzIjogbnVsbCwgImVycmJhY2tzIjogbnVsbCwgImNoYWluIjogbnVsbCwgImNob3JkIjogbnVsbH1d\\&quot;, \\&quot;content-encoding\\&quot;: \\&quot;utf-8\\&quot;, \\&quot;content-type\\&quot;: \\&quot;application/json\\&quot;, \\&quot;headers\\&quot;: {\\&quot;lang\\&quot;: \\&quot;py\\&quot;, \\&quot;task\\&quot;: \\&quot;app.celery_app.tasks.wait\\&quot;, \\&quot;id\\&quot;: \\&quot;1ddc3c5e-fa33-4d12-aa3f-c3d13581a4c8\\&quot;, \\&quot;shadow\\&quot;: null, \\&quot;eta\\&quot;: null, \\&quot;expires\\&quot;: null, \\&quot;group\\&quot;: null, \\&quot;group_index\\&quot;: null, \\&quot;retries\\&quot;: 0, \\&quot;timelimit\\&quot;: [null, null], \\&quot;root_id\\&quot;: \\&quot;1ddc3c5e-fa33-4d12-aa3f-c3d13581a4c8\\&quot;, \\&quot;parent_id\\&quot;: null, \\&quot;argsrepr\\&quot;: \\&quot;(60.0,)\\&quot;, \\&quot;kwargsrepr\\&quot;: \\&quot;{}\\&quot;, \\&quot;origin\\&quot;: \\&quot;gen11@a840cdd15b13\\&quot;, \\&quot;ignore_result\\&quot;: false}, \\&quot;properties\\&quot;: {\\&quot;correlation_id\\&quot;: \\&quot;1ddc3c5e-fa33-4d12-aa3f-c3d13581a4c8\\&quot;, \\&quot;reply_to\\&quot;: \\&quot;4b0f2f2d-aee2-3349-81ab-e95a1f0e9f02\\&quot;, \\&quot;delivery_mode\\&quot;: 2, \\&quot;delivery_info\\&quot;: {\\&quot;exchange\\&quot;: \\&quot;\\&quot;, \\&quot;routing_key\\&quot;: \\&quot;celery\\&quot;}, \\&quot;priority\\&quot;: 0, \\&quot;body_encoding\\&quot;: \\&quot;base64\\&quot;, \\&quot;delivery_tag\\&quot;: \\&quot;927d1ac0-3709-4e23-8c0f-037713c55217\\&quot;}}&quot;  127.0.0.1:6379&gt; HGETALL unacked 1) &quot;927d1ac0-3709-4e23-8c0f-037713c55217&quot; 2) &quot;[{\\&quot;body\\&quot;: \\&quot;W1s2MC4wXSwge30sIHsiY2FsbGJhY2tzIjogbnVsbCwgImVycmJhY2tzIjogbnVsbCwgImNoYWluIjogbnVsbCwgImNob3JkIjogbnVsbH1d\\&quot;, \\&quot;content-encoding\\&quot;: \\&quot;utf-8\\&quot;, \\&quot;content-type\\&quot;: \\&quot;application/json\\&quot;, \\&quot;headers\\&quot;: {\\&quot;lang\\&quot;: \\&quot;py\\&quot;, \\&quot;task\\&quot;: \\&quot;app.celery_app.tasks.wait\\&quot;, \\&quot;id\\&quot;: \\&quot;1ddc3c5e-fa33-4d12-aa3f-c3d13581a4c8\\&quot;, \\&quot;shadow\\&quot;: null, \\&quot;eta\\&quot;: null, \\&quot;expires\\&quot;: null, \\&quot;group\\&quot;: null, \\&quot;group_index\\&quot;: null, \\&quot;retries\\&quot;: 0, \\&quot;timelimit\\&quot;: [null, null], \\&quot;root_id\\&quot;: \\&quot;1ddc3c5e-fa33-4d12-aa3f-c3d13581a4c8\\&quot;, \\&quot;parent_id\\&quot;: null, \\&quot;argsrepr\\&quot;: \\&quot;(60.0,)\\&quot;, \\&quot;kwargsrepr\\&quot;: \\&quot;{}\\&quot;, \\&quot;origin\\&quot;: \\&quot;gen11@a840cdd15b13\\&quot;, \\&quot;ignore_result\\&quot;: false}, \\&quot;properties\\&quot;: {\\&quot;correlation_id\\&quot;: \\&quot;1ddc3c5e-fa33-4d12-aa3f-c3d13581a4c8\\&quot;, \\&quot;reply_to\\&quot;: \\&quot;4b0f2f2d-aee2-3349-81ab-e95a1f0e9f02\\&quot;, \\&quot;delivery_mode\\&quot;: 2, \\&quot;delivery_info\\&quot;: {\\&quot;exchange\\&quot;: \\&quot;\\&quot;, \\&quot;routing_key\\&quot;: \\&quot;celery\\&quot;}, \\&quot;priority\\&quot;: 0, \\&quot;body_encoding\\&quot;: \\&quot;base64\\&quot;, \\&quot;delivery_tag\\&quot;: \\&quot;927d1ac0-3709-4e23-8c0f-037713c55217\\&quot;}}, \\&quot;\\&quot;, \\&quot;celery\\&quot;]&quot;  Wait for all these tasks to be done 127.0.0.1:6379&gt; KEYS * 1) &quot;_kombu.binding.email_service&quot; 2) &quot;celery-task-meta-da959152-1f45-4846-99e4-5205d30c1be7&quot; 3) &quot;celery-task-meta-815587f5-782d-454a-8498-b4ebbb91abd8&quot; 4) &quot;_kombu.binding.celery.pidbox&quot; 5) &quot;celery-task-meta-3d6b2028-6ee6-4e2c-85f1-cbeba644aca5&quot; 6) &quot;_kombu.binding.celeryev&quot; 7) &quot;_kombu.binding.celery&quot; 8) &quot;_kombu.binding.ml_service&quot; 9) &quot;celery-task-meta-1ddc3c5e-fa33-4d12-aa3f-c3d13581a4c8&quot; 10) &quot;celery-task-meta-e5a1b7db-f1ad-4d3e-b2b9-3b7de8f8c87e&quot;  After all tasks are done successfully, both keys: celery and unacked are removed from Redis. The result of a task is stored in celery-task-meta-{{uuid}} key. 127.0.0.1:6379&gt; TYPE celery-task-meta-da959152-1f45-4846-99e4-5205d30c1be7 string 127.0.0.1:6379&gt; GET celery-task-meta-da959152-1f45-4846-99e4-5205d30c1be7 &quot;{\\&quot;status\\&quot;: \\&quot;SUCCESS\\&quot;, \\&quot;result\\&quot;: \\&quot;wait() - Done, secs[60.0]s\\&quot;, \\&quot;traceback\\&quot;: null, \\&quot;children\\&quot;: [], \\&quot;date_done\\&quot;: \\&quot;2023-11-07T07:54:16.954872\\&quot;, \\&quot;task_id\\&quot;: \\&quot;da959152-1f45-4846-99e4-5205d30c1be7\\&quot;}&quot;  "},{"title":"Serve machine learning model​","type":1,"pageTitle":"Celery","url":"/blog/python-celery#serve-machine-learning-model","content":"Properly running a machine learning model in task is different with running other jobs as we need avoiding loading ML model every time we run tasks. So it is stateful that we should keep something in worker. "},{"title":"Different workers for different tasks​","type":1,"pageTitle":"Celery","url":"/blog/python-celery#different-workers-for-different-tasks","content":"Assuming a such situation: There is a worker x to only handle email tasks and a worker y to only handle machine learning related tasks. These are configurations for project x: #Celery routing. app.conf.task_routes = { 'celery_app.email_tasks.*': { 'queue': 'email_service', }, } #Run celery. celery -A celery_app.email_tasks:app worker -l info -E -Q email_service  These are configurations for project y: #Celery routing. app.conf.task_routes = { 'celery_app.ml_tasks.*': { 'queue': 'ml_service', }, } #Run celery. celery -A celery_app.ml_tasks:app worker -l info -E -Q ml_service  Details in explanation: Different workers handle their own queues for separate tasks. Look at https://github.com/liviaerxin/fastapi-celery-ml for see a complete Celery project. "},{"title":"Code Analysis​","type":1,"pageTitle":"Celery","url":"/blog/python-celery#code-analysis","content":"from celery import signature sig = add.s(2, 2) sig.freeze()  "},{"title":"Known issues​","type":1,"pageTitle":"Celery","url":"/blog/python-celery#known-issues","content":"Result state is always PENDING in windows FIX: use --pool=solo instead of --pool=prefork in default. multiprocessing may cause this problem as its some defect in windows! Long running jobs redelivering after broker visibility timeout with celery and redis · Issue #5935 · celery/celery · GitHubLong tasks are executed multiple times · Issue #3430 · celery/celery · GitHub No Worker Heartbeat With Solo Pool · Issue #3768 · celery/celery · GitHub "},{"title":"Resources​","type":1,"pageTitle":"Celery","url":"/blog/python-celery#resources","content":"Celery - Distributed Task Queue — Celery 5.3.4 documentation Celery Execution Pools: What is it all about? Celery Execution Pool: The worker and the pool - separation of concerns Serving ML Models in Production with FastAPI and Celery | by Jonathan Readshaw | Towards Data Science GitHub - liviaerxin/FastAPISpamDetection: Code for my Medium article: &quot;How you can quickly deploy your ML models with FastAPI&quot; Celery ETA Tasks Demystified. At Instawork, we use Celery to queue… | by Oleg Pesok | Instawork Engineering "},{"title":"QEMU Direct Linux Kernel Boot","type":0,"sectionRef":"#","url":"/blog/qemu-linux-kernel-boot","content":"","keywords":"QEMU Linux Kernel Boot"},{"title":"Prerequisites​","type":1,"pageTitle":"QEMU Direct Linux Kernel Boot","url":"/blog/qemu-linux-kernel-boot#prerequisites","content":"On Ubuntu, sudo apt-get install git fakeroot build-essential ncurses-dev xz-utils libssl-dev bc flex libelf-dev bison  On macOS, you need create a Case Sensitive filesystem and use GNU GCC instead of Clang the following ways: hdiutil create -size 20g -type SPARSE -fs &quot;Case-sensitive HFS+&quot; -volname brosx brosx.sparseimage hdiutil attach brosx.sparseimage  hdiutil detach /Volumes/brosx -force  brew install gpatch gcc flock attr libtool libart  ln -s /opt/homebrew/bin/gcc-13 /opt/homebrew/bin/gcc n -s /opt/homebrew/bin/gcc-13 /opt/homebrew/bin/cc ln -s /opt/homebrew/bin/g++-13 /opt/homebrew/bin/g++ ln -s /opt/homebrew/bin/g++-13 /opt/homebrew/bin/c++  rm /opt/homebrew/bin/gcc /opt/homebrew/bin/cc /opt/homebrew/bin/g++ /opt/homebrew/bin/c++  "},{"title":"Build Linux kernel​","type":1,"pageTitle":"QEMU Direct Linux Kernel Boot","url":"/blog/qemu-linux-kernel-boot#build-linux-kernel","content":"wget https://cdn.kernel.org/pub/linux/kernel/v6.x/linux-6.1.55.tar.xz  tar xvf linux-6.1.55.tar.xz cd linux-6.1.55  # Use the default `x86_64` configuration file form `/x86/configs/x86_64_defconfig` make ARCH=x86_64 x86_64_defconfig  # Tweak some options for GDB and initramfs make menuconfig  make -j8  Generate kernel file ./arch/x86/boot/bzImage. note To extract vmlinux from bzImage, ./scripts/extract-vmlinux ./arch/x86_64/boot/bzImage &gt;./arch/x86_64/boot/vmlinux  "},{"title":"Build root filesystem​","type":1,"pageTitle":"QEMU Direct Linux Kernel Boot","url":"/blog/qemu-linux-kernel-boot#build-root-filesystem","content":"git clone https://github.com/buildroot/buildroot.git cd buildroot  make menuconfig  Choose x86_64 as Target Architecture and ext4 root file system. make -j8  Generate root filesystem disk ./output/images/rootfs.ext4. "},{"title":"Run QEMU​","type":1,"pageTitle":"QEMU Direct Linux Kernel Boot","url":"/blog/qemu-linux-kernel-boot#run-qemu","content":"Copy bzImage and rootfs.ext4 to any host machine with QEMU available. rsync -l ./linux-6.1.55/arch/x86/boot/bzImage destination_directory/ rsync -l ./buildroot/output/images/rootfs.ext4 destination_directory/  kernel=&quot;$PWD/linux_qemu/x86_64/bzImage&quot; vmlinuz=&quot;$PWD/linux_qemu/x86_64/vmlinux&quot; initrd=&quot;$PWD/linux_qemu/x86_64/rootfs.ext4&quot; img=&quot;$PWD/linux_qemu/x86_64/rootfs.ext4&quot;  qemu-system-x86_64 \\ -nographic \\ -m 4G \\ -kernel $kernel \\ -append &quot;earlyprintk loglevel=8 root=/dev/zero console=ttyS0&quot;  qemu-system-x86_64 \\ -nographic \\ -m 4G \\ -kernel $kernel \\ -hda $img \\ -append &quot;earlyprintk loglevel=8 root=/dev/sda rootfstype=ext4 console=ttyS0&quot; \\ -netdev user,id=mynet,hostfwd=tcp::2222-:22 \\ -device virtio-net-pci,netdev=mynet  Default password: root "},{"title":"Debug Linux kernel​","type":1,"pageTitle":"QEMU Direct Linux Kernel Boot","url":"/blog/qemu-linux-kernel-boot#debug-linux-kernel","content":"qemu-system-x86_64 \\ -s -S \\ -nographic \\ -m 4G \\ -kernel $kernel \\ -append &quot;earlyprintk loglevel=8 root=/dev/zero console=ttyS0 nokaslr&quot;  Options in details, -s: allows port tcp::1234 for remote debug-S: stop CPU until continue from GDB what is connected to tcp 1234 port-append nokaslr: turn off KASLR Or with root filesystem, qemu-system-x86_64 \\ -nographic \\ -m 4G \\ -s -S \\ -kernel $kernel \\ -hda $img \\ -append &quot;earlyprintk loglevel=8 root=/dev/sda rootfstype=ext4 console=ttyS0 nokaslr&quot; \\ -netdev user,id=mynet,hostfwd=tcp::2222-:22 \\ -device virtio-net-pci,netdev=mynet  Enter gdb, $ gdb ./vmlinux  In gdb shell, (gdb) target remote 10.6.64.243:1234 Remote debugging using 10.6.64.243:1234 warning: No executable has been specified and target does not support determining executable automatically. Try using the &quot;file&quot; command. 0x000000000000fff0 in ?? () (gdb) continue Continuing.  "},{"title":"Resources​","type":1,"pageTitle":"QEMU Direct Linux Kernel Boot","url":"/blog/qemu-linux-kernel-boot#resources","content":"Daniel P. Berrangé » Blog Archive » make-tiny-image.py: creating tiny initrds for testing QEMU or Linux kernel/userspace behaviour GitHub - dhruvvyas90/qemu-rpi-kernel: Qemu kernel for emulating Rpi on QEMUhttps://medicineyeh.wordpress.com/2016/03/29/buildup-your-arm-image-for-qemu/ Prepare the environment for developing Linux kernel with qemu. | by DaeSeok Youn | Medium  "},{"title":"QEMU Emulate Raspberry Pi 3 and 4","type":0,"sectionRef":"#","url":"/blog/qemu-raspberry-pi","content":"","keywords":"QEMU Raspberry Pi 3/4"},{"title":"Prerequisites​","type":1,"pageTitle":"QEMU Emulate Raspberry Pi 3 and 4","url":"/blog/qemu-raspberry-pi#prerequisites","content":"Docker be required in macOScan be skipped in Linuxcan use wsl as an alternative in Windows QEMU homebrew install in macOS Raspberry Pi image: 2023-05-03-raspios-bullseye-arm64-lite.img Since I am in mac M1, and the raspberry pi image which contains a fat filesystem as boot and a ext4 filesystem as OS, we need write some configuration into it. So I will use a Docker Ubuntu container to do the operation on the the filesystem. There some other tools to do the like of these operations: ext4fuse is free and easy to install via homebrew, but it has limit as read-only access.ExtFS from Paragon supports read-write access while you need pay for it.virtual machine Docker in OSX make use of virtual machine while it is quick and flexible to use. "},{"title":"Raspberry Pi image​","type":1,"pageTitle":"QEMU Emulate Raspberry Pi 3 and 4","url":"/blog/qemu-raspberry-pi#raspberry-pi-image","content":"cd ~ wget https://downloads.raspberrypi.org/raspios_arm64/images/raspios_arm64-2023-05-03/2023-05-03-raspios-bullseye-arm64-lite.img.xz xz -d 2023-05-03-raspios-bullseye-arm64-lite.img.xz  "},{"title":"Docker Ubuntu container​","type":1,"pageTitle":"QEMU Emulate Raspberry Pi 3 and 4","url":"/blog/qemu-raspberry-pi#docker-ubuntu-container","content":"Mount the folder including 2023-05-03-raspios-bullseye-arm64-lite.img docker run -it -d --privileged -v $PWD:/qemu --name ubuntu ubuntu docekr exec -it ubuntu bash  "},{"title":"Extracting Kernel and device tree​","type":1,"pageTitle":"QEMU Emulate Raspberry Pi 3 and 4","url":"/blog/qemu-raspberry-pi#extracting-kernel-and-device-tree","content":"Operations all in Ubuntu container. root@f36a3251391d:/qemu# fdisk -l 2023-05-03-raspios-bullseye-arm64-lite.img Disk 2023-05-03-raspios-bullseye-arm64-lite.img: 1.96 GiB, 2101346304 bytes, 4104192 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0x544c6228 Device Boot Start End Sectors Size Id Type 2023-05-03-raspios-bullseye-arm64-lite.img1 8192 532479 524288 256M c W95 FAT32 (LBA) 2023-05-03-raspios-bullseye-arm64-lite.img2 532480 4104191 3571712 1.7G 83 Linux  The first partition is boot filesystem.The second partition is real root filesystem. All the data we need is in the first partition, to do the operation is mounting it. The offset of the first partition: 8192 * 512 = 4194304, root@f36a3251391d:/qemu# mount -o loop,offset=4194304 2023-05-03-raspios-bullseye-arm64-lite.img /mnt/rpi-boot/  root@f36a3251391d:/qemu# ls -ls /mnt/rpi-boot/ total 30244 20 -rwxr-xr-x 1 root root 18693 Apr 5 11:32 COPYING.linux 2 -rwxr-xr-x 1 root root 1594 Apr 5 11:32 LICENCE.broadcom 30 -rwxr-xr-x 1 root root 30390 Apr 5 11:32 bcm2710-rpi-2-b.dtb 32 -rwxr-xr-x 1 root root 32753 Apr 5 11:32 bcm2710-rpi-3-b-plus.dtb 32 -rwxr-xr-x 1 root root 32142 Apr 5 11:32 bcm2710-rpi-3-b.dtb 30 -rwxr-xr-x 1 root root 30285 Apr 5 11:32 bcm2710-rpi-cm3.dtb 32 -rwxr-xr-x 1 root root 31318 Apr 5 11:32 bcm2710-rpi-zero-2-w.dtb 32 -rwxr-xr-x 1 root root 31318 Apr 5 11:32 bcm2710-rpi-zero-2.dtb 52 -rwxr-xr-x 1 root root 52593 Apr 5 11:32 bcm2711-rpi-4-b.dtb 52 -rwxr-xr-x 1 root root 52682 Apr 5 11:32 bcm2711-rpi-400.dtb 38 -rwxr-xr-x 1 root root 38182 Apr 5 11:32 bcm2711-rpi-cm4-io.dtb 52 -rwxr-xr-x 1 root root 53202 Apr 5 11:32 bcm2711-rpi-cm4.dtb 50 -rwxr-xr-x 1 root root 50504 Apr 5 11:32 bcm2711-rpi-cm4s.dtb 52 -rwxr-xr-x 1 root root 52476 Apr 5 11:32 bootcode.bin 2 -rwxr-xr-x 1 root root 154 May 3 03:11 cmdline.txt 4 -rwxr-xr-x 1 root root 2109 May 3 02:53 config.txt ... 2 -rwxr-xr-x 1 root root 145 May 3 03:11 issue.txt 8028 -rwxr-xr-x 1 root root 8219600 Apr 5 11:32 kernel8.img ...  To run QEMU we will need the kernel and device tree, so let’s copy them out: root@f36a3251391d:/qemu# cp /mnt/rpi-boot/kernel8.img . root@f36a3251391d:/qemu# cp /mnt/rpi-boot/bcm2710-rpi-3-b.dtb .  "},{"title":"Setting up default user​","type":1,"pageTitle":"QEMU Emulate Raspberry Pi 3 and 4","url":"/blog/qemu-raspberry-pi#setting-up-default-user","content":"Operations all in docker container. Now in order to set up user and enable ssh in default, we need write files into /userconf and /ssh under the boot filesystem mounted as /mnt/rpi-boot/. Set up a default user:pi and password:raspberry. Hash password raspberry using openssl, root@f36a3251391d:/qemu# openssl passwd Password: Verifying - Password: $1$d...AvcL$wqfUqTIauUP1TVJ/uU1td0  root@f36a3251391d:/qemu# echo 'pi:$1$d...AvcL$wqfUqTIauUP1TVJ/uU1td0' | tee /mnt/rpi-boot/userconf  Enable ssh, root@f36a3251391d:/qemu# touch /mnt/rpi-boot/ssh  root@f36a3251391d:/qemu# umount /mnt/rpi-boot  "},{"title":"Running QEMU​","type":1,"pageTitle":"QEMU Emulate Raspberry Pi 3 and 4","url":"/blog/qemu-raspberry-pi#running-qemu","content":""},{"title":"Emulate Raspberry Pi 3​","type":1,"pageTitle":"QEMU Emulate Raspberry Pi 3 and 4","url":"/blog/qemu-raspberry-pi#emulate-raspberry-pi-3","content":"Now switch back to the host macOS to run QEMU, Resize the image to the next power of 2 size, The original size, ❯ stat -f%z 2023-05-03-raspios-bullseye-arm64-lite.img 2101346304  To resize to 4GB, qemu-img resize ./2023-05-03-raspios-bullseye-arm64-lite.img 4G  qemu-system-aarch64 \\ -machine raspi3b \\ -cpu cortex-a72 \\ -nographic \\ -m 1G \\ -smp 4 \\ -dtb bcm2710-rpi-3-b.dtb \\ -kernel kernel8.img \\ -append &quot;rw earlyprintk loglevel=8 console=ttyAMA0,115200 dwc_otg.lpm_enable=0 root=/dev/mmcblk0p2 rootdelay=1&quot; \\ -netdev user,id=net0,hostfwd=tcp::2222-:22 \\ -device usb-net,netdev=net0 \\ -sd 2023-05-03-raspios-bullseye-arm64-lite.img  Options in detail: -machine raspi3b: use raspberry pi 3 machine.-append: console=ttyAMA0: output the VM std to QEMU console.root=/dev/mmcblk0p2: mount real root filesystem to /dev/mmcblk0p2(the second partition of mmcblk0) as we -sd xx will be mounted to /dev/mmcblk0. -netdev user,id=net0,hostfwd=tcp::2222-:22: network mapping host port 2222 to the VM 22-device usb-net,netdev=net0: expose netdev=net0 as usb-net in the raspberry pi 3 machine.-sd 2023-05-03-raspios-bullseye-arm64-lite.img: sd drive is available in the raspberry pi 3 machine. "},{"title":"Emulate Raspberry Pi 4 with virt​","type":1,"pageTitle":"QEMU Emulate Raspberry Pi 3 and 4","url":"/blog/qemu-raspberry-pi#emulate-raspberry-pi-4-with-virt","content":"We will use generic virtual machine virt to act as raspi4, since there is no raspi4 machine defined in QEMU official machines. However you can still use raspi3 to act as raspi4 as they are same! Hardware Acceleration can be enable in virt machine by using -accel hvf option in my mac M1 host as it's arm-based. So virt will bring high performance and increase efficiency! After tuning options and searching from many resources, the operational setting for QEMU to emulate is, Use ubuntu-22.04.3-preinstalled-server-arm64+raspi.img, of which the default user is ubuntu and password is ubuntu. kernel=&quot;$PWD/ubuntu-22.04.3-preinstalled-server-arm64+raspi-boot/vmlinuz&quot; initrd=&quot;$PWD/ubuntu-22.04.3-preinstalled-server-arm64+raspi-boot/initrd.img&quot; img=&quot;$PWD/ubuntu-22.04.3-preinstalled-server-arm64+raspi.img&quot;  For SCSI hard disk​ This storage device file will be named /dev/sdX, qemu-system-aarch64 \\ -machine virt \\ -accel hvf \\ -cpu host \\ -smp 4 \\ -m 4G \\ -nographic \\ -kernel $kernel \\ -initrd $initrd \\ -append &quot;earlyprintk loglevel=8 root=/dev/sda2 rootfstype=ext4 rw console=ttyAMA0&quot; \\ -drive file=$img,format=raw,if=none,id=drive0 \\ -device virtio-scsi-pci,id=scsi \\ -device scsi-hd,drive=drive0,bus=scsi.0 \\ -netdev user,id=mynet,hostfwd=tcp::2222-:22 \\ -device virtio-net-pci,netdev=mynet  Options in detail: -accel hvf: hardware acceleration in mac M1. Don't use in x86_64 host.-cpu host: change to -cpu cortex-a72 when no hardware acceleration available such as in x86_64 host.-append root=/dev/sda2: the second partition of the ubuntu-22.04.3-preinstalled-server-arm64+raspi.img disk image hold the real root filesystem. -initrd $initrd the boot loader works using configuration like vmlinuz initrd=initrd.img root=/dev/sda2. For virtual disk storage device​ This storage device file will be named /dev/vdX, qemu-system-aarch64 \\ -machine virt \\ -accel hvf \\ -cpu host \\ -smp 4 \\ -m 4G \\ -nographic \\ -kernel $kernel \\ -initrd $initrd \\ -append &quot;earlyprintk loglevel=8 root=/dev/vda2 rootfstype=ext4 rw console=ttyAMA0&quot; \\ -drive file=$img,format=raw,if=none,id=drive0 \\ -device virtio-blk-pci,drive=drive0 \\ -netdev user,id=mynet,hostfwd=tcp::2222-:22 \\ -device virtio-net-pci,netdev=mynet  For NVMe storage device​ This storage device file will be named /dev/nvmeX, qemu-system-aarch64 \\ -machine virt \\ -accel hvf \\ -cpu host \\ -smp 4 \\ -m 4G \\ -nographic \\ -kernel $kernel \\ -append &quot;earlyprintk loglevel=8 root=/dev/nvme0n1p2 rootfstype=ext4 rw console=ttyAMA0&quot; \\ -drive file=$img,format=raw,if=none,id=drive0 \\ -device nvme,drive=drive0,serial=deadbeaf1 \\ -netdev user,id=mynet,hostfwd=tcp::2222-:22 \\ -device virtio-net-pci,netdev=mynet  Options in detail: no -initrd $initrd the boot loader works using configuration like vmlinuz root=/dev/nvme0n1p2.we directly mount the real filesystem /dev/nvme0n1p2, skipping to mount the initial RAM disk.I test other type storage device must binding -initrd $initrd while there is no need for NVME. In my assumption, those storage devices need to be configured in the initramfs. For usb storage​ This storage device file will be named /dev/sdX, qemu-system-aarch64 \\ -machine virt \\ -cpu cortex-a57 \\ -smp 4 \\ -m 4G \\ -no-reboot \\ -nographic \\ -kernel $kernel \\ -initrd $initrd \\ -append &quot;earlyprintk loglevel=8 root=/dev/sda2 rootfstype=ext4 console=ttyAMA0 raid=noautodetect&quot; \\ -device usb-ehci \\ -device usb-storage,drive=disk0 \\ -drive file=$img,format=raw,if=none,id=disk0 \\ -device virtio-net-pci,netdev=mynet \\ -netdev user,id=mynet,hostfwd=tcp::2222-:22  Options in detail: -device usb-ehci: usb bus -&gt; PCI bus-device usb-storage: usb storage device -&gt; usb bus "},{"title":"Test Raspberry Pi VM​","type":1,"pageTitle":"QEMU Emulate Raspberry Pi 3 and 4","url":"/blog/qemu-raspberry-pi#test-raspberry-pi-vm","content":"Log into the Raspberry Pi via ssh from the macOS host, ❯ ssh -p 2222 pi@localhost The authenticity of host '[localhost]:2222 ([127.0.0.1]:2222)' can't be established. ED25519 key fingerprint is SHA256:6igL6iaigBCszv8m6nyNl+tsB2siV/tL+TRQANC6nBw. This key is not known by any other names Are you sure you want to continue connecting (yes/no/[fingerprint])? yes Warning: Permanently added '[localhost]:2222' (ED25519) to the list of known hosts. pi@localhost's password: Linux raspberrypi 6.1.21-v8+ #1642 SMP PREEMPT Mon Apr 3 17:24:16 BST 2023 aarch64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. Last login: Fri Sep 22 16:30:58 2023 SSH is enabled and the default password for the 'pi' user has not been changed. This is a security risk - please login as the 'pi' user and type 'passwd' to set a new password. pi@raspberrypi:~ $  "},{"title":"Resources​","type":1,"pageTitle":"QEMU Emulate Raspberry Pi 3 and 4","url":"/blog/qemu-raspberry-pi#resources","content":"Emulating a Raspberry Pi in QEMU | InterruptEmulating a Raspberry Pi in QEMU How to emulate block devices with QEMU Emulation of block devices — Das U-Boot unknown version documentation "},{"title":"REST API Filtering, Sorting and Pagination","type":0,"sectionRef":"#","url":"/blog/rest-api-filtering-sorting-pagination","content":"api-guidelines/Guidelines.md at vNext · microsoft/api-guidelines · GitHub REST API Design: Filtering, Sorting, and Pagination | Moesif Blog How we write our query filter engine on our REST API (part 1) | by Adam Ben Aharon | Melio’s R&amp;D blog | Medium","keywords":"rest api filtering  sorting and pagination"},{"title":"Python Unicode String","type":0,"sectionRef":"#","url":"/blog/python-unicode-string","content":"","keywords":"Python Unicode memory layout"},{"title":"FAQ​","type":1,"pageTitle":"Python Unicode String","url":"/blog/python-unicode-string#faq","content":""},{"title":"Why Python doesn't use UTF-8 encoding variable-length bytes in memory directly, why it will convert them to UCS-2 or UCS-4 data?​","type":1,"pageTitle":"Python Unicode String","url":"/blog/python-unicode-string#why-python-doesnt-use-utf-8-encoding-variable-length-bytes-in-memory-directly-why-it-will-convert-them-to-ucs-2-or-ucs-4-data","content":"Keep each character in a string in the same width in the data memory. What's the purpose? Indexing into strings in Python is operated in a constant time, as it's based on the fixed-length encodings. "},{"title":"How do other programming languages access character in a string by index?​","type":1,"pageTitle":"Python Unicode String","url":"/blog/python-unicode-string#how-do-other-programming-languages-access-character-in-a-string-by-index","content":"Go Iterating yields Unicode code pointIndexing yields a byte Rust Iteration yields Unicode code point(method.chars()) or byte(method.bytes)Indexing not supported Python Iterating yields Unicode code pointIndexing yields Unicode code point "},{"title":"How a string in Python is printed on the screen?​","type":1,"pageTitle":"Python Unicode String","url":"/blog/python-unicode-string#how-a-string-in-python-is-printed-on-the-screen","content":"You may wonder why they have the same result on the terminal from Python output, assuming that the terminal is using the UTF-8 encoding. &gt;&gt;&gt; &quot;\\xe9&quot; 'é' &gt;&gt;&gt; &quot;\\u00e9&quot; 'é' &gt;&gt;&gt; 'é' 'é'  When Python prints string, here the print() is used in default in Python IDE. create PyObject. When the string is \\xe9 or \\u00e9, the Python interpret they as the code point of which 0xe9 is 233 in decimal. And convert it in PyUnicodeObject of which stores data use UCS-1 as 0xe9 is one byte. print the PyUnicodeObject. As the system locale uses UTF-8 Encoding, Python will convert UCS-1 data to utf-8 encoding bytes, which is b'\\xc3\\xa9'. &gt;&gt;&gt; 'é'.encode() b'\\xc3\\xa9' send bytes to the terminal emulator. b'\\xc3\\xa9' is sent to the terminal which uses the UTF-8 encoding. b'\\xc3\\xa9' in utf-8 is decode as code point \\u00e9 which represent the character é. draw character. The terminal emulator draw the glyph é on the screen as you see. If the terminal using latin-1, &quot;\\xe9&quot; will be show as Ã© in the terminal. "},{"title":"How to write raw bytes to the terminal from Python?​","type":1,"pageTitle":"Python Unicode String","url":"/blog/python-unicode-string#how-to-write-raw-bytes-to-the-terminal-from-python","content":"As you see above, Python print strings: firstly strings are encoded to utf-8 bytes.secondly these bytes are sent to the terminal. Sometimes, you may want to write raw bytes in the terminal directly to see how the terminal represents these bytes on the screen. ➜ ~ python3 -c 'import sys; sys.stdout.buffer.write(b&quot;\\xc3\\xa9&quot;)' é  UTF-8 terminal represent bytes b&quot;\\xc3\\xa9&quot; to character é. ➜ ~ python3 -c 'import sys; sys.stdout.buffer.write(b&quot;\\xe9&quot;)' �  UTF-8 terminal can not represent bytes b&quot;\\xe9&quot; to any known character, as b&quot;\\xe9&quot; is not a valid utf-8 encoding bytes. python - Python3 print raw byte - Stack Overflow "},{"title":"An outline of the PyUnicodeObject​","type":1,"pageTitle":"Python Unicode String","url":"/blog/python-unicode-string#an-outline-of-the-pyunicodeobject","content":"References are mainly from: ctypes — A foreign function library for Python — Python 3.12.1 documentationunicodeobject.hunicodeobject.c A brief PyUnicodeObject structure defined from unicodeobject.h: cpython/Include/cpython/unicodeobject.h typedef struct { Py_ssize_t ob_refcnt; PyTypeObject *ob_type; } PyObject /* --- Unicode Type ------------------------------------------------------- */ typedef struct { /* There are 4 forms of Unicode strings: - compact ascii: * structure = PyASCIIObject * test: PyUnicode_IS_COMPACT_ASCII(op) * kind = PyUnicode_1BYTE_KIND * compact = 1 * ascii = 1 * ready = 1 * (length is the length of the utf8 and wstr strings) * (data starts just after the structure) * (since ASCII is decoded from UTF-8, the utf8 string are the data) - compact: * structure = PyCompactUnicodeObject * test: PyUnicode_IS_COMPACT(op) &amp;&amp; !PyUnicode_IS_ASCII(op) * kind = PyUnicode_1BYTE_KIND, PyUnicode_2BYTE_KIND or PyUnicode_4BYTE_KIND * compact = 1 * ready = 1 * ascii = 0 * utf8 is not shared with data * utf8_length = 0 if utf8 is NULL * wstr is shared with data and wstr_length=length if kind=PyUnicode_2BYTE_KIND and sizeof(wchar_t)=2 or if kind=PyUnicode_4BYTE_KIND and sizeof(wchar_t)=4 * wstr_length = 0 if wstr is NULL * (data starts just after the structure) - legacy string, not ready: * structure = PyUnicodeObject * test: kind == PyUnicode_WCHAR_KIND * length = 0 (use wstr_length) * hash = -1 * kind = PyUnicode_WCHAR_KIND * compact = 0 * ascii = 0 * ready = 0 * interned = SSTATE_NOT_INTERNED * wstr is not NULL * data.any is NULL * utf8 is NULL * utf8_length = 0 - legacy string, ready: * structure = PyUnicodeObject structure * test: !PyUnicode_IS_COMPACT(op) &amp;&amp; kind != PyUnicode_WCHAR_KIND * kind = PyUnicode_1BYTE_KIND, PyUnicode_2BYTE_KIND or PyUnicode_4BYTE_KIND * compact = 0 * ready = 1 * data.any is not NULL * utf8 is shared and utf8_length = length with data.any if ascii = 1 * utf8_length = 0 if utf8 is NULL * wstr is shared with data.any and wstr_length = length if kind=PyUnicode_2BYTE_KIND and sizeof(wchar_t)=2 or if kind=PyUnicode_4BYTE_KIND and sizeof(wchar_4)=4 * wstr_length = 0 if wstr is NULL Compact strings use only one memory block (structure + characters), whereas legacy strings use one block for the structure and one block for characters. Legacy strings are created by PyUnicode_FromUnicode() and PyUnicode_FromStringAndSize(NULL, size) functions. They become ready when PyUnicode_READY() is called. See also _PyUnicode_CheckConsistency(). */ PyObject_HEAD Py_ssize_t length; /* Number of code points in the string */ Py_hash_t hash; /* Hash value; -1 if not set */ struct { /* SSTATE_NOT_INTERNED (0) SSTATE_INTERNED_MORTAL (1) SSTATE_INTERNED_IMMORTAL (2) If interned != SSTATE_NOT_INTERNED, the two references from the dictionary to this object are *not* counted in ob_refcnt. */ unsigned int interned:2; /* Character size: - PyUnicode_WCHAR_KIND (0): * character type = wchar_t (16 or 32 bits, depending on the platform) - PyUnicode_1BYTE_KIND (1): * character type = Py_UCS1 (8 bits, unsigned) * all characters are in the range U+0000-U+00FF (latin1) * if ascii is set, all characters are in the range U+0000-U+007F (ASCII), otherwise at least one character is in the range U+0080-U+00FF - PyUnicode_2BYTE_KIND (2): * character type = Py_UCS2 (16 bits, unsigned) * all characters are in the range U+0000-U+FFFF (BMP) * at least one character is in the range U+0100-U+FFFF - PyUnicode_4BYTE_KIND (4): * character type = Py_UCS4 (32 bits, unsigned) * all characters are in the range U+0000-U+10FFFF * at least one character is in the range U+10000-U+10FFFF */ unsigned int kind:3; /* Compact is with respect to the allocation scheme. Compact unicode objects only require one memory block while non-compact objects use one block for the PyUnicodeObject struct and another for its data buffer. */ unsigned int compact:1; /* The string only contains characters in the range U+0000-U+007F (ASCII) and the kind is PyUnicode_1BYTE_KIND. If ascii is set and compact is set, use the PyASCIIObject structure. */ unsigned int ascii:1; /* The ready flag indicates whether the object layout is initialized completely. This means that this is either a compact object, or the data pointer is filled out. The bit is redundant, and helps to minimize the test in PyUnicode_IS_READY(). */ unsigned int ready:1; /* Padding to ensure that PyUnicode_DATA() is always aligned to 4 bytes (see issue #19537 on m68k). */ unsigned int :24; } state; wchar_t *wstr; /* wchar_t representation (null-terminated) */ } PyASCIIObject; /* Non-ASCII strings allocated through PyUnicode_New use the PyCompactUnicodeObject structure. state.compact is set, and the data immediately follow the structure. */ typedef struct { PyASCIIObject _base; Py_ssize_t utf8_length; /* Number of bytes in utf8, excluding the * terminating \\0. */ char *utf8; /* UTF-8 representation (null-terminated) */ Py_ssize_t wstr_length; /* Number of code points in wstr, possible * surrogates count as two code points. */ } PyCompactUnicodeObject; /* Strings allocated through PyUnicode_FromUnicode(NULL, len) use the PyUnicodeObject structure. The actual string data is initially in the wstr block, and copied into the data block using _PyUnicode_Ready. */ typedef struct { PyCompactUnicodeObject _base; union { void *any; Py_UCS1 *latin1; Py_UCS2 *ucs2; Py_UCS4 *ucs4; } data; /* Canonical, smallest-form Unicode buffer */ } PyUnicodeObject;  As it's known that each Unicode character in string is represented by a Unicode code point. In PyUnicodeObject, these code points are the encoding saved in the data, so PyUnicodeObject does not use the UTF-8 encoding in the data. "},{"title":"How a Unicode string object is created?​","type":1,"pageTitle":"Python Unicode String","url":"/blog/python-unicode-string#how-a-unicode-string-object-is-created","content":"Invokes several internal C functions in such a sequence generally, PyObject *PyUnicode_FromStringAndSize(const char *str, Py_ssize_t size) PyObject *PyUnicode_DecodeUTF8Stateful(const char *str, Py_ssize_t size, const char *errors, Py_ssize_t *consumed) static PyObject *unicode_decode_utf8(const char *s, Py_ssize_t size, _Py_error_handler error_handler, const char *errors, Py_ssize_t *consumed) PyObject *PyUnicode_New(Py_ssize_t size, Py_UCS4 maxchar) static Py_ssize_t ascii_decode(const char *start, const char *end, Py_UCS1 *dest) ch = ucs2lib_utf8_decode(&amp;s, end, writer.data, &amp;writer.pos); // ucs2lib.h #define STRINGLIB(F) ucs2lib_##F STRINGLIB(utf8_decode)(const char **inptr, const char *end, STRINGLIB_CHAR *dest, Py_ssize_t *outpos)  "},{"title":"Inspect Unicode string object in Python 3​","type":1,"pageTitle":"Python Unicode String","url":"/blog/python-unicode-string#inspect-unicode-string-object-in-python-3","content":"Let's examine the internal data struct of a string object in modern Python 3. :::NOTE You keep the character being referred otherwise the GC may release that memory, Define the layout mapping unicodeobject, import ctypes # It's recommended to go to see [python 3.10 unicodeobject.h](https://github.com/python/cpython/blob/3.10/Include/cpython/unicodeobject.h#L85-L244) class PyASCIIObject(ctypes.Structure): # internal fields of the string object _fields_ = [ (&quot;ob_refcnt&quot;, ctypes.c_long), (&quot;ob_type&quot;, ctypes.c_void_p), (&quot;length&quot;, ctypes.c_ssize_t), (&quot;hash&quot;, ctypes.c_ssize_t), (&quot;interned&quot;, ctypes.c_uint, 2), (&quot;kind&quot;, ctypes.c_uint, 3), (&quot;compact&quot;, ctypes.c_uint, 1), (&quot;ascii&quot;, ctypes.c_uint, 1), (&quot;ready&quot;, ctypes.c_uint, 1), (&quot;_padding&quot;, ctypes.c_uint, 24), (&quot;wstr&quot;, ctypes.POINTER(ctypes.c_wchar)) ] def __repr__(self) -&gt; str: return f&quot;ob_refcnt[{self.ob_refcnt}], length[{self.length}], interned[{self.interned}], kind[{self.kind}], compact[{self.compact}], ascii[{self.ascii}], ready[{self.ready}]&quot; class PyCompactUnicodeObject(PyASCIIObject): # internal fields of the string object _fields_ = [ (&quot;utf8_length&quot;, ctypes.c_ssize_t), (&quot;utf8&quot;, ctypes.POINTER(ctypes.c_char)), (&quot;wstr_length&quot;, ctypes.c_ssize_t), ] def __repr__(self) -&gt; str: return super().__repr__() + f&quot; utf8_length[{self.utf8_length}], utf8[{self.utf8}], wstr_length[{self.wstr_length}]&quot; class PyUnicodeObject(PyCompactUnicodeObject): class _Data(ctypes.Union): _fields_ = [ (&quot;any&quot;, ctypes.c_void_p), (&quot;latin1&quot;, ctypes.POINTER(ctypes.c_uint8)), (&quot;ucs2&quot;, ctypes.POINTER(ctypes.c_uint16)), (&quot;ucs4&quot;, ctypes.POINTER(ctypes.c_uint32)), ] _fields_ = [ (&quot;data&quot;, _Data), ]  Type: compact ascii. Key fields: kind[1], compact[1], ascii[1], ready[1] &gt;&gt;&gt; string_obj = &quot;Hello, ctypes!&quot; &gt;&gt;&gt; addr = id(string_obj) &gt;&gt;&gt; ascii_obj = PyASCIIObject.from_address(addr) &gt;&gt;&gt; print(ascii_obj) ob_refcnt[1], length[14], interned[0], kind[1], compact[1], ascii[1], ready[1] &gt;&gt;&gt; &gt;&gt;&gt; # compact ascii: data starts just after the structure &gt;&gt;&gt; data_addr = addr + ctypes.sizeof(PyASCIIObject) &gt;&gt;&gt; data = ctypes.cast(data_addr, ctypes.c_char_p) &gt;&gt;&gt; print(f&quot;data: {data.value}&quot;) data: b'Hello, ctypes!'  Type: compact UCS-2. Key fields: kind[1], compact[1], ascii[1], ready[1] &gt;&gt;&gt; string_obj = &quot;你好!&quot; &gt;&gt;&gt; addr = id(string_obj) &gt;&gt;&gt; ascii_obj = PyASCIIObject.from_address(addr) &gt;&gt;&gt; print(ascii_obj) ob_refcnt[1], length[3], interned[0], kind[2], compact[1], ascii[0], ready[1] &gt;&gt;&gt; &gt;&gt;&gt; compact_obj = PyCompactUnicodeObject.from_address(addr) &gt;&gt;&gt; print(compact_obj) ob_refcnt[1], length[3], interned[0], kind[2], compact[1], ascii[0], ready[1] utf8_length[0], utf8[&lt;ctypes.LP_c_char object at 0x7f0c29297ac 0&gt;], wstr_length[0] &gt;&gt;&gt; &gt;&gt;&gt; # compact: data starts just after the structure &gt;&gt;&gt; data_addr = addr + ctypes.sizeof(PyCompactUnicodeObject) &gt;&gt;&gt; data = ctypes.cast(data_addr, ctypes.POINTER(ctypes.c_uint16)) &gt;&gt;&gt; print(f&quot;data: {data[0]}, {data[0]:#06x}, {chr(data[0])}&quot;) data: 20320, 0x4f60, 你 &gt;&gt;&gt; print(f&quot;data: {data[1]}, {data[1]:#06x}, {chr(data[1])}&quot;) data: 22909, 0x597d, 好 &gt;&gt;&gt; print(f&quot;data: {data[2]}, {data[2]:#06x}, {chr(data[2])}&quot;) data: 33, 0x0021, ! &gt;&gt;&gt; print(f&quot;data: {data[3]}, {data[3]:#06x}, {chr(data[3])}&quot;) data: 0, 0x0000,  Type: compact UCS-4. Key fields: kind[4], compact[1], ascii[1], ready[1] &gt;&gt;&gt; string_obj = &quot;你好🤨&quot; &gt;&gt;&gt; addr = id(string_obj) &gt;&gt;&gt; ascii_obj = PyASCIIObject.from_address(addr) &gt;&gt;&gt; print(ascii_obj) ob_refcnt[1], length[3], interned[0], kind[4], compact[1], ascii[0], ready[1] &gt;&gt;&gt; &gt;&gt;&gt; compact_obj = PyCompactUnicodeObject.from_address(addr) &gt;&gt;&gt; print(compact_obj) ob_refcnt[1], length[3], interned[0], kind[4], compact[1], ascii[0], ready[1] utf8_length[0], utf8[&lt;ctypes.LP_c_char object at 0x7f0c292b1ac 0&gt;], wstr_length[3] &gt;&gt;&gt; &gt;&gt;&gt; # compact: data starts just after the structure &gt;&gt;&gt; data_addr = addr + ctypes.sizeof(PyCompactUnicodeObject) &gt;&gt;&gt; data = ctypes.cast(data_addr, ctypes.POINTER(ctypes.c_uint32)) &gt;&gt;&gt; print(f&quot;data: {data[0]}, {data[0]:#010x}, {chr(data[0])}&quot;) data: 20320, 0x00004f60, 你 &gt;&gt;&gt; print(f&quot;data: {data[1]}, {data[1]:#010x}, {chr(data[1])}&quot;) data: 22909, 0x0000597d, 好 &gt;&gt;&gt; print(f&quot;data: {data[2]}, {data[2]:#010x}, {chr(data[2])}&quot;) data: 129320, 0x0001f928, 🤨 &gt;&gt;&gt; print(f&quot;data: {data[3]}, {data[3]:#010x}, {chr(data[3])}&quot;) data: 0, 0x00000000,  Type: legacy string. Key fields: kind[2], compact[0], ascii[0] I can't produce it in Python3.10, maybe you can try python2.7. All codes are at object layout "},{"title":"Resources​","type":1,"pageTitle":"Python Unicode String","url":"/blog/python-unicode-string#resources","content":"How Python saves memory when storing strings | Artem Golubin Python behind the scenes #9: how Python strings work https://nedbatchelder.com/text/unipain.html https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/ "},{"title":"Intel VROC RAID on Ubuntu","type":0,"sectionRef":"#","url":"/blog/raid-intel-vroc","content":"","keywords":"Setup Intel VROC RAID on Ubuntu"},{"title":"Background​","type":1,"pageTitle":"Intel VROC RAID on Ubuntu","url":"/blog/raid-intel-vroc#background","content":"On the premise machine, there are 2 NVMe SSDs and 8 SATA hard drives(HDDs), and also it ships with a in-box hardware-assisted RAID controller(Intel VROC) on the Intel CPU, which is supposed to keep overall advantages over software RAID. For me, I would like to use these 8 HDDs(sda, sdb, ..., sdh) to store data for long time, while retaining the balance between redundancy and performance. So here RAID 5(Stripping with Parity) comes into my mind. To leverage the power of Intel VROC in Ubuntu(Linux), you also need the mdadm command line tool to manage intel VROC which support RAID 0, RAID 1, RAID 5 and RAID 10 note In my understanding, the intel VROC register in system with the common interface with mdadm, so the mdadm software can operate it. And running command will show the mdadm is using intel VROC, $ sudo mdadm --detail-platform Platform : Intel(R) Virtual RAID on CPU Version : 8.0.3.1002 RAID Levels : raid0 raid1 raid10 raid5 Chunk Sizes : 4k 8k 16k 32k 64k 128k 2TB volumes : supported 2TB disks : supported Max Disks : 8 Max Volumes : 2 per array, 8 per controller I/O Controller : /sys/devices/pci0000:00/0000:00:17.0 (SATA) Port7 : /dev/sdh (ZR909K07) Port6 : /dev/sdg (ZV70BN24) Port3 : /dev/sdd (ZV70BD3T) Port4 : /dev/sde (ZR909Q89) Port1 : /dev/sdb (ZRT0S2FM) Port5 : /dev/sdf (ZR9099MM) Port2 : /dev/sdc (ZR909AGN) Port0 : /dev/sda (ZV70BMH9) Platform : Intel(R) Virtual RAID on CPU Version : 8.0.3.1002 RAID Levels : raid0 raid1 raid10 Chunk Sizes : 4k 8k 16k 32k 64k 128k 2TB volumes : supported 2TB disks : supported Max Disks : 96 Max Volumes : 2 per array, 24 per controller 3rd party NVMe : supported I/O Controller : /sys/devices/pci0000:8d/0000:8d:00.5 (VMD) NVMe under VMD : /dev/nvme0n1 (633FC084FCVK) NVMe under VMD : /dev/nvme1n1 (633FC0DEFCVK) I/O Controller : /sys/devices/pci0000:6f/0000:6f:00.5 (VMD) I/O Controller : /sys/devices/pci0000:51/0000:51:00.5 (VMD)  info Install Ubuntu Server on RAID: Ubuntu Server Image has inbox mdadm utilities and VMD drivers(which enable intel VROC functionalities), so it is quite convenient to create the RAID 1 on 2 SSDs either in BIOS stage(for intel VROC only) or in storage layer step during OS installation stage(software RAID), then install Ubuntu Server OS on the RAID 1. After creating the RAID 1 via intel VROC in BIOS, Ubuntu Server installation can detect the RAID created by VROC in step when set up the storage layer. If you skip BIOS to create RAID during OS installation, remember to add -e isms when using mdadm to create RAID(you can enter the terminal, do ``) otherwise the RAID is software based and does not apply VROC. Install Ubuntu Desktop on RAID: Ubuntu Desk Image does not ship the mdadm tool, so it is nearly impossible to create RAID and install Ubuntu Desktop OS on the RAID(however this one Install Ubuntu 20.04 desktop with RAID 1 and LVM on machine with UEFI BIOS from stackoverflow seems to be successful) "},{"title":"Set up RAID 5 array​","type":1,"pageTitle":"Intel VROC RAID on Ubuntu","url":"/blog/raid-intel-vroc#set-up-raid-5-array","content":"Here, I use 8 disks: /dev/sda, /dev/sdb, ..., /dev/sdh to create RAID 5 array and mount it for use in practice. "},{"title":"Create RAID array​","type":1,"pageTitle":"Intel VROC RAID on Ubuntu","url":"/blog/raid-intel-vroc#create-raid-array","content":"When creating RAID array, Intel VROC is different with software RAID array creation as an additional container is needed to create firstly. Inside the container, some information is labelled into the drives for Intel VROC controller to recognize them. Create RAID Container with Intel IMSM Metadata the total number of drives is 8 and -e imsm. sudo mdadm --create /dev/md/imsm0 /dev/sd[a-h] -n 8 -e imsm  Then, Create a RAID array in the /dev/md/imsm0 container using total 8 drives with RAID 5. sudo mdadm --create /dev/md/md0 /dev/md/imsm0 -l 0 -n 2  "},{"title":"Mount the RAID array for use​","type":1,"pageTitle":"Intel VROC RAID on Ubuntu","url":"/blog/raid-intel-vroc#mount-the-raid-array-for-use","content":"After you create the RAID array in above step, all partitions and data will be erased from all individual disks. The RAID array is treated as a logical drive now. Create a ext4 filesystem on the RAID array sudo mkfs.ext4 -F /dev/md/md0  Mount the RAID array sudo mkdir -p /mnt/md0 sudo mount /dev/md/md0 /mnt/md0  "},{"title":"Save RAID array configuration​","type":1,"pageTitle":"Intel VROC RAID on Ubuntu","url":"/blog/raid-intel-vroc#save-raid-array-configuration","content":"To make sure that the RAID array is reassembled and mounted automatically after reboot, we will have to add some necessary information into /etc/mdadm/mdadm.conf and /etc/fstab. Scan active array and append into /etc/mdadm/mdadm.conf file with following: sudo mdadm --detail --scan | sudo tee -a /etc/mdadm/mdadm.conf  Update initramfs, so the array will be available at early boot: sudo update-initramfs -u  Add mount options to /etc/fstab, you can use UUID=xxxx instead of the /dev/md0. echo '/dev/md0 /mnt/md0 ext4 defaults,nofail,discard 0 0' | sudo tee -a /etc/fstab  "},{"title":"Remove RAID Array​","type":1,"pageTitle":"Intel VROC RAID on Ubuntu","url":"/blog/raid-intel-vroc#remove-raid-array","content":""},{"title":"[Optional] Umount the array from filesystem​","type":1,"pageTitle":"Intel VROC RAID on Ubuntu","url":"/blog/raid-intel-vroc#optional-umount-the-array-from-filesystem","content":"Umount the array from filesystem if mounted, sudo umount /dev/md/md0  "},{"title":"Stop RAID container and array​","type":1,"pageTitle":"Intel VROC RAID on Ubuntu","url":"/blog/raid-intel-vroc#stop-raid-container-and-array","content":"# Stop RAID container sudo mdadm --stop /dev/md/imsm0 # Stop RAID array sudo mdadm --stop /dev/md/md0 # Stop all arrays and containers sudo mdadm --stop --scan  "},{"title":"Removes the RAID metadata​","type":1,"pageTitle":"Intel VROC RAID on Ubuntu","url":"/blog/raid-intel-vroc#removes-the-raid-metadata","content":"Removes the RAID metadata on each drive and resets the drive to normal sudo mdadm --zero-superblock /dev/sda sudo mdadm --zero-superblock /dev/sd[a-h]  "},{"title":"[Optional] Remove RAID configuration​","type":1,"pageTitle":"Intel VROC RAID on Ubuntu","url":"/blog/raid-intel-vroc#optional-remove-raid-configuration","content":"Remove mount information to the array if exist. Edit the /etc/fstab: /etc/fstab sudo nano /etc/fstab  Also, remove the array definition if exist, from the /etc/mdadm/mdadm.conf file: /etc/mdadm/mdadm.conf sudo nano /etc/mdadm/mdadm.conf  "},{"title":"Manage RAID Array with mdadm​","type":1,"pageTitle":"Intel VROC RAID on Ubuntu","url":"/blog/raid-intel-vroc#manage-raid-array-with-mdadm","content":""},{"title":"Find all RAID arrays​","type":1,"pageTitle":"Intel VROC RAID on Ubuntu","url":"/blog/raid-intel-vroc#find-all-raid-arrays","content":"$ cat /proc/mdstat Personalities : [raid1] [linear] [multipath] [raid0] [raid6] [raid5] [raid4] [raid10] md126 : active raid1 nvme0n1[1] nvme1n1[0] 3800741888 blocks super external:/md127/0 [2/2] [UU] md127 : inactive nvme0n1[1](S) nvme1n1[0](S) 10402 blocks super external:imsm unused devices: &lt;none&gt;  "},{"title":"Query information on a RAID array​","type":1,"pageTitle":"Intel VROC RAID on Ubuntu","url":"/blog/raid-intel-vroc#query-information-on-a-raid-array","content":"sudo mdadm --detail /dev/md0 sudo mdadm --query /dev/md0  "},{"title":"Query information on a physical disk drive​","type":1,"pageTitle":"Intel VROC RAID on Ubuntu","url":"/blog/raid-intel-vroc#query-information-on-a-physical-disk-drive","content":"sudo mdadm --query /dev/sda sudo mdadm --examine /dev/sda  "},{"title":"Stop a RAID array​","type":1,"pageTitle":"Intel VROC RAID on Ubuntu","url":"/blog/raid-intel-vroc#stop-a-raid-array","content":"sudo mdadm --stop /dev/md0 # Stop all arrays sudo mdadm --stop --scan  "},{"title":"Starting a RAID Array​","type":1,"pageTitle":"Intel VROC RAID on Ubuntu","url":"/blog/raid-intel-vroc#starting-a-raid-array","content":"# This works if the array is defined in the configuration `/etc/mdadm/mdadm.conf` file. sudo mdadm --assemble --scan sudo mdadm --assemble /dev/md0 # If the array is not persisted in `/etc/mdadm/mdadm.conf` file but keeping RAID metadata sudo mdadm --assemble /dev/md0 /dev/sda /dev/sdb  "},{"title":"Adding spare devices to a RAID Array​","type":1,"pageTitle":"Intel VROC RAID on Ubuntu","url":"/blog/raid-intel-vroc#adding-spare-devices-to-a-raid-array","content":"sudo mdadm /dev/md0 --add /dev/sde  $ lsblk -f NAME FSTYPE FSVER LABEL UUID FSAVAIL FSUSE% MOUNTPOINTS loop0 squashfs 4.0 0 100% /snap/core20/1974 loop1 squashfs 4.0 0 100% /snap/lxd/24322 loop2 squashfs 4.0 0 100% /snap/snapd/19457 sda isw_raid_member 1.3.00 sdb isw_raid_member 1.3.00 sdc isw_raid_member 1.3.00 sdd isw_raid_member 1.3.00 sde isw_raid_member 1.3.00 sdf isw_raid_member 1.3.00 sdg isw_raid_member 1.3.00 sdh isw_raid_member 1.3.00 nvme0n1 isw_raid_member 1.3.00 ├─md126 │ ├─md126p1 vfat FAT32 292B-DB66 1G 1% /boot/efi │ └─md126p2 ext4 1.0 0f58386c-334d-4877-8051-b855bae37fb0 3.3T 0% / └─md127 nvme1n1 isw_raid_member 1.3.00 ├─md126 │ ├─md126p1 vfat FAT32 292B-DB66 1G 1% /boot/efi │ └─md126p2 ext4 1.0 0f58386c-334d-4877-8051-b855bae37fb0 3.3T 0% / └─md127  sudo fdisk -l /dev/sda  "},{"title":"Delete partition and data in disk​","type":1,"pageTitle":"Intel VROC RAID on Ubuntu","url":"/blog/raid-intel-vroc#delete-partition-and-data-in-disk","content":"sudo dd if=/dev/zero of=/dev/sda bs=512 count=1  "},{"title":"Resumable Upload","type":0,"sectionRef":"#","url":"/blog/resumable-upload","content":"","keywords":"file upload resumable"},{"title":"A Basic Resumable Upload​","type":1,"pageTitle":"Resumable Upload","url":"/blog/resumable-upload#a-basic-resumable-upload","content":"app_resumable_upload.py loading... See full example on GitHub "},{"title":"TUS Resumable Upload​","type":1,"pageTitle":"Resumable Upload","url":"/blog/resumable-upload#tus-resumable-upload","content":"FastAPI implementing tus v1.0.0 server in Python app_tusd.py loading... See full example on GitHub Implementations | tus.io Resumable file upload GitHub - tus/tus-js-client: A pure JavaScript client for the tus resumable upload protocol GitHub - tus/tusd: Reference server implementation in Go of tus: the open protocol for resumable file uploads IO, StreamIO, FileIO high-level used by asyncio.io in socket/tcp/http Streams — Python 3.11.4 documentation starlette.Request.stream = http Request Body low-level: io — Core tools for working with streams — Python 3.11.4 documentation "},{"title":"RAID on Ubuntu","type":0,"sectionRef":"#","url":"/blog/raid-on-ubuntu","content":"","keywords":"Setup Intel VROC RAID on Ubuntu"},{"title":"Background​","type":1,"pageTitle":"RAID on Ubuntu","url":"/blog/raid-on-ubuntu#background","content":"Recently, there is a chance for me to install Ubuntu(server) OS on a Dell Precision xxx workstation which is includes 2 NVMe SSDs and 8 SATA hard drives(HDDs) and has in-box hardware-assisted RAID controller(Intel VROC). In the past, I just play cloud virtual machines or personal host with single disk. Configuring storage is a critical part of setting up a reliable workstation. So firstly, how to organize these following disks to their roles? 2 SSDs hold the system to load quickly8 HDDs store data persistently In order to access these physical disks easily and reduce damages from data loss, I need to combine multiple disks to act as one, while keep data redundant and backup. After step-by-step research, there are some enterprise solutions present for me. These drive layer or file system layer approaches designed for specific purposes have their own advantages over others while they maybe achieve some same features. Here are some benefits and shortcomings of them alongside common use cases: RAID(Redundant Array of Independent Disks) Abstraction level: drive layer Concept: RAID uses multiple drives to act as one(logical drive). Benefits: improve data redundancy and data read/write performance LVM(Logical Volume Management) Abstraction level: file system layer Concept: Manage a logical volume over multiple drives, each drive is a Physical Volume(PV). Benefits: combine multiple disks into one logical volume, extend the volume with new disk added, increase/decrease mounted folder in file system ZFS(Z File System) There are three types of raid, as Wiki saying: hardware RAIDsoftware RAID mdadm in Linux hardware-assisted software RAID, firmware RAID, fake RAID Intel VROC (Virtual RAID on CPU) This document will introduce how to set up software RAID(RAID0, RAID1, RAID5, RAID 10) on already-installed Ubuntu. To create a RAID to hold the Ubuntu OS when installing Ubuntu, see SoftwareRAID or How to install Ubuntu with software RAID-1 In addition, there are different challenges you will face when installing Ubuntu Server and Ubuntu Desktop. Install Ubuntu Server on RAID: Ubuntu Server Image has inbox mdadm utilities, so it is quite convenient to create the software RAID on multiple disks then install Ubuntu Server OS on the RAID in storage layer step during OS installation stage.  Install Ubuntu Desktop on RAID: Ubuntu Desk Image does not ship the mdadm tool, so it is nearly impossible to create RAID and install Ubuntu Desktop OS on the RAID(however this one Install Ubuntu 20.04 desktop with RAID 1 and LVM on machine with UEFI BIOS from stackoverflow seems to be successful) "},{"title":"Set up RAID array​","type":1,"pageTitle":"RAID on Ubuntu","url":"/blog/raid-on-ubuntu#set-up-raid-array","content":"To create a RAID array ready to use in practice, there are always common steps: Create a RAID array(RAID 0, RAID 1, RAID 5 or RAID 10)Mount the RAID arraySave the RAID array configuration for system boot "},{"title":"Create RAID array with mdadm​","type":1,"pageTitle":"RAID on Ubuntu","url":"/blog/raid-on-ubuntu#create-raid-array-with-mdadm","content":"Create RAID 0 array using devices: /dev/sda and /dev/sdb sudo mdadm --create --verbose /dev/md0 -l 0 -n 2 /dev/sda /dev/sdb  "},{"title":"Mount RAID array for use​","type":1,"pageTitle":"RAID on Ubuntu","url":"/blog/raid-on-ubuntu#mount-raid-array-for-use","content":"Create a ext4 filesystem on the array sudo mkfs.ext4 -F /dev/md0  Mount the array sudo mkdir -p /mnt/md0 sudo mount /dev/md0 /mnt/md0  "},{"title":"Save RAID array configuration​","type":1,"pageTitle":"RAID on Ubuntu","url":"/blog/raid-on-ubuntu#save-raid-array-configuration","content":"Persist the RAID array configuration to make the system reassemble and mount the RAID array automatically after reboot. Append the line to /etc/mdadm/mdadm.conf: sudo mdadm --detail --scan | sudo tee -a /etc/mdadm/mdadm.conf  Make RAID array available in early boot stage: sudo update-initramfs -u  Persist the mount point, edit /etc/fstab: /etc/fstab /dev/md0 /mnt/md0 ext4 defaults,nofail,discard 0 0  or persist the mount point by using UUID, get UUID of the disk drive, $ blkid /dev/md124 /dev/md124: UUID=&quot;b7fa44f2-0f05-47a1-b4ef-e9ad306898de&quot; BLOCK_SIZE=&quot;4096&quot; TYPE=&quot;ext4&quot;  then edit in /etc/fstab, /etc/fstab UUID=b7fa44f2-0f05-47a1-b4ef-e9ad306898de /volume ext4 defaults,nofail,discard 0 0  finally apply the new mount, sudo mount -a  "},{"title":"Delete RAID Array with mdadm​","type":1,"pageTitle":"RAID on Ubuntu","url":"/blog/raid-on-ubuntu#delete-raid-array-with-mdadm","content":"Make sure to remove what are using the RAID array, [Optional] Umount the array from filesystem if mounted, sudo umount /dev/md0  Stop RAID array, sudo mdadm --stop /dev/md0 # Stop all arrays sudo mdadm --stop --scan  Removes the RAID metadata and resets them to normal on the Drives, sudo mdadm --zero-superblock /dev/sda sudo mdadm --zero-superblock /dev/sd[a-h]  [Optional] Remove any persistent references to the array if exist. Edit the /etc/fstab: /etc/fstab sudo nano /etc/fstab  [Optional] Also, remove the array definition if exist, from the /etc/mdadm/mdadm.conf file: /etc/mdadm/mdadm.conf sudo nano /etc/mdadm/mdadm.conf  "},{"title":"Manage RAID Array with mdadm​","type":1,"pageTitle":"RAID on Ubuntu","url":"/blog/raid-on-ubuntu#manage-raid-array-with-mdadm","content":""},{"title":"Find the RAID arrays​","type":1,"pageTitle":"RAID on Ubuntu","url":"/blog/raid-on-ubuntu#find-the-raid-arrays","content":"$ cat /proc/mdstat Personalities : [raid1] [linear] [multipath] [raid0] [raid6] [raid5] [raid4] [raid10] md126 : active raid1 nvme0n1[1] nvme1n1[0] 3800741888 blocks super external:/md127/0 [2/2] [UU] md127 : inactive nvme0n1[1](S) nvme1n1[0](S) 10402 blocks super external:imsm unused devices: &lt;none&gt;  "},{"title":"Query information on RAID array​","type":1,"pageTitle":"RAID on Ubuntu","url":"/blog/raid-on-ubuntu#query-information-on-raid-array","content":"sudo mdadm --detail /dev/md0 sudo mdadm --query /dev/md0  "},{"title":"Query information on individual physical devices​","type":1,"pageTitle":"RAID on Ubuntu","url":"/blog/raid-on-ubuntu#query-information-on-individual-physical-devices","content":"sudo mdadm --query /dev/sda sudo mdadm --examine /dev/sda  "},{"title":"Stop RAID array​","type":1,"pageTitle":"RAID on Ubuntu","url":"/blog/raid-on-ubuntu#stop-raid-array","content":"sudo mdadm --stop /dev/md0 # Stop all arrays sudo mdadm --stop --scan  "},{"title":"Start an RAID array​","type":1,"pageTitle":"RAID on Ubuntu","url":"/blog/raid-on-ubuntu#start-an-raid-array","content":"# This works if the array is defined in the configuration `/etc/mdadm/mdadm.conf` file. sudo mdadm --assemble --scan sudo mdadm --assemble /dev/md0 # If the array is not persisted in `/etc/mdadm/mdadm.conf` file but keeping RAID metadata sudo mdadm --assemble /dev/md0 /dev/sda /dev/sdb  "},{"title":"Add a spare device to an RAID array​","type":1,"pageTitle":"RAID on Ubuntu","url":"/blog/raid-on-ubuntu#add-a-spare-device-to-an-raid-array","content":"sudo mdadm /dev/md0 --add /dev/sde  "},{"title":"Check block devices​","type":1,"pageTitle":"RAID on Ubuntu","url":"/blog/raid-on-ubuntu#check-block-devices","content":"$ lsblk -f NAME FSTYPE FSVER LABEL UUID FSAVAIL FSUSE% MOUNTPOINTS loop0 squashfs 4.0 0 100% /snap/core20/1974 loop1 squashfs 4.0 0 100% /snap/lxd/24322 loop2 squashfs 4.0 0 100% /snap/snapd/19457 sda isw_raid_member 1.3.00 sdb isw_raid_member 1.3.00 sdc isw_raid_member 1.3.00 sdd isw_raid_member 1.3.00 sde isw_raid_member 1.3.00 sdf isw_raid_member 1.3.00 sdg isw_raid_member 1.3.00 sdh isw_raid_member 1.3.00 nvme0n1 isw_raid_member 1.3.00 ├─md126 │ ├─md126p1 vfat FAT32 292B-DB66 1G 1% /boot/efi │ └─md126p2 ext4 1.0 0f58386c-334d-4877-8051-b855bae37fb0 3.3T 0% / └─md127 nvme1n1 isw_raid_member 1.3.00 ├─md126 │ ├─md126p1 vfat FAT32 292B-DB66 1G 1% /boot/efi │ └─md126p2 ext4 1.0 0f58386c-334d-4877-8051-b855bae37fb0 3.3T 0% / └─md127  "},{"title":"List UUID of devices​","type":1,"pageTitle":"RAID on Ubuntu","url":"/blog/raid-on-ubuntu#list-uuid-of-devices","content":"$ sudo blkid /dev/sdf: TYPE=&quot;isw_raid_member&quot; /dev/nvme0n1: TYPE=&quot;isw_raid_member&quot; /dev/sdd: TYPE=&quot;isw_raid_member&quot; /dev/sdb: TYPE=&quot;isw_raid_member&quot; /dev/sdg: TYPE=&quot;isw_raid_member&quot; /dev/sde: TYPE=&quot;isw_raid_member&quot; /dev/sdc: TYPE=&quot;isw_raid_member&quot; /dev/md126p2: UUID=&quot;ff1f3640-e590-486b-8570-c34dfd7bd1de&quot; BLOCK_SIZE=&quot;4096&quot; TYPE=&quot;ext4&quot; PARTUUID=&quot;07473e4a-9324-435d-9238-cf358cd9a6a9&quot; /dev/md126p1: UUID=&quot;A636-3441&quot; BLOCK_SIZE=&quot;512&quot; TYPE=&quot;vfat&quot; PARTUUID=&quot;7eb27871-d9ad-4132-af06-7110948faf06&quot; /dev/nvme1n1: TYPE=&quot;isw_raid_member&quot; /dev/sda: TYPE=&quot;isw_raid_member&quot; /dev/md124: UUID=&quot;b7fa44f2-0f05-47a1-b4ef-e9ad306898de&quot; BLOCK_SIZE=&quot;4096&quot; TYPE=&quot;ext4&quot; /dev/sdh: TYPE=&quot;isw_raid_member&quot; /dev/loop1: TYPE=&quot;squashfs&quot; /dev/loop4: TYPE=&quot;squashfs&quot; /dev/loop2: TYPE=&quot;squashfs&quot; /dev/loop0: TYPE=&quot;squashfs&quot; /dev/loop3: TYPE=&quot;squashfs&quot;  "},{"title":"Partition a disk​","type":1,"pageTitle":"RAID on Ubuntu","url":"/blog/raid-on-ubuntu#partition-a-disk","content":"sudo fdisk -l /dev/sda  "},{"title":"Create filesystem on disk​","type":1,"pageTitle":"RAID on Ubuntu","url":"/blog/raid-on-ubuntu#create-filesystem-on-disk","content":"sudo mkfs.ext4 -F /dev/sda  "},{"title":"Delete partition and data in disk​","type":1,"pageTitle":"RAID on Ubuntu","url":"/blog/raid-on-ubuntu#delete-partition-and-data-in-disk","content":"sudo dd if=/dev/zero of=/dev/sda bs=512 count=1  "},{"title":"RPC vs MQ","type":0,"sectionRef":"#","url":"/blog/rpc_vs_mq","content":"","keywords":""},{"title":"RPC​","type":1,"pageTitle":"RPC vs MQ","url":"/blog/rpc_vs_mq#rpc","content":""},{"title":"IPC​","type":1,"pageTitle":"RPC vs MQ","url":"/blog/rpc_vs_mq#ipc","content":"IPC: (local)Inter-Process Communication Using gRPC for (local) inter-process communication IPC Benchmark "},{"title":"MQ​","type":1,"pageTitle":"RPC vs MQ","url":"/blog/rpc_vs_mq#mq","content":""},{"title":"Serialization","type":0,"sectionRef":"#","url":"/blog/serialization","content":"","keywords":"MessagePack msgpack json serialization Protocol Buffers Protobuf"},{"title":"Json​","type":1,"pageTitle":"Serialization","url":"/blog/serialization#json","content":""},{"title":"MessagePack​","type":1,"pageTitle":"Serialization","url":"/blog/serialization#messagepack","content":"msgpack GitHub "},{"title":"Protocol Buffers​","type":1,"pageTitle":"Serialization","url":"/blog/serialization#protocol-buffers","content":"Protocol Buffers "},{"title":"Supported Features​","type":1,"pageTitle":"Serialization","url":"/blog/serialization#supported-features","content":"Protocol\tDiscriminator Property &amp; PolymorphismJson\t✔️ MessagePack\t✔️ Protobuf\t✖️ "},{"title":"Learn ASGI","type":0,"sectionRef":"#","url":"/blog/wiki-asgi","content":"Nowadays as web server framework is getting easy to use and work with. In Python areas, FastAPI obtains nearly 60k stars and becomes the most popular web framework for Pythoners. Looking at the advantage of FastAPI, it simplifies everything from parsing http requests, middleware processing, authentication, database manipulation and more. Let's dive into the behind-the-scenes technique stacks of FastAPI. Before research, there are some common questions around the web server development: How to process messages on HTTP protocol on TCP protocol? What're the favorite library used to do that?What are the differences between WSGI and ASGI?Data model used for database and users stacks from low-level to high-level Uvicorn: ASGI web server implementation/interface scopereceivesend h11 to process HTTP messageswebsocket to process websocket messages Starlette: ASGI frameworkabstract Request class for receive in Uvicornabstract Response class for send in Uvicornprovide middleware FastAPI: Fast to codeOpenAPI docsPydantic native model APIRoute APIRouter Application &lt;-- APIRouter &lt;-- APIRoute","keywords":"Learn ASGI"},{"title":"WiFi AutoSwitch Windows","type":0,"sectionRef":"#","url":"/blog/wifi-autoswitch-windows","content":"If autoSwitch is turned on, it allows Windows to continue looking for other auto-connected wireless networks while connected to the current wireless network. If a higher priority auto-connected wireless network than the currently connected wireless network comes in range, Windows will automatically connect to it instead. It also needs to work along with priority setting. For example: There're 3 networks of profile name: TP-Link-1, TP-Link-2 and TP-Link-3. PC(windows) will try to connect TP-Link-3 if it's in range when it's already connected to TP-Link-1 or TP-Link-2. Setup autoswitch: netsh wlan set profileparameter name=&quot;TP-Link-1&quot; autoswitch=Yes netsh wlan set profileparameter name=&quot;TP-Link-2&quot; autoswitch=Yes netsh wlan set profileparameter name=&quot;TP-Link-3&quot; autoswitch=No Setup priority: netsh wlan set profileorder name=&quot;TP-Link-1&quot; interface=&quot;Wi-Fi&quot; priority=3 netsh wlan set profileorder name=&quot;TP-Link-2&quot; interface=&quot;Wi-Fi&quot; priority=2 netsh wlan set profileorder name=&quot;TP-Link-3&quot; interface=&quot;Wi-Fi&quot; priority=1 other tools: List profile name: netsh wlan show profiles List connected WiFi: netsh wlan show interfaces Enable Auto Switch for Wireless Network Connection in Windows 10 Change WiFi network priority in Windows 10","keywords":"autoswitch wifi windows"},{"title":"Wiki Avalonia","type":0,"sectionRef":"#","url":"/blog/wiki-avalonia","content":"","keywords":"practice avalonia"},{"title":"SkiaSharp​","type":1,"pageTitle":"Wiki Avalonia","url":"/blog/wiki-avalonia#skiasharp","content":"SkiaSharp/GRContextTest.cs at main · mono/SkiaSharp · GitHub "},{"title":"Wiki Coral","type":0,"sectionRef":"#","url":"/blog/wiki-coral","content":"","keywords":"wiki coral mendel"},{"title":"Resources​","type":1,"pageTitle":"Wiki Coral","url":"/blog/wiki-coral#resources","content":"Get started with the Dev Board | CoralCoralClose "},{"title":"Background​","type":1,"pageTitle":"Wiki Coral","url":"/blog/wiki-coral#background","content":"The official documents Get started with the Dev Board contains comprehensive how-to contents and rich examples. Here are just some experiences from myself. You can always go back to the official website to review and get the details. The recommended method to access the Coral board is using Mendel Development Tool (mdt), which is required to be installed on your host machine alongside the Python. Common steps to enter the shell terminal from mdt are in following: mdt tool generate a pair of SSH keys, save the private key on the host and push the public key to the Coral using http via 41337 port.Coral board has a running a mdt-keymaster server that is listening 41337 port, and put the public key into ~/.ssh/authorized_keys.mdt shell now can login to the shell terminal of Coral board like ssh mendel@192.168.100.2 when connecting over USB-C(OTG) or ssh mendel@indigo-quill.local over the same network where your host PC is. info Coral board is set up by disabling password login in OpenSSH in default, so it must be provided with SSH key otherwise you change the setting to be like PasswordAuthentication yes. note You can check the key master by, mendel@indigo-quill:~$ lsof -i:41337 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME mdt-keyma 7846 mendel 5u IPv4 20302 0t0 TCP 192.168.100.2:41337 (LISTEN) mdt-keyma 7847 mendel 6u IPv4 20619 0t0 TCP 192.168.101.2:41337 (LISTEN)  Although mdt maybe facilitate the access to the Coral board, some magics and additional steps are kept from sight. To do not use mdt, we need access the dev board through serial console instead of mdt keymaster server, to make configuration. There are general ways to access a just-setup Coral in brief steps: Connect to Coral board's serial console by the instructions Connect to the Dev Board's serial consoleLog into the Dev board by username: mendel and password: mendel in default.Enable SSH Password Authentication. Edit /etc/ssh/sshd_config to change PasswordAuthentication no to PasswordAuthentication yes, and sudo service ssh restart to restart the ssh service.Log into the shell using username: mendel and password: mendel.If you want to keep the secure shell, generate private SSH key stored in host and public SSH key saved into Coral. "},{"title":"Wiki Assembly","type":0,"sectionRef":"#","url":"/blog/wiki-assembly","content":"","keywords":"Wiki Assembly"},{"title":"Assembler​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#assembler","content":"GNU assembler (GAS) x86-64 GNU assembler AT&amp;T syntax aarch64 GNU assembler aarch64/arm64 syntax Clang Assembler external Assembler GNU Assembler LLVM’s integrated assembler Netwide assembler (NASM) Intel syntaxx86-64 macOSlinuxwindows MASM Intel syntax "},{"title":"XXX​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#xxx","content":"print.asm ; print.asm ; nasm -f elf64 print.asm &amp;&amp; ld print.o &amp;&amp; ./a.out ; echo $? ; objdump -d a.out section .data message db, &quot;Welcome, to, Segmentation, Faults!, &quot; section .text global _start _printMessage: mov rax, 4 ; System call number for sys_write mov rbx, 1 ; File descriptor 1 is stdout mov rcx, message ; Pointer to the message string mov rdx, 32 ; Length of the message int 0x80 ; Call kernel ret ; Return from the function _exit: mov rax, 1 ; System call number for sys_exit mov rbx, 0 ; Exit code 0 int 0x80 ; Call kernel _start: call _printMessage ; Call the print message function mov rax, 1 ; System call number for sys_exit mov rbx, 1 ; Exit code 0 int 0x80 ; Call kernel  sum.asm ; sum.asm ; nasm -f elf64 sum.asm &amp;&amp; ld sum.o &amp;&amp; ./a.out ; echo $? ; objdump -d a.out section .text global _start ; Function to calculate the sum of two integers sum: mov rax, rdi ; Move the first argument (a) to rax add rax, rsi ; Add the second argument (b) to rax ret ; Return with the result in rax _start: ; Example usage of the sum function mov rdi, 5 ; First argument: a = 5 mov rsi, 7 ; Second argument: b = 7 call sum ; Call the sum function ; The result is now in rax ; It can be used or printed, depending on the context mov rdi, rax ; Exit code 0 ; Exit the program mov rax, 60 ; System call number for sys_exit syscall ; Make the system call  "},{"title":"Memory Layout​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#memory-layout","content":"The structure of an assembly file generally consists of serval section: .text section: .text section is generally read-only. It is typically used for storing executable code, and it is not intended to be modified during program execution..text section contains the machine code instructions that the processor will execute..text section contains global constant data. .data section: .data section is writable. It is used for storing initialized data that can be modified during the execution of the program..data section contains global variable data. .bss section: It's mostly the same with .data section except it's used for storing uninitialized data .rodata section: It is used for read-only data, such as constant strings. Here's a simple example illustrating the use of these sections: .section .text .global _start _start: // Code goes here .section .data my_data: .word 42 // Initialized data .section .bss my_uninitialized_data: .skip 4 // Uninitialized data, occupies 4 bytes .section .rodata my_string: .asciz &quot;Hello, World!&quot; // Read-only data  A compiled program's memory layout consists of these segments. A running program's memory layout consists of these segments, and also heap and stack memory. "},{"title":"Memory Layout of a Running Program​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#memory-layout-of-a-running-program","content":"A running program typically consists of serval segments or sections, each serving a specific purpose but common sections include: Stack: Stores local variables and function call information.Memory is automatically allocated and de-allocated as functions are called and return.Register(sp in arm64, stack pointer) is used to manage and point to the stack memory.Size is limited(may lead to stack overflow). set via ulimit -s in linux. Heap: Dynamic memory managed by programmer at runtime.Memory is allocated and deallocated explicitly using functions like malloc/free in C, and new/delete in C++, brk system call in assembly etc.Store dynamic data that can be shared across functions. Data lifecycle is not bound to functions.Size is much larger than the stack, Data(.data, .bss): Stores global variables/constants, separated into initialized and uninitialized Text(.text): Stores the code being executed CS 225 | Stack and Heap Memory "},{"title":"Label​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#label","content":""},{"title":"Instruction​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#instruction","content":"Assembly instructions are human readable representation of the machine code as CPU can only understand the machine code. Instruction: Opcode + Oprand "},{"title":"Opcode​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#opcode","content":"Intel x86 Assembler Instruction Set Opcode Table "},{"title":"Oprand​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#oprand","content":"Data area Register Operand​ mov rdi, rsi  Immediate Operand​ mov rdi, 0x21 mov rdi, 5 mov edi, 0x21314151  in aarch64, the immediate value is subject to: Arithmetic instructions (add{s}, sub{s}, cmp, cmn) take a 12-bit unsigned immediate with an optional 12-bit left shift.Move instructions (movz, movn, movk) take a 16-bit immediate optionally shifted to any 16-bit-aligned position within the register.Address calculations (adr, adrp) take a 21-bit signed immediate, although there's no actual syntax to specify it directly - to do so you'd have to resort to assembler expression trickery to generate an appropriate &quot;label&quot;.Logical instructions (and{s}, orr, eor, tst) take a &quot;bitmask immediate&quot;. Memory Operand​ mov rdi, [sdi]  "},{"title":"Instruction Encoding​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#instruction-encoding","content":"Assembler will encode the human-readable instruction into machine code. In aarch64, the encoding instruction is fixed-size(4 bytes) machine code.In x86_64, the encoding instruction is non-fixed-size(up to 16 bytes) machine code. Encoding Real x86 Instructions Let's have a glimpse on the impact of the fixed/non-fixed encoding. In order to load 32-bit integer, x86_64 need only one instruction while more instructions are needed for aarch64 to do that. Load a 32-bit integer 0x1a2b3c4d in x86_64, mov rid, 0x1a2b3c4d  Load a 32-bit integer 32-bit 0x1a2b3c4d in aarch64(the immediate value in mov must be in the range of 16-bit, so it needs two instructions), movz x1, 0x3c4d movk x1, 0x1a2b, lsl 16  "},{"title":"NASM x86_64 cheat sheet​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#nasm-x86_64-cheat-sheet","content":""},{"title":"GAS aarch64 cheat sheet​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#gas-aarch64-cheat-sheet","content":""},{"title":"Bootstrap a compiler for new language​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#bootstrap-a-compiler-for-new-language","content":"New programming language and its corresponding compiler is mainly developed from an existing language. The progress is called bootstrapping, which can be summarized as, C1 + L1 -&gt; C20 C20 + L2u -&gt; C21 C21 + L2 -&gt; C22 C22 + L2 -&gt; C23 C23 + L2 -&gt; C24  L1 : an existing languageC1 : an existing compiler for language L1C20: a compiler written in language L1 for language L2uC21: a compiler written in language L2u for language L2L2u: is subset of language L2 Bootstrapping stage: Write a bootstrap compiler C20 to understand language L2u(a subset of language L2) in using existed language L1 and its corresponding compiler C1.Use the compiler C20 and language L2u to write the compiler C21 to understand language L2.Now C21 is a fully self-hosted compiler, as well as its descendants C22, C23, and C24. "},{"title":"Where did the existing compiler C1 come from?​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#where-did-the-existing-compiler-c1-come-from","content":"There is no need to use a compiler C1 + L1 if you write the bootstrap compiler C20 in machine code. This solves the chicken-and-egg problem totally for programming languages. Bootstrapping initial compiler C20: A small and simple compiler is created manually in machine code or written in assembly language.[Option*] Translate the assembly language into machine code manually if it's not written in machine code.The initial compiler is just capable enough to understand a subset of the target language C it is supposed to compile. Use the initial compiler C20 to compile the compiler C21 written in language C while the C21 is also supposed to compile language C.Now compiler C21 a fully self-compilation. Strange Loops: Ken Thompson and the Self-referencing C Compiler | ScienceBlogs Bootstrapping (compilers) - Wikipedia Compilers: Principles, Techniques, and Tools - Wikipedia "},{"title":"Compiler's job overview​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#compilers-job-overview","content":"lexer(Lexical analysis) generate tokens from source code parser construct abstract syntax tree(AST) from tokens code generation generate low-level code, such as assembly code or machine code "},{"title":"Interpreter vs compiler​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#interpreter-vs-compiler","content":"an interpreter also does lexer and parser jobs as a compiler does in step 1 and 2, but instead of generating low-level code, the interpreter generates the results. "},{"title":"Implementations​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#implementations","content":"Interpreter: GitHub - rswier/c4: C in four functionsGitHub - lotabout/write-a-C-interpreter: Write a simple interpreter of C. Inspired by c4 and largely based on it. Self-hosted Compiler: GitHub - DoctorWkt/acwj: A Compiler Writing JourneyGitHub - certik/bcompile: Bootstrapping a simple compiler from nothing The basic knowledge of lexer and parser is critical and necessary for developing a programming language, flex/lexyacc/parser "},{"title":"Compiler for a subset of C language bootstrapping from Python​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#compiler-for-a-subset-of-c-language-bootstrapping-from-python","content":"Recently, I am becoming interested in building a lexer, parser and code generator to try to create a mini language and deep insight of how GCC or Clang/LLVM do their jobs. For educational purposes, learning in practice is my favorite approach to grasp an overview. Let's do it! Prerequisites: Python for writing the bootstrap compiler  I use ply, a pure Python implementation of the lex and yacc tools to facilitate me to write the bootstrap compiler for the subset of C language. "},{"title":"Compiler for a subset of C language bootstrapping from C​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#compiler-for-a-subset-of-c-language-bootstrapping-from-c","content":"Prerequisites: An existing GCC for writing the bootstrap compiler Here are some popular tutorials from GitHub - DoctorWkt/acwj: A Compiler Writing Journey. You can also refer GitHub - lotabout/write-a-C-interpreter although I prefer classifying it as interpreter not a complete compiler. "},{"title":"Compiler bootstrapping from assembly​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#compiler-bootstrapping-from-assembly","content":""},{"title":"Compiler bootstrapping from HEX​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#compiler-bootstrapping-from-hex","content":"GitHub - certik/bcompile: Bootstrapping a simple compiler from nothing "},{"title":"Resources​","type":1,"pageTitle":"Wiki Assembly","url":"/blog/wiki-assembly#resources","content":"https://gist.github.com/mikesmullin/6259449 https://cs.lmu.edu/~ray/notes/nasmtasutorial/ https://cs.brown.edu/courses/cs033/docs/guides/x64_cheatsheet.pdf http://6.s081.scripts.mit.edu/sp18/x86-64-architecture-guide.html https://cs61.seas.harvard.edu/site/2018/Asm1/ https://web.stanford.edu/class/cs107/guide/x86-64.html https://www.cs.virginia.edu/~evans/cs216/guides/x86.html https://www.cs.uaf.edu/2016/fall/cs301/lecture/09_28_machinecode.html https://p403n1x87.github.io/getting-started-with-x86-64-assembly-on-linux.html https://flint.cs.yale.edu/cs421/papers/x86-asm/asm.html https://nickdesaulniers.github.io/blog/2014/04/18/lets-write-some-x86-64/ https://pacman128.github.io/static/pcasm-book.pdf https://redirect.cs.umbc.edu/portal/help/nasm/sample_64.shtml "},{"title":"Wiki Cross Compilation","type":0,"sectionRef":"#","url":"/blog/wiki-cross-compilation","content":"","keywords":"Wiki Cross Compilation"},{"title":"Cross Compilation Anatomy​","type":1,"pageTitle":"Wiki Cross Compilation","url":"/blog/wiki-cross-compilation#cross-compilation-anatomy","content":"Cross-Compilation ecosystem involves the following components: host system cross-Compilation toolchain cross compilercross linkercross debuggersysroot target system library filestarget system header filestarget system other files target system Cross-Compilation toolchain: GCCBuildrootYocto ProjectCrosstool-NGLinaroClang/LLVM "},{"title":"GCC​","type":1,"pageTitle":"Wiki Cross Compilation","url":"/blog/wiki-cross-compilation#gcc","content":"Let's explore what a toolchain is like and what are needed to build something for a aarch64 platform on x86_64 debian-like host. "},{"title":"Obtaining a cross-compilation toolchain for aarch64​","type":1,"pageTitle":"Wiki Cross Compilation","url":"/blog/wiki-cross-compilation#obtaining-a-cross-compilation-toolchain-for-aarch64","content":"For simplicity and in a super fast way, we will use a prebuilt and ready-on toolchain in x86_64 Ubuntu. apt install gcc make gcc-aarch64-linux-gnu binutils-aarch64-linux-gnu  "},{"title":"Where is cross compiler​","type":1,"pageTitle":"Wiki Cross Compilation","url":"/blog/wiki-cross-compilation#where-is-cross-compiler","content":"We see cross compiler binary type in host is x86-64, $ file /usr/bin/aarch64-linux-gnu-gcc-11 /usr/bin/aarch64-linux-gnu-gcc-11: ELF 64-bit LSB executable, x86-64, version 1 (GNU/Linux), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=b1112487d0dcb759db32e15b8f40f28a05484272, for GNU/Linux 3.2.0, stripped  "},{"title":"Where is sysroot​","type":1,"pageTitle":"Wiki Cross Compilation","url":"/blog/wiki-cross-compilation#where-is-sysroot","content":"The sysroot locates in /usr/aarch64-linux-gnu, $ tree --filelimit=100 /usr/aarch64-linux-gnu /usr/aarch64-linux-gnu ├── bin │ ├── ar -&gt; ../../bin/aarch64-linux-gnu-ar │ ├── as -&gt; ../../bin/aarch64-linux-gnu-as │ ├── ld -&gt; ../../bin/aarch64-linux-gnu-ld │ ├── ld.bfd -&gt; ../../bin/aarch64-linux-gnu-ld.bfd │ ├── ld.gold -&gt; ../../bin/aarch64-linux-gnu-ld.gold │ ├── nm -&gt; ../../bin/aarch64-linux-gnu-nm │ ├── objcopy -&gt; ../../bin/aarch64-linux-gnu-objcopy │ ├── objdump -&gt; ../../bin/aarch64-linux-gnu-objdump │ ├── ranlib -&gt; ../../bin/aarch64-linux-gnu-ranlib │ ├── readelf -&gt; ../../bin/aarch64-linux-gnu-readelf │ └── strip -&gt; ../../bin/aarch64-linux-gnu-strip ├── include [139 entries exceeds filelimit, not opening dir] └── lib ├── Mcrt1.o ├── Scrt1.o ├── crt1.o ├── crti.o ├── crtn.o ├── gcrt1.o ├── grcrt1.o ├── ld-linux-aarch64.so.1  As you see, the binutils-aarch64-linux-gnu will install binutils tools in /usr/aarch64-linux-gnu/bin, These binutils are also x86_64 binaries,  file $(readlink -f /usr/aarch64-linux-gnu/bin/ar) /usr/bin/aarch64-linux-gnu-ar: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=4f75b6dc6fe5ae92c78a51e6479ca2c65bbf5335, for GNU/Linux 3.2.0, stripped  While target libraries are aarch64 type, file /usr/aarch64-linux-gnu/lib/crt1.o /usr/aarch64-linux-gnu/lib/crt1.o: ELF 64-bit LSB relocatable, ARM aarch64, version 1 (SYSV), for GNU/Linux 3.7.0, not stripped  "},{"title":"Compile hello.c​","type":1,"pageTitle":"Wiki Cross Compilation","url":"/blog/wiki-cross-compilation#compile-helloc","content":"$ aarch64-linux-gnu-gcc-11 hello.c -o a.out $ file a.out a.out: ELF 64-bit LSB pie executable, ARM aarch64, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux-aarch64.so.1, BuildID[sha1]=367c436db0697f16039d9249e4a4e809ef9e68b3, for GNU/Linux 3.7.0, not stripped  "},{"title":"Clang/LLVM​","type":1,"pageTitle":"Wiki Cross Compilation","url":"/blog/wiki-cross-compilation#clangllvm","content":"Cross compilation with Clang and LLVM tools Cross compiling made easy, using Clang and LLVM · mcilloni's blog apt install lld clang llvm  $ wget https://releases.linaro.org/components/toolchain/binaries/7.5-2019.12/aarch64-linux-gnu/sysroot-glibc-linaro-2.25-2019.12-aarch64-linux-gnu.tar.xz $ tar -xvf sysroot-glibc-linaro-2.25-2019.12-aarch64-linux-gnu.tar.xz $ mv sysroot-glibc-linaro-2.25-2019.12-aarch64-linux-gnu aarch64-linux-gnu  $ ll aarch64-linux-gnu total 20K drwxr-xr-x 2 11827 9000 4.0K Dec 4 2019 etc drwxr-xr-x 3 11827 9000 4.0K Dec 4 2019 lib drwxr-xr-x 2 11827 9000 4.0K Dec 4 2019 sbin drwxr-xr-x 8 11827 9000 4.0K Dec 4 2019 usr drwxr-xr-x 3 11827 9000 4.0K Dec 4 2019 var  $ cat &gt; hello.c &lt;&lt; EOL #include &lt;stdio.h&gt; int main(int argc, char *argv[]) { printf(&quot;Hello cross-compilation world!\\n&quot;); return 0; } EOL  sysroot=~/Documents/sysroot/aarch64-linux-gnu/usr  clang --target=aarch64-linux-gnu hello.c -o hello_aarch64 -v  clang --target=aarch64-linux-gnu hello.c -o hello_aarch64 --sysroot=$sysroot -v  clang --target=aarch64-linux-gnu -fsanitize=undefined \\ -fuse-ld=lld \\ --rtlib=compiler-rt -stdlib=libc++ \\ -nostdinc++ -nostdlib \\ -I${sysroot}/usr/include/ \\ -Wl,-L${sysroot}/usr/lib \\ --sysroot=$sysroot \\ --verbose \\ hello.c -o hello  "},{"title":"Resources​","type":1,"pageTitle":"Wiki Cross Compilation","url":"/blog/wiki-cross-compilation#resources","content":"https://wiki.osdev.org/GCC_Cross-Compiler https://github.com/generia/buildroot-osx https://crosstool-ng.github.io/docs/ https://github.com/messense/homebrew-macos-cross-toolchains/blob/main/.github/workflows/aarch64.yml "},{"title":"Wiki Cryptography","type":0,"sectionRef":"#","url":"/blog/wiki-cryptography","content":"","keywords":"Wiki Cryptography"},{"title":"Asymmetric cryptography​","type":1,"pageTitle":"Wiki Cryptography","url":"/blog/wiki-cryptography#asymmetric-cryptography","content":"Also known as public-key cryptography "},{"title":"Symmetric cryptography​","type":1,"pageTitle":"Wiki Cryptography","url":"/blog/wiki-cryptography#symmetric-cryptography","content":""},{"title":"AES-128​","type":1,"pageTitle":"Wiki Cryptography","url":"/blog/wiki-cryptography#aes-128","content":""},{"title":"Resources​","type":1,"pageTitle":"Wiki Cryptography","url":"/blog/wiki-cryptography#resources","content":""},{"title":"Learn CMake","type":0,"sectionRef":"#","url":"/blog/wiki-cmake","content":"","keywords":"cmake project structure"},{"title":"CMake Project Structure​","type":1,"pageTitle":"Learn CMake","url":"/blog/wiki-cmake#cmake-project-structure","content":"A typical CMake project can be regarded to has three Tree: Source Tree: project_root ├── CMakeLists.txt ├── simple_example.cpp ├── simple_lib.cpp └── simple_lib.hpp  Build Tree: project_root ├── CMakeLists.txt ├── simple_example.cpp ├── simple_lib.cpp ├── simple_lib.hpp └── build └── CMakeCache.txt  Install Tree: This tree is located in the CMAKE_INSTALL_PREFIX, of which default value is platform-dependent. By default, it is set to /usr/local on Unix-like systems (Linux, macOS) and C:/Program Files/&lt;Project Name&gt; on Windows.. To change it, you can pass -DCMAKE_INSTALL_PREFIX argument during CMake configuration step, like this: cmake -B build -S . -DCMAKE_INSTALL_PREFIX=/my/custom/installation/path  Alternatively, you can change it by passing --prefix(it can be relative path) argument during CMake install step, like this: cmake --install build --prefix &quot;/my/custom/installation/path&quot;  It's recommended to use a default install layout as GNUInstallDirs. A install tree will look like as below if you'd like all things to be installed inside the project via cmake --install build --prefix &quot;./install. project_root ├── CMakeLists.txt ├── simple_example.cpp ├── simple_lib.cpp ├── simple_lib.hpp ├── build │ └── CMakeCache.txt └── install ├── bin │ └── executables ├── sbin │ └── sysadmin executables ├── lib │ ├── compiled libraries (*.so (unix) or *.dll (windows)) │ └── library archive files (*.lib (windows)) ├── libexec │ └── executables not directly invoked by user ├── include │ └── header files └── doc └── documentation  "},{"title":"How CMake Works​","type":1,"pageTitle":"Learn CMake","url":"/blog/wiki-cmake#how-cmake-works","content":"A typical workflow of CMake includes Configure, Build and Install steps, combined with the above mentioned Trees concepts. Configure step will generate a sort of configuration files, the most important ones among them are CMakeCache.txt, cmake_install.cmake and Makefile if using Make as building system. With these generated configuration files, the later steps Build and Install will run according to them.Build step will generate the build binary directory.Install step will generate the install binary directory. "},{"title":"How to make your package be found by others by find_package()​","type":1,"pageTitle":"Learn CMake","url":"/blog/wiki-cmake#how-to-make-your-package-be-found-by-others-by-find_package","content":"package configuration files: find_package Title "},{"title":"RPATH in CMake​","type":1,"pageTitle":"Learn CMake","url":"/blog/wiki-cmake#rpath-in-cmake","content":"rpath "},{"title":"CMake Variables​","type":1,"pageTitle":"Learn CMake","url":"/blog/wiki-cmake#cmake-variables","content":"There are some useful and important CMake variables that will be introduced here: CMAKE_PREFIX_PATH CMAKE_IGNORE_PATH "},{"title":"clang FAQ​","type":1,"pageTitle":"Learn CMake","url":"/blog/wiki-cmake#clang-faq","content":""},{"title":"Find out clang include search path​","type":1,"pageTitle":"Learn CMake","url":"/blog/wiki-cmake#find-out-clang-include-search-path","content":"❯ clang -x c -v -E /dev/null ... #include &quot;...&quot; search starts here: #include &lt;...&gt; search starts here: /opt/homebrew/Cellar/llvm/17.0.1/lib/clang/17/include /Library/Developer/CommandLineTools/SDKs/MacOSX14.sdk/usr/include /Library/Developer/CommandLineTools/SDKs/MacOSX14.sdk/System/Library/Frameworks (framework directory) End of search list. # 1 &quot;/dev/null&quot; # 1 &quot;&lt;built-in&gt;&quot; 1 # 1 &quot;&lt;built-in&gt;&quot; 3 # 420 &quot;&lt;built-in&gt;&quot; 3 # 1 &quot;&lt;command line&gt;&quot; 1 # 1 &quot;&lt;built-in&gt;&quot; 2 # 1 &quot;/dev/null&quot; 2  "},{"title":"Add include search path to clang​","type":1,"pageTitle":"Learn CMake","url":"/blog/wiki-cmake#add-include-search-path-to-clang","content":"Use environment variables C_INCLUDE_PATH for c and CPLUS_INCLUDE_PATH for c++. clang: ❯ C_INCLUDE_PATH=/opt/homebrew/include clang -x c -v -E /dev/null ... #include &quot;...&quot; search starts here: #include &lt;...&gt; search starts here: /usr/local/include /opt/homebrew/include /Library/Developer/CommandLineTools/usr/lib/clang/15.0.0/include /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include /Library/Developer/CommandLineTools/usr/include /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/System/Library/Frameworks (framework directory)  clang++: ❯ CPLUS_INCLUDE_PATH=/opt/homebrew/include clang -x c++ -v -E /dev/null ... #include &quot;...&quot; search starts here: #include &lt;...&gt; search starts here: /usr/local/include /opt/homebrew/include /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1 /Library/Developer/CommandLineTools/usr/lib/clang/15.0.0/include /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include /Library/Developer/CommandLineTools/usr/include /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/System/Library/Frameworks (framework directory)  Use -I flag, ❯ clang -x c -I/opt/homebrew/include -v -E /dev/null ... #include &quot;...&quot; search starts here: #include &lt;...&gt; search starts here: /opt/homebrew/include /usr/local/include /Library/Developer/CommandLineTools/usr/lib/clang/15.0.0/include /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include /Library/Developer/CommandLineTools/usr/include /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/System/Library/Frameworks (framework directory)  "},{"title":"Find out clang library search paths​","type":1,"pageTitle":"Learn CMake","url":"/blog/wiki-cmake#find-out-clang-library-search-paths","content":"❯ clang -Xlinker -v ... Library search paths: /usr/local/lib Framework search paths: ld: Undefined symbols: _main, referenced from: &lt;initial-undefines&gt; clang: error: linker command failed with exit code 1 (use -v to see invocation)  "},{"title":"Add library search path to clang​","type":1,"pageTitle":"Learn CMake","url":"/blog/wiki-cmake#add-library-search-path-to-clang","content":"Use environment variables LIBRARY_PATH, ❯ LIBRARY_PATH=$LIBRARY_PATH:/usr/lib clang -Xlinker -v ... Library search paths: . /usr/lib /usr/local/lib Framework search paths: ld: Undefined symbols: _main, referenced from: &lt;initial-undefines&gt; clang: error: linker command failed with exit code 1 (use -v to see invocation)  Use -L flag: ❯ clang -L/opt/homebrew/lib -Xlinker -v  https://langui.sh/2015/07/24/osx-clang-include-lib-search-paths/ "},{"title":"What is the difference? clang++ | clang -std=c++11​","type":1,"pageTitle":"Learn CMake","url":"/blog/wiki-cmake#what-is-the-difference-clang--clang--stdc11","content":""},{"title":"CMake FAQ​","type":1,"pageTitle":"Learn CMake","url":"/blog/wiki-cmake#cmake-faq","content":""},{"title":"Add library search path to CMake globally in project​","type":1,"pageTitle":"Learn CMake","url":"/blog/wiki-cmake#add-library-search-path-to-cmake-globally-in-project","content":"set(CMAKE_LIBRARY_PATH ${CMAKE_LIBRARY_PATH} /opt/local/lib)LINK_DIRECTORIES(/opt/local/lib) "},{"title":"Resources​","type":1,"pageTitle":"Learn CMake","url":"/blog/wiki-cmake#resources","content":"CMake hands-on workshop — CMake Workshoprpath: RPATH handling from official cmake "},{"title":"Cyber Security Wiki","type":0,"sectionRef":"#","url":"/blog/wiki-cybersecurity","content":"","keywords":"Wiki Cybersecurity"},{"title":"Resources​","type":1,"pageTitle":"Cyber Security Wiki","url":"/blog/wiki-cybersecurity#resources","content":""},{"title":"Wiki Development Environment","type":0,"sectionRef":"#","url":"/blog/wiki-dev-environment","content":"","keywords":"Wiki Dev Environment"},{"title":"VS Code​","type":1,"pageTitle":"Wiki Development Environment","url":"/blog/wiki-dev-environment#vs-code","content":"As of now, the VS Code is the most popular IDE among developers. Absolutely, for me, it's my first choice and favorite developing tool. "},{"title":"Dev Container​","type":1,"pageTitle":"Wiki Development Environment","url":"/blog/wiki-dev-environment#dev-container","content":"Developing inside a Container using Visual Studio Code Remote Development What is Dev Container? A &quot;Dev Container&quot; typically refers to a development environment that is containerized. Containers are lightweight, portable, and consistent environments that encapsulate an application and its dependencies. They provide a standardized way to package and run software across different environments, ensuring that the application behaves consistently regardless of where it is deployed. The benefits of using Dev Containers include: Consistency: Developers work in the same environment, reducing the chances of environment-related issues.Isolation: Dev Containers are isolated from the host system, preventing conflicts with other software installed on the developer's machine.Reproducibility: The development environment can be easily recreated by anyone using the container specifications.Portability: Dev Containers can be easily shared, allowing developers to work on the same project with minimal setup. Best ways to customize the environment in Dev containers? Using Images, Dockerfile, and Docker Compose:love_you_gesture:Using FeaturesUsing lifecycle scripts How to Write Dockerfile for Dev containers? You can refer to this repo GitHub - devcontainers/images: Repository for pre-built dev container images published under mcr.microsoft.com/devcontainers What magics does the Dev Containers extension do when starting? Hook a default startup command while sleep 1000; do :; done to keep the container not exit. Disable this behavior by setting overrideCommand: false. How to run a container inside of Dev containers? Docker-in-DockerDocker-from-Docker For instance, I use the Docker-in-Docker method to always test/run Docker containers inside of Dev containers. "},{"title":"C/C++​","type":1,"pageTitle":"Wiki Development Environment","url":"/blog/wiki-dev-environment#cc","content":""},{"title":"Resources​","type":1,"pageTitle":"Wiki Development Environment","url":"/blog/wiki-dev-environment#resources","content":""},{"title":"Wiki Emulator","type":0,"sectionRef":"#","url":"/blog/wiki-emulator","content":"","keywords":"Wiki Emulator"},{"title":"Background​","type":1,"pageTitle":"Wiki Emulator","url":"/blog/wiki-emulator#background","content":""},{"title":"Wiki FFmpeg","type":0,"sectionRef":"#","url":"/blog/wiki-ffmpeg","content":"","keywords":"Learn FFmpeg"},{"title":"Best Resources​","type":1,"pageTitle":"Wiki FFmpeg","url":"/blog/wiki-ffmpeg#best-resources","content":"FFmpeg Wiki "},{"title":"Wiki Network","type":0,"sectionRef":"#","url":"/blog/wiki-network","content":"","keywords":"Wiki Proxy"},{"title":"TCP handshake​","type":1,"pageTitle":"Wiki Network","url":"/blog/wiki-network#tcp-handshake","content":""},{"title":"TLS handshake​","type":1,"pageTitle":"Wiki Network","url":"/blog/wiki-network#tls-handshake","content":"https://www.cloudflare.com/learning/ssl/what-happens-in-a-tls-handshake/ "},{"title":"Man-in-the-middle(MitM) or Proxy​","type":1,"pageTitle":"Wiki Network","url":"/blog/wiki-network#man-in-the-middlemitm-or-proxy","content":"https://httptoolkit.com/docs/guides/android/ https://docs.mitmproxy.org/stable/concepts-howmitmproxyworks/ "},{"title":"HTTPS proxy​","type":1,"pageTitle":"Wiki Network","url":"/blog/wiki-network#https-proxy","content":""},{"title":"HTTP proxy​","type":1,"pageTitle":"Wiki Network","url":"/blog/wiki-network#http-proxy","content":""},{"title":"SOCKS proxy​","type":1,"pageTitle":"Wiki Network","url":"/blog/wiki-network#socks-proxy","content":""},{"title":"Resources​","type":1,"pageTitle":"Wiki Network","url":"/blog/wiki-network#resources","content":""},{"title":"Wiki PowerShell","type":0,"sectionRef":"#","url":"/blog/wiki-powershell","content":"Set environment variables permanently [Environment]::SetEnvironmentVariable(&quot;VCPKG_ROOT&quot;, &quot;Whatever you need it to be&quot;, &quot;Machine&quot;) Get environment variables # Get all variables [Environment]::GetEnvironmentVariable() # Get specific variable [Environment]::GetEnvironmentVariable(&quot;VCPKG_ROOT&quot;) ","keywords":"wiki powershell"},{"title":"Wiki NVIDIA Driver and CUDA Library","type":0,"sectionRef":"#","url":"/blog/wiki-cuda","content":"","keywords":"wiki cuda"},{"title":"NVIDIA Driver on Ubuntu​","type":1,"pageTitle":"Wiki NVIDIA Driver and CUDA Library","url":"/blog/wiki-cuda#nvidia-driver-on-ubuntu","content":""},{"title":"Find out whether the host machine have NVIDIA GPU hardware​","type":1,"pageTitle":"Wiki NVIDIA Driver and CUDA Library","url":"/blog/wiki-cuda#find-out-whether-the-host-machine-have-nvidia-gpu-hardware","content":"$ lspci | grep VGA 0000:ac:00.0 VGA compatible controller: NVIDIA Corporation Device 2233 (rev a1)  or, $ sudo lshw -C display *-display description: VGA compatible controller product: NVIDIA Corporation vendor: NVIDIA Corporation physical id: 0 bus info: pci@0000:ac:00.0 logical name: /dev/fb0 version: a1 width: 64 bits clock: 33MHz capabilities: pm msi pciexpress vga_controller bus_master cap_list rom fb configuration: depth=32 driver=nouveau latency=0 resolution=1920,1080 resources: iomemory:204f0-204ef iomemory:204f0-204ef irq:68 memory:99000000-99ffffff memory:204fe0000000-204fefffffff memory:204ff0000000-204ff1ffffff ioport:3000(size=128) memory:9a080000-9a0fffff  or, $ hwinfo --gfxcard --short graphics card: nVidia VGA compatible controller Primary display adapter: #94  "},{"title":"Check which NVIDIA driver being used​","type":1,"pageTitle":"Wiki NVIDIA Driver and CUDA Library","url":"/blog/wiki-cuda#check-which-nvidia-driver-being-used","content":"Ubuntu is using open-source Nouveau drivers $ lsmod | grep nouveau nouveau 2306048 1 mxm_wmi 16384 1 nouveau i2c_algo_bit 16384 1 nouveau drm_ttm_helper 16384 1 nouveau ttm 86016 2 drm_ttm_helper,nouveau drm_kms_helper 311296 1 nouveau drm 622592 5 drm_kms_helper,drm_ttm_helper,ttm,nouveau video 65536 2 dell_wmi,nouveau wmi 32768 7 dell_wmi_sysman,dell_wmi,wmi_bmof,dell_smbios,dell_wmi_descriptor,mxm_wmi,nouveau  Ubuntu is not using the proprietary NVIDIA drivers $ lsmod | grep nvidia  "},{"title":"Install the NVIDIA driver​","type":1,"pageTitle":"Wiki NVIDIA Driver and CUDA Library","url":"/blog/wiki-cuda#install-the-nvidia-driver","content":"Ubuntu Linux Install Nvidia Driver (Latest Proprietary Driver) Install Nvidia Beta Drivers via PPA Repository "},{"title":"Verify the NVIDIA driver​","type":1,"pageTitle":"Wiki NVIDIA Driver and CUDA Library","url":"/blog/wiki-cuda#verify-the-nvidia-driver","content":"nvidia-smi nvidia-smi --query-gpu=driver_version --format=csv  dconfig -p | grep nvidia  "},{"title":"Reload NVIDIA driver​","type":1,"pageTitle":"Wiki NVIDIA Driver and CUDA Library","url":"/blog/wiki-cuda#reload-nvidia-driver","content":"Get related drivers, lsmod | grep nvidia  Unload drivers, sudo rmmod nvidia_drm sudo rmmod nvidia_modeset sudo rmmod nvidia_uvm  sudo rmmod nvidia  Load NVIDIA driver again, nvidia-smi  cuda - Nvidia NVML Driver/library version mismatch - Stack Overflow Prevent updating NVIDIA driver, sudo apt-mark hold nvidia-driver-535 sudo apt-mark hold nvidia-dkms-535 sudo apt-mark hold nvidia-utils-535  updates - How to prevent updating of a specific package? - Ask Ubuntu "},{"title":"NVIDIA CUDA Toolkit on WSL​","type":1,"pageTitle":"Wiki NVIDIA Driver and CUDA Library","url":"/blog/wiki-cuda#nvidia-cuda-toolkit-on-wsl","content":"NVIDIA CUDA software stack on WSL 2:  "},{"title":"NVIDIA CUDA Toolkit on Ubuntu​","type":1,"pageTitle":"Wiki NVIDIA Driver and CUDA Library","url":"/blog/wiki-cuda#nvidia-cuda-toolkit-on-ubuntu","content":"Official documentation: CUDA installation How to Install CUDA on Ubuntu 22.04 LTS "},{"title":"NVIDIA Container Toolkit​","type":1,"pageTitle":"Wiki NVIDIA Driver and CUDA Library","url":"/blog/wiki-cuda#nvidia-container-toolkit","content":"Build and run containers leveraging NVIDIA GPUs, already including CUDA Toolkit.   Prerequisites on Host Machine: Nvidia GPU driverNvidia CUDA Container ToolkitDocker Running a docker container ubuntu, Specialized Configurations with Docker — container-toolkit 1.14.1 documentation $ docker run --rm --gpus all ubuntu nvidia-smi $ docker run --rm --gpus all ubuntu ldconfig -p | grep nvidia libnvidia-ptxjitcompiler.so.1 (libc6,x86-64) =&gt; /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.1 libnvidia-pkcs11-openssl3.so.535.86.05 (libc6,x86-64) =&gt; /usr/lib/x86_64-linux-gnu/libnvidia-pkcs11-openssl3.so.535.86.05 libnvidia-opencl.so.1 (libc6,x86-64) =&gt; /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.1 libnvidia-nvvm.so.4 (libc6,x86-64) =&gt; /usr/lib/x86_64-linux-gnu/libnvidia-nvvm.so.4 libnvidia-ml.so.1 (libc6,x86-64) =&gt; /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1 libnvidia-cfg.so.1 (libc6,x86-64) =&gt; /usr/lib/x86_64-linux-gnu/libnvidia-cfg.so.1 libnvidia-allocator.so.1 (libc6,x86-64) =&gt; /usr/lib/x86_64-linux-gnu/libnvidia-allocator.so.1 $ docker run --rm -e NVIDIA_DRIVER_CAPABILITIES=video --gpus all ubuntu ldconfig -p | grep nvidia libnvidia-ptxjitcompiler.so.1 (libc6,x86-64) =&gt; /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.1 libnvidia-pkcs11-openssl3.so.535.86.05 (libc6,x86-64) =&gt; /usr/lib/x86_64-linux-gnu/libnvidia-pkcs11-openssl3.so.535.86.05 libnvidia-opticalflow.so.1 (libc6,x86-64) =&gt; /usr/lib/x86_64-linux-gnu/libnvidia-opticalflow.so.1 libnvidia-opencl.so.1 (libc6,x86-64) =&gt; /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.1 libnvidia-nvvm.so.4 (libc6,x86-64) =&gt; /usr/lib/x86_64-linux-gnu/libnvidia-nvvm.so.4 libnvidia-encode.so.1 (libc6,x86-64) =&gt; /usr/lib/x86_64-linux-gnu/libnvidia-encode.so.1 libnvidia-allocator.so.1 (libc6,x86-64) =&gt; /usr/lib/x86_64-linux-gnu/libnvidia-allocator.so.1  Running a docker container nvidia/cuda, info Make sure the version of CUDA container nvidia/cuda:xx.x.x-base-ubuntu22.04 such as 12.2.0 in following must be compatible with the version of the Nvidia GPU driver on the host platform such as &gt;525.60.13. docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi  docker run --rm \\ --gpus all \\ -e NVIDIA_VISIBLE_DEVICES=all \\ -e NVIDIA_DRIVER_CAPABILITIES=compute,video,utility,graphics \\ nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi  More Dockerfile examples: Dockerfiledocker compose "},{"title":"FFmpeg in NVIDIA CUDA container​","type":1,"pageTitle":"Wiki NVIDIA Driver and CUDA Library","url":"/blog/wiki-cuda#ffmpeg-in-nvidia-cuda-container","content":"https://developer.nvidia.com/ffmpeg https://docs.nvidia.com/video-technologies/video-codec-sdk/12.0/ffmpeg-with-nvidia-gpu/index.html#compiling-for-linux https://developer.nvidia.com/blog/nvidia-ffmpeg-transcoding-guide/ Install FFmpeg on Nvidia CUDA Container "},{"title":"Known issues​","type":1,"pageTitle":"Wiki NVIDIA Driver and CUDA Library","url":"/blog/wiki-cuda#known-issues","content":"After random long running time, in Nvidia docker the FFmpeg encoding stops and error comes out: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. [Issue]: NVidia Docker transcoding randomly stops working after 5 minutes to 4 hours later. · Issue #9287 · jellyfin/jellyfin · GitHub "},{"title":"References​","type":1,"pageTitle":"Wiki NVIDIA Driver and CUDA Library","url":"/blog/wiki-cuda#references","content":"CUDA And Nvidia Graphics Driver CUDA on WSL User Guide "},{"title":"Wiki Samba","type":0,"sectionRef":"#","url":"/blog/wiki-samba","content":"","keywords":"Wiki Samba"},{"title":"Setting up Samba​","type":1,"pageTitle":"Wiki Samba","url":"/blog/wiki-samba#setting-up-samba","content":"How to Install Samba in Ubuntu "},{"title":"Troubleshooting Samba​","type":1,"pageTitle":"Wiki Samba","url":"/blog/wiki-samba#troubleshooting-samba","content":"Troubleshooting Access Denied on SAMBA - Ask Ubuntu /etc/samba.conf [documents] path = /data/documents valid users = @simon guest ok = no writable = yes browsable = yes  "},{"title":"Wiki Skia","type":0,"sectionRef":"#","url":"/blog/wiki-skia","content":"What the difference between SkImage/SkPicture/SkCanvas/SkSurface? SkBitmap based SkCanvas very slow... How to improve draw speeds? How to move SkImage from CPU to GPU? How to control the SkImage GPU back cache size? As far as I understand when I load SkImage from file or SkBitmap the SkImage lives in CPU side memory. Then the moment I draw this SkImage on a GPU backed canvas it will make a copy of the CPU data into a GPU backed texture. So now we technically have two copies available on the SkImage. Then each time I draw that SkImage it will do it quickly cause it's already in the GPU side.","keywords":""},{"title":"Wiki VPN","type":0,"sectionRef":"#","url":"/blog/wiki-vpn","content":"","keywords":"vpn"},{"title":"Routers Support for VPN(OpenVPN) Client​","type":1,"pageTitle":"Wiki VPN","url":"/blog/wiki-vpn#routers-support-for-vpnopenvpn-client","content":"How to set up a router with Surfshark? – Surfshark Customer Support Routers Supporting VPN Client - Home Network Community "},{"title":"Kill Switch​","type":1,"pageTitle":"Wiki VPN","url":"/blog/wiki-vpn#kill-switch","content":"KillSwitch could be used to block outgoing traffic when the VPN connection drops and crashes. "},{"title":"PF(packet filter) MacOS​","type":1,"pageTitle":"Wiki VPN","url":"/blog/wiki-vpn#pfpacket-filter-macos","content":"Setting up correctly Packet Filter (pf) firewall on any macOS Prevent outgoing traffic unless OpenVPN connection is active using pf.conf on Mac OS X Quick and easy pf (packet filter) firewall rules on macOS A Cheat Sheet For Using pf in OS X Lion and Up OS X PF Manual "},{"title":"Set Up Firewall to Allow Access Only via VPN(KillSwitch)​","type":1,"pageTitle":"Wiki VPN","url":"/blog/wiki-vpn#set-up-firewall-to-allow-access-only-via-vpnkillswitch","content":"ENABLING VPN-ONLY ACCESS TO THE INTERNET WITH WINDOWS FIREWALL KillSwitch for macOS Prevent outgoing traffic unless OpenVPN connection is active using pf.conf on Mac OS X "},{"title":"Wiki vcpkg","type":0,"sectionRef":"#","url":"/blog/wiki-vcpkg","content":"","keywords":"docs docusaurus"},{"title":"Classic mode​","type":1,"pageTitle":"Wiki vcpkg","url":"/blog/wiki-vcpkg#classic-mode","content":"Official saying: In Classic mode, vcpkg maintains a central installed tree inside the vcpkg instance built up by individual vcpkg install and vcpkg remove commands. This central set of packages can then be shared by any number of projects. All packages are installed in a common %VCPKG_ROOT%/installed directory. "},{"title":"Classic mode how-to​","type":1,"pageTitle":"Wiki vcpkg","url":"/blog/wiki-vcpkg#classic-mode-how-to","content":"Just run vcpkg install %package% to use classic mode as the package will be installed into %VCPKG_ROOT%/installed/. "},{"title":"Manifest mode​","type":1,"pageTitle":"Wiki vcpkg","url":"/blog/wiki-vcpkg#manifest-mode","content":"Official saying: In Manifest mode, vcpkg creates separate installed trees for each project and configuration. This allows separate projects to use different versions of libraries. The vcpkg.json file and optional vcpkg-configuration.json file form a project's manifest. The manifest declares the project's direct dependencies, version constraints, and registries used. All packages are installed in their own ${project}/vcpkg_installed directory inside the ${project} directory. "},{"title":"Manifest mode how-to​","type":1,"pageTitle":"Wiki vcpkg","url":"/blog/wiki-vcpkg#manifest-mode-how-to","content":"Create vcpkg.json in the project, then run vcpkg install to use manifest mode as all the packages declared in vcpkg.json will be installed into ${project}/vcpkg_installed/. "},{"title":"Useful environment variables for development​","type":1,"pageTitle":"Wiki vcpkg","url":"/blog/wiki-vcpkg#useful-environment-variables-for-development","content":"CURRENT_INSTALLED_DIRCURRENT_PACKAGES_DIR set(VCPKG_RELEASE_LIBDIR &quot;${CURRENT_INSTALLED_DIR}/lib&quot;) set(VCPKG_DEBUG_LIBDIR &quot;${CURRENT_INSTALLED_DIR}/debug/lib&quot;) set(VCPKG_TOOLS_DIR &quot;${CURRENT_INSTALLED_DIR}/tools&quot;) set(VCPKG_SHARE_DIR &quot;${CURRENT_INSTALLED_DIR}/share&quot;) set(VCPKG_INCLUDE_DIR &quot;${CURRENT_INSTALLED_DIR}/include&quot;)  "},{"title":"Tips and Tricks​","type":1,"pageTitle":"Wiki vcpkg","url":"/blog/wiki-vcpkg#tips-and-tricks","content":""},{"title":"How to specify a compiler fof vcpkg install?​","type":1,"pageTitle":"Wiki vcpkg","url":"/blog/wiki-vcpkg#how-to-specify-a-compiler-fof-vcpkg-install","content":"As vcpkg just use cmake toolchain to do install, how to set a specific compile is cmake things. A fast way is use CC and CXX environment variables. export CC=gcc-4.2 export CXX=/usr/bin/g++-4.2  See more ways at iar - How to specify a compiler in CMake? - Stack Overflow "},{"title":"Install *-osx-dynamic​","type":1,"pageTitle":"Wiki vcpkg","url":"/blog/wiki-vcpkg#install--osx-dynamic","content":"vcpkg install libpq --host-triplet=arm64-osx-dynamic --triplet=arm64-osx-dynamic  "},{"title":"Reinstall packages without caching​","type":1,"pageTitle":"Wiki vcpkg","url":"/blog/wiki-vcpkg#reinstall-packages-without-caching","content":"vcpkg remove icu --host-triplet=arm64-osx-dynamic --triplet=arm64-osx-dynamic vcpkg install icu --host-triplet=arm64-osx-dynamic --triplet=arm64-osx-dynamic --no-binarycaching vcpkg install libpq --host-triplet=arm64-osx-dynamic --triplet=arm64-osx-dynamic --binarysource=clear vcpkg remove libpq --host-triplet=arm64-osx-dynamic --triplet=arm64-osx-dynamic vcpkg remove &quot;qtbase[gui,widgets]&quot; --host-triplet=arm64-osx-dynamic --triplet=arm64-osx-dynamic vcpkg install &quot;qtbase[gui,widgets]&quot; --host-triplet=arm64-osx-dynamic --triplet=arm64-osx-dynamic --no-binarycaching vcpkg install &quot;qtbase[gui,widgets]&quot; --host-triplet=arm64-osx-dynamic --triplet=arm64-osx-dynamic --binarysource=clear  "},{"title":"Clean up all packages​","type":1,"pageTitle":"Wiki vcpkg","url":"/blog/wiki-vcpkg#clean-up-all-packages","content":"rm -rf /opt/vcpkg/installed/ rm -rf /opt/vcpkg/packages/ rm -rf /opt/vcpkg/buildtrees/  "},{"title":"Clean up all caching packages​","type":1,"pageTitle":"Wiki vcpkg","url":"/blog/wiki-vcpkg#clean-up-all-caching-packages","content":"rm -rf ~/.cache/vcpkg/archives/  "},{"title":"INSTALL_RPATH_USE_LINK_PATH different behaviours in manifest mode and classic mode​","type":1,"pageTitle":"Wiki vcpkg","url":"/blog/wiki-vcpkg#install_rpath_use_link_path-different-behaviours-in-manifest-mode-and-classic-mode","content":"INSTALL_RPATH_USE_LINK_PATH will not work properly when being used in the manifest mode, because CMake will don't handle libraries located in buildtree: set_target_properties(${PROJECT_NAME} PROPERTIES INSTALL_RPATH &quot;@executable_path/../Frameworks&quot; INSTALL_RPATH_USE_LINK_PATH ON )  After ${PROJECT_NAME} installed, in the manifest mode: ❯ otoolll /Users/frankchen/Documents/vcpkg-qt-app/install/./helloworld.app/Contents/MacOS/helloworld cmd LC_RPATH cmdsize 48 path @executable_path/../Frameworks (offset 12)  After ${PROJECT_NAME} installed, in the classic mode: ❯ otoolll /Users/frankchen/Documents/vcpkg-qt-app/install/./helloworld.app/Contents/MacOS/helloworld cmd LC_RPATH cmdsize 56 path /opt/vcpkg/installed/arm64-osx-dynamic/lib (offset 12) Load command 27 cmd LC_FUNCTION_STARTS -- cmd LC_RPATH cmdsize 48 path @executable_path/../Frameworks (offset 12)  [wiki-cmake.mdx#RPATH in CMake](/blog/wiki-cmake#RPATH in CMake) "},{"title":"Resources​","type":1,"pageTitle":"Wiki vcpkg","url":"/blog/wiki-vcpkg#resources","content":"TODO: Fix qtbase tools/config in release/debug osx https://github.com/microsoft/vcpkg/tree/master/ports/qtbase https://learn.microsoft.com/en-us/vcpkg/maintainers/functions/vcpkg_cmake_config_fixup "},{"title":"Wiki QEMU","type":0,"sectionRef":"#","url":"/blog/wiki-qemu","content":"","keywords":"Wiki QEMU"},{"title":"OS image Resources​","type":1,"pageTitle":"Wiki QEMU","url":"/blog/wiki-qemu#os-image-resources","content":"Ubuntu OS ImagesDebian OS ImagesRaspberry PI OS Images "},{"title":"QEMU Keyboard shortcuts​","type":1,"pageTitle":"Wiki QEMU","url":"/blog/wiki-qemu#qemu-keyboard-shortcuts","content":"Switch between QEMU monitor console and the guest non-graphic OS CTRL+a c Exit the guest non-graphic OS CTRL+a x Switch between QEMU monitor console and the guest graphic OS CTRL+ALT+1, CTRL+ALT+2 "},{"title":"Discover the VM device tree​","type":1,"pageTitle":"Wiki QEMU","url":"/blog/wiki-qemu#discover-the-vm-device-tree","content":"Enter the QEMU monitor console, using info qtree command, $ info qtree dev: gpex-pcihost, id &quot;&quot; ... bus: pcie.0 type PCIE dev: virtio-scsi-pci, id &quot;&quot; ... bus: virtio-bus type virtio-pci-bus dev: virtio-scsi-device, id &quot;&quot; ... bus: scsi.0 type SCSI dev: scsi-hd, id &quot;&quot; drive = &quot;hd&quot; ... dev: nvme, id &quot;&quot; drive = &quot;drive0&quot; ... bus: nvme-bus.0 type nvme-bus dev: virtio-net-pci, id &quot;&quot; ... bus: virtio-bus type virtio-pci-bus dev: virtio-net-device, id &quot;&quot; ...  "},{"title":"List supported devices​","type":1,"pageTitle":"Wiki QEMU","url":"/blog/wiki-qemu#list-supported-devices","content":"$ qemu-system-aarch64 -device help $ qemu-system-aarch64 -device scsi-hd,help  "},{"title":"Create disk image​","type":1,"pageTitle":"Wiki QEMU","url":"/blog/wiki-qemu#create-disk-image","content":"qemu-img create -f raw ubuntu.raw 20G qemu-img create -f qcow2 ubuntu.qcow2 20G  QEMU can boot from 3 ways: BIOS in defaultLinux kernel and initradUEFI For UEFI boot, the -bios option should be used alongside UEFI firmware(OVMF.fd file) being provided to help QEMU do UEFI boot. For instance it is like: -bios OVMF.fd. Get a prebuilt OVMF file from the OVMF. "},{"title":"BIOS boot​","type":1,"pageTitle":"Wiki QEMU","url":"/blog/wiki-qemu#bios-boot","content":"Test entering BIOS, qemu-system-x86_64 -monitor stdio -m 1G  Then QEMU will show like this,  "},{"title":"Kernel boot​","type":1,"pageTitle":"Wiki QEMU","url":"/blog/wiki-qemu#kernel-boot","content":""},{"title":"UEFI boot​","type":1,"pageTitle":"Wiki QEMU","url":"/blog/wiki-qemu#uefi-boot","content":""},{"title":"Test UEFI boot​","type":1,"pageTitle":"Wiki QEMU","url":"/blog/wiki-qemu#test-uefi-boot","content":"aarch64, efi=&quot;$PWD/UEFI/aarch64/QEMU_EFI.fd&quot; qemu-system-aarch64 -monitor stdio -M virt -cpu cortex-a57 -m 1G -net none -bios $efi qemu-system-aarch64 -nographic -M virt -cpu cortex-a57 -m 1G -net none -bios $efi  x86_64, efi=&quot;$PWD/UEFI/ovmf-x64/OVMF-pure-efi.fd&quot; qemu-system-x86_64 -monitor stdio -m 1G -net none -bios $efi  Then QEMU will drop into the UEFI shell, like this following image show,  Options in detail: -nographic: Don't create a video for the VM, just use the terminal. info quit QEMU: Ctrl+A X. enter QEMU monitor console: Ctrl+A C. see at How to quit the QEMU monitor when not using a GUI? -monitor stdio: Put QEMU monitor console in the terminal, while guest OS kept in created video device. info switch between monitor console and guest OS: Ctrl+Alt+1 or Ctrl+Alt+2. -net none: Disable iPXE. "},{"title":"Boot x86_64 ISO image​","type":1,"pageTitle":"Wiki QEMU","url":"/blog/wiki-qemu#boot-x86_64-iso-image","content":"Boot x86_64 image in Windows, efi=&quot;$PWD/UEFI/ovmf-x64/OVMF-pure-efi.fd&quot; iso=ubuntu-22.04-live-server-amd64.iso  note ubuntu-**-amd64.iso support both UEFI and Legacy BIOS boot, QEMU use BIOS when the option -bios is not specified! Create a disk image to install the ubuntu OS, qemu-img create -f qcow2 ubuntu-image.qcow2 20G  Boot to run the Ubuntu OS qemu-system-x86_64 \\ -monitor stdio \\ -accel whpx \\ -m 8G \\ -smp 4 \\ -drive file=ubuntu-image.qcow2 \\ -bios $efi \\ -cdrom $iso  Options in details, -accel whpx: use hardware acceleration [?]Boot the installed Ubuntu OS # Install OS into a disk image qemu-system-x86_64 \\ -accel whpx \\ -m 8G \\ -smp 4 \\ -bios $efi \\ -drive file=ubuntu.qcow2,format=qcow2,if=virtio \\  "},{"title":"Boot aarch64 ISO image​","type":1,"pageTitle":"Wiki QEMU","url":"/blog/wiki-qemu#boot-aarch64-iso-image","content":"Emulate aarch64 ISO image in Windows, efi=&quot;$PWD/UEFI/aarch64/QEMU_EFI.fd&quot; iso=&quot;ubuntu-22.04-live-server-arm64.iso&quot; qemu-system-aarch64 \\ -monitor stdio \\ -machine virt \\ -cpu cortex-a57 \\ -m 4G \\ -smp 4 \\ -drive file=ubuntu.qcow2,format=raw,if=virtio \\ -bios $efi \\ -cdrom $iso  Emulate aarch64 ISO image in mac M1, qemu-system-aarch64 \\ -monitor stdio \\ -machine virt \\ -accel hvf \\ -cpu host \\ -m 4G \\ -smp 4 \\ -drive file=ubuntu.qcow2,format=raw,if=virtio \\ -bios $efi \\ -cdrom $iso  Options in details, -accel hvf: use hardware acceleration in mac M1.-cpu host: use mac M1 arm CPU. "},{"title":"Boot a preinstalled image​","type":1,"pageTitle":"Wiki QEMU","url":"/blog/wiki-qemu#boot-a-preinstalled-image","content":"# linux fdisk -l ubuntu-core-22-arm64+raspi.img # osx hdiutil imageinfo ubuntu-core-22-arm64+raspi.img  kernel=&quot;$PWD/TinyCore/boot/vmlinuz64&quot; initrd=$&quot;$PWD/TinyCore/boot/corepure64.gz&quot; img=$&quot;$PWD/TinyCorePure64-14.0.iso&quot; efi=&quot;$PWD/UEFI/ovmf-x64/OVMF-pure-efi.fd&quot; kernel=&quot;$PWD/linux_qemu/x86_64/bzImage&quot; vmlinuz=&quot;$PWD/linux_qemu/x86_64/vmlinux&quot; initrd=&quot;$PWD/linux_qemu/x86_64/rootfs.ext2&quot; img=&quot;$PWD/linux_qemu/x86_64/rootfs.ext2&quot;  qemu-system-x86_64 \\ -nographic \\ -m 4G \\ -kernel $kernel \\ -initrd $img \\ -append &quot;console=ttyS0&quot; \\ -netdev user,id=mynet,hostfwd=tcp::2222-:22 \\ -device virtio-net-pci,netdev=mynet  "},{"title":"Boot linux kernel​","type":1,"pageTitle":"Wiki QEMU","url":"/blog/wiki-qemu#boot-linux-kernel","content":""},{"title":"Troubleshooting​","type":1,"pageTitle":"Wiki QEMU","url":"/blog/wiki-qemu#troubleshooting","content":""},{"title":"Resources​","type":1,"pageTitle":"Wiki QEMU","url":"/blog/wiki-qemu#resources","content":"UEFI, PC boot process and UEFI with QEMU | joonas.fi https://medium.com/@ThyCrow/compiling-the-linux-kernel-and-creating-a-bootable-iso-from-it-6afb8d23ba22 https://levelup.gitconnected.com/probably-the-simplest-way-to-install-debian-ubuntu-in-qemu-2db6afde27ef UEFI on AARCH64 | Welcome to the Mike’s homepage! OVMF · tianocore/tianocore.github.io Wiki · GitHub https://wiki.debian.org/Arm64Qemu http://cdn.kernel.org/pub/linux/kernel/people/will/docs/qemu/qemu-arm64-howto.html https://futurewei-cloud.github.io/ARM-Datacenter/qemu/how-to-launch-aarch64-vm/ https://xryan.net/p/212 "},{"title":"Wiki WPF","type":0,"sectionRef":"#","url":"/blog/wiki-wpf","content":"","keywords":"Wiki WPF"},{"title":"MVVM​","type":1,"pageTitle":"Wiki WPF","url":"/blog/wiki-wpf#mvvm","content":"MVVM Pattern Made Simple - CodeProject MVVM in Depth - CodeProject My attempt to understand MVVM pattern and questions raised during it : csharp Patterns - WPF Apps With The Model-View-ViewModel Design Pattern | Microsoft Docs Introduction to the MVVM Toolkit - Windows Community Toolkit | Microsoft Docs "},{"title":"Features​","type":1,"pageTitle":"Wiki WPF","url":"/blog/wiki-wpf#features","content":"IoC, Inversion of Control DI, Dependency Injection Navigation ViewModel-to-ViewModel Communication MVVM Light MessengerEvent Aggregator | PrismReactiveUI - Message Bus Observable Object in ViewModel Wrapping a non-observable model // https://docs.microsoft.com/en-us/windows/communitytoolkit/mvvm/observableobject#wrapping-a-non-observable-model public class ObservableUser : ObservableObject { private readonly User user;mvvm-application.png public ObservableUser(User user) =&gt; this.user = user; public string Name { get =&gt; user.Name; set =&gt; SetProperty(user.Name, value, user, (u, n) =&gt; u.Name = n); } }  "},{"title":"Principles​","type":1,"pageTitle":"Wiki WPF","url":"/blog/wiki-wpf#principles","content":" View-to-ViewModel one-to-one/many-to-one mappingViewModel-to-ViewModel communicationViewModel-to-Model one-to-one/one-to-many binding "},{"title":"Access Database​","type":1,"pageTitle":"Wiki WPF","url":"/blog/wiki-wpf#access-database","content":"DAO or Repository Entity DB Context "},{"title":"ReactiveUI​","type":1,"pageTitle":"Wiki WPF","url":"/blog/wiki-wpf#reactiveui","content":"To property - pasoft-share/ReactiveUI One of the core features of ReactiveUI is to be able to convert properties to Observables, via WhenAny , and to convert Observables into Properties, via a method called ToProperty . These properties are called Output Properties in ReactiveUI, and they are a huge part of using the framework effectively. "},{"title":"Monday, July 3, 2023","type":0,"sectionRef":"#","url":"/journal/2023/07/03","content":"As a backend engineer, there are several core skills that are important for success in the field. These skills include: Programming languages: Proficiency in one or more programming languages is crucial for backend development. Common languages for backend engineering include Python, Java, C#, Ruby, and JavaScript (Node.js). It's important to have a strong understanding of data structures, algorithms, and object-oriented programming concepts. Web frameworks: Familiarity with backend web frameworks is essential. Depending on the language you work with, you should be proficient in frameworks such as Django (Python), Spring (Java), ASP.NET (C#), Ruby on Rails (Ruby), or Express.js (Node.js). These frameworks provide tools and libraries for building robust web applications and services. Databases and query languages: Backend engineers often work with databases to store and retrieve data. Understanding relational databases like MySQL, PostgreSQL, or Oracle, as well as NoSQL databases like MongoDB or Redis, is valuable. Additionally, knowledge of SQL (Structured Query Language) for database querying is important. API development and integration: Backend engineers frequently design and build APIs (Application Programming Interfaces) to enable communication between different systems and services. You should have experience in designing and implementing RESTful APIs and be familiar with tools like Swagger or OpenAPI. Server management and deployment: Understanding server management and deployment processes is essential. Familiarity with cloud platforms like AWS (Amazon Web Services), Azure, or Google Cloud, as well as containerization technologies like Docker and orchestration tools like Kubernetes, is valuable. Security and scalability: Backend engineers need to have a strong understanding of security principles to develop secure applications. Knowledge of authentication and authorization mechanisms, data encryption, and handling user input securely is important. Additionally, understanding scalability concepts and techniques for handling high traffic and load balancing can be beneficial. Testing and debugging: Proficiency in testing and debugging is crucial to ensure the reliability and stability of backend systems. Knowledge of unit testing frameworks, integration testing, and debugging tools is important to identify and fix issues efficiently. Version control systems: Proficiency in version control systems like Git is essential for collaboration and managing code repositories. Understanding branching, merging, and pull requests is important to work effectively in a team. Continuous Integration and Continuous Deployment (CI/CD): Familiarity with CI/CD practices and tools like Jenkins, Travis CI, or CircleCI is valuable. Knowledge of automated testing, build pipelines, and deployment workflows is important to streamline development processes. Problem-solving and analytical thinking: Backend engineers often face complex problems that require analytical thinking and problem-solving skills. The ability to analyze requirements, break down problems into manageable tasks, and devise efficient solutions is highly valuable. Remember, the specific skills required may vary depending on the organization, industry, and technology stack being used. It's important to stay updated with emerging technologies and trends in backend development to remain competitive in the job market. Why Google Search Journey? Google Search Journey groups pages from your search histories by topic or intent, providing a more helpful user experience than just showing a chronological list of pages. Search can, at times, become a rabbit hole. A user may start out looking to book a trip but then get distracted by work or life- or doing several related searches for things they'll need for that trip - and totally forget to book the actual trip. Practice programming skills leetcodecodewars","keywords":""},{"title":"Tuesday, July 4, 2023","type":0,"sectionRef":"#","url":"/journal/2023/07/04","content":"Resumable upload app_resumable_uploadapp_resumable_upload Implementations | tus.io Resumable file upload GitHub - tus/tus-js-client: A pure JavaScript client for the tus resumable upload protocol GitHub - tus/tusd: Reference server implementation in Go of tus: the open protocol for resumable file uploads IO, StreamIO, FileIO high-level used by asyncio.io in socket/tcp/http: Streams — Python 3.11.4 documentation starlette.Request.stream = http Request Body low-level: io — Core tools for working with streams — Python 3.11.4 documentation","keywords":""},{"title":"Sunday, July 16, 2023","type":0,"sectionRef":"#","url":"/journal/2023/07/16","content":"Admission program requirements | University of Ottawa Faculty of Graduate Studies | University of Calgary Graduate Programs - University of Alberta Temporary Foreign Workers - Job Bank 20 Common Resume Buzzwords (and What to Use Instead)","keywords":""},{"title":"Thursday, July 14, 2023","type":0,"sectionRef":"#","url":"/journal/2023/07/14","content":"Best practice: Update markdown metadata such as datetime when saving filesIntroduction | Front Matter Docusaurus refer code snippets from GitHub repositoriesGitHub - saucelabs/docusaurus-theme-github-codeblock: A Docusaurus v2 plugin that supports referencing code examples from public GitHub repositories. src/theme/ReferenceCodeBlock/index.tsx loading... See full example on GitHub code-snippets/XKeyIn.cpp loading... See full example on GitHub Test-Driven Development mindset involving CI, CD, documentation, iterative deliveries Create a local volume to bind a specific local folder, only available in Linux below. docker volume create --opt type=none --opt o=bind --opt device=/data/volumes/testvol testvol ➜ ~ docker inspect testvol [ { &quot;CreatedAt&quot;: &quot;2023-07-13T04:36:16Z&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: {}, &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/testvol/_data&quot;, &quot;Name&quot;: &quot;testvol&quot;, &quot;Options&quot;: { &quot;device&quot;: &quot;/data/volumes/testvol&quot;, &quot;o&quot;: &quot;bind&quot;, &quot;type&quot;: &quot;none&quot; }, &quot;Scope&quot;: &quot;local&quot; } In default, the created volume will just sit on /var/lib/docker/volumes docker volume create defaultvol ➜ ~ docker volume inspect defaultvol [ { &quot;CreatedAt&quot;: &quot;2023-07-13T04:51:57Z&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: null, &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/defaultvol/_data&quot;, &quot;Name&quot;: &quot;defaultvol&quot;, &quot;Options&quot;: null, &quot;Scope&quot;: &quot;local&quot; } Proxies Server: Traefik vs NGINIX Proxies have become an essential networking component and are frequently used with many popular internet services. Proxy servers facilitate requests and responses between end-users and web servers, providing helpful features that augment routing control, privacy, and security. NGINX and Traefik are the most popular tools currently offering proxy functionality. Both solutions can support traditional server-based deployments and containerized application environments, such as Kubernetes. This article will examine both tools in-depth and cover their pros, cons, and distinguishing features. Traefik vs NGINX: Use Case Comparison","keywords":""},{"title":"Thursday, July 20, 2023","type":0,"sectionRef":"#","url":"/journal/2023/07/20","content":" HapiJS Hapi.js — Project Structure and Best Practices (Part 2) Optimizing HapiJS for Benchmarks. In the past year or so, our team… | by Joel Chen | Walmart Global Tech Blog | Medium The confused saying in Microservices: &quot;each service should own its own database and no two services should share a database&quot; No golden rule, no fast rules, no best practices suitable for all businesses, only tradeoff Q: Need separate database per service? A: Creating a separate database for each service helps to enforce domain boundaries. The Hardest Part About Microservices: Your Data – Software Blog Nodejs development practices Set default configs: author name, author email, author url, the license, and the version. npm set init.author.name &quot;Your name&quot; npm set init.author.email &quot;your@email.com&quot; npm set init.author.url &quot;https://your-url.com&quot; npm set init.license &quot;MIT&quot; npm set init.version &quot;1.0.0&quot; function node-project { git init npx license $(npm get init.license) -o &quot;$(npm get init.author.name)&quot; &gt; LICENSE npx gitignore node npx covgen &quot;$(npm get init.author.email)&quot; npm init -y git add -A git commit -m &quot;Initial commit&quot; } Setting up efficient workflows with ESLint, Prettier and TypeScript in vscode. Setting up efficient workflows with ESLint, Prettier and TypeScript - JavaScript inDepth","keywords":""},{"title":"Wiki Unicode","type":0,"sectionRef":"#","url":"/blog/wiki-unicode","content":"","keywords":"Wiki UTF8"},{"title":"FAQ​","type":1,"pageTitle":"Wiki Unicode","url":"/blog/wiki-unicode#faq","content":""},{"title":"How a character is displayed on the screen?​","type":1,"pageTitle":"Wiki Unicode","url":"/blog/wiki-unicode#how-a-character-is-displayed-on-the-screen","content":"software maps each character to its glyph(a grid of pixels), draw these pixels onto the screen. "},{"title":"How to find out whether the file uses UTF-8 or ASCII or other encoding schemas?​","type":1,"pageTitle":"Wiki Unicode","url":"/blog/wiki-unicode#how-to-find-out-whether-the-file-uses-utf-8-or-ascii-or-other-encoding-schemas","content":"It's not always foolproof because there is no universal mandate or requirement that all files must specify their encoding. But it's a good practice to add BOM(Byte Order Mark) at the beginning of a UTF-8 encoded file. "},{"title":"Can I set UTF-16 as locale in Linux?​","type":1,"pageTitle":"Wiki Unicode","url":"/blog/wiki-unicode#can-i-set-utf-16-as-locale-in-linux","content":"No, you cannot. Linux use UTF-8 encoding which is compatible with ASCII. "},{"title":"What happens when printing a UTF-16 file in Linux?​","type":1,"pageTitle":"Wiki Unicode","url":"/blog/wiki-unicode#what-happens-when-printing-a-utf-16-file-in-linux","content":"# &gt;&gt;&gt; '€'.encode(&quot;utf16&quot;) -&gt; b'\\xff\\xfe\\xac ' $ echo -n -e \\\\xff\\\\xfe\\\\xac\\\\x20 &gt; a.txt $ hexdump -C a.txt 00000000 ff fe ac 20 |... | 00000004 $ file a.txt a.txt: Unicode text, UTF-16, little-endian text, with no line terminators $ cat a.txt ��� $ iconv -f UTF-16LE -t UTF-8 a.txt €  "},{"title":"How can I check a UTF-8 file has a BOM?​","type":1,"pageTitle":"Wiki Unicode","url":"/blog/wiki-unicode#how-can-i-check-a-utf-8-file-has-a-bom","content":"Create a file without BOM, &gt;&gt;&gt; f.flush() &gt;&gt;&gt; b'\\xe2\\x82\\xac'.decode() '€' &gt;&gt;&gt; '€'.encode() b'\\xe2\\x82\\xac' &gt;&gt;&gt; bom=b&quot;\\xef\\xbb\\xbf&quot; &gt;&gt;&gt; f=open(&quot;a.txt&quot;, &quot;wb+&quot;) &gt;&gt;&gt; f.write(b'\\xe2\\x82\\xac') 3 &gt;&gt;&gt; f.flush()  $ file a.txt a.txt: Unicode text, UTF-8 text, with no line terminators  Create a BOM adhere file, &gt;&gt;&gt; f.seek(0) 0 &gt;&gt;&gt; f.truncate(0) 0 &gt;&gt;&gt; f.write(b'\\xef\\xbb\\xbf\\xe2\\x82\\xac') 6 &gt;&gt;&gt; f.flush()  $ file a.txt a.txt: Unicode text, UTF-8 (with BOM) text, with no line terminators $ hexdump -C a.txt 00000000 ef bb bf e2 82 ac |......| 00000006  "},{"title":"Why we can copy and paste the unicode characters into a shell?​","type":1,"pageTitle":"Wiki Unicode","url":"/blog/wiki-unicode#why-we-can-copy-and-paste-the-unicode-characters-into-a-shell","content":"When we do copying on the screen, we're copying the character's UTF8 encoded bytes which is in the memory, not the code point. # b'\\xe2\\x82\\xac'.decode() -&gt; '€' $ echo -e \\\\xe2\\\\x82\\\\xac | xclip -selection clipboard  Then you can use your mouse right click to copy to the shell and you will see €. "},{"title":"How a string is stored in memory when Python running?​","type":1,"pageTitle":"Wiki Unicode","url":"/blog/wiki-unicode#how-a-string-is-stored-in-memory-when-python-running","content":""},{"title":"Unicode in JSON​","type":1,"pageTitle":"Wiki Unicode","url":"/blog/wiki-unicode#unicode-in-json","content":"JSON(natively a text format) support the unicode character to be escaped or not. When being escaped, the character will be replaced with the unicode code point, then which will be represented in 6 or 8 ascii characters occupying 6 or 8 bytes. When not being escaped, the character will be represented as just one unicode character as itself occupying 1 to 4 bytes if using UTF-8. Escaping will cost more storage but will be compatible in ASCII-only environments, as escaping force all characters to be ASCII characters. Case 1: Characters escaped, &gt;&gt;&gt; import json &gt;&gt;&gt; b=b'{&quot;text&quot;: &quot;\\u4f60\\u597d&quot;}' &gt;&gt;&gt; json.loads(b) {'text': '你好'}jsn &gt;&gt;&gt; json.dumps(json.loads(b)) '{&quot;text&quot;: &quot;\\\\u4f60\\\\u597d&quot;}' &gt;&gt;&gt; json.dumps(json.loads(b), ensure_ascii=False) '{&quot;text&quot;: &quot;你好&quot;}'  &gt;&gt;&gt; f=open(&quot;a.txt&quot;, &quot;w+&quot;) &gt;&gt;&gt; f.write(json.dumps(json.loads(b))) 24 &gt;&gt;&gt; f.flush()  $ cat a.txt {&quot;text&quot;: &quot;\\u4f60\\u597d&quot;}# $ hexdump -C a.txt 00000000 7b 22 74 65 78 74 22 3a 20 22 5c 75 34 66 36 30 |{&quot;text&quot;: &quot;\\u4f60| 00000010 5c 75 35 39 37 64 22 7d |\\u597d&quot;}| 00000018  Case 2: Characters not escaped, &gt;&gt;&gt; f.seek(0) 0 &gt;&gt;&gt; f.truncate(0) 0 &gt;&gt;&gt; f.write(json.dumps(json.loads(b), ensure_ascii=False)) 14 &gt;&gt;&gt; f.flush()  $ cat a.txt {&quot;text&quot;: &quot;你好&quot;}# $ hexdump -C a.txt 00000000 7b 22 74 65 78 74 22 3a 20 22 e4 bd a0 e5 a5 bd |{&quot;text&quot;: &quot;......| 00000010 22 7d |&quot;}| 00000012  "},{"title":"Base64​","type":1,"pageTitle":"Wiki Unicode","url":"/blog/wiki-unicode#base64","content":"Base64 is binary-to-text encoding schema which make bytes data to be represented in ASCII characters to be human readable. "},{"title":"Python​","type":1,"pageTitle":"Wiki Unicode","url":"/blog/wiki-unicode#python","content":""},{"title":"C application​","type":1,"pageTitle":"Wiki Unicode","url":"/blog/wiki-unicode#c-application","content":"Let's have a look at how the Unicode is represented in a C executable file. char cat &gt; unicode.c &lt;&lt; EOL #include &lt;stdio.h&gt; int main(){ printf(&quot;Hello, World 你好🤨!\\n&quot;); return 0; } EOL  gcc unicode.c -o unicode.out  root@112b172acfff:/workspaces/liviaerxin.github.io/# hexdump -C unicode.out | grep -A3 &quot;Hello, World&quot; 00002000 01 00 02 00 48 65 6c 6c 6f 2c 20 57 6f 72 6c 64 |....Hello, World| 00002010 20 e4 bd a0 e5 a5 bd f0 9f a4 a8 21 00 00 00 00 | ..........!....| 00002020 01 1b 03 3b 34 00 00 00 05 00 00 00 00 f0 ff ff |...;4...........| 00002030 68 00 00 00 20 f0 ff ff 90 00 00 00 30 f0 ff ff |h... .......0...|  View each character's UTF8 encoding respectively, # utf-8 encoding bytes &gt;&gt;&gt; &quot;你&quot;.encode() b'\\xe4\\xbd\\xa0' &gt;&gt;&gt; &quot;好&quot;.encode() b'\\xe5\\xa5\\xbd' &gt;&gt;&gt; &quot;🤨&quot;.encode() b'\\xf0\\x9f\\xa4\\xa8'  So char in the C output file stores the UTF8 encoding bytes, not the code points. wide char, cat &gt; unicode.c &lt;&lt; EOL #include &lt;stdio.h&gt; #include &lt;wchar.h&gt; #include &lt;locale.h&gt; int main(int argc, char *argv[]) { setlocale(LC_ALL, &quot;C.UTF-8&quot;); wchar_t* msg = L&quot;Hello, World 你好🤨!&quot;; printf(&quot;%ls\\n&quot;, msg); return 0; } EOL  root@112b172acfff:/workspaces/liviaerxin.github.io/# hexdump -C unicode.out 00002000 01 00 02 00 00 00 00 00 43 2e 55 54 46 2d 38 00 |........C.UTF-8.| 00002010 48 00 00 00 65 00 00 00 6c 00 00 00 6c 00 00 00 |H...e...l...l...| 00002020 6f 00 00 00 2c 00 00 00 20 00 00 00 57 00 00 00 |o...,... ...W...| 00002030 6f 00 00 00 72 00 00 00 6c 00 00 00 64 00 00 00 |o...r...l...d...| 00002040 20 00 00 00 60 4f 00 00 7d 59 00 00 28 f9 01 00 | ...`O..}Y..(...|  # unicode code point &gt;&gt;&gt; hex(ord(&quot;H&quot;)) '0x48' &gt;&gt;&gt; hex(ord(&quot;你&quot;)) '0x4f60' &gt;&gt;&gt; hex(ord(&quot;好&quot;)) '0x597d' &gt;&gt;&gt; hex(ord(&quot;🤨&quot;)) '0x1f928'  wchar in the C output file stores the code point(also in little endian), not the UTF8 encoding bytes. In conclusion, char and wchar lead different encoding in C. "},{"title":"Resources​","type":1,"pageTitle":"Wiki Unicode","url":"/blog/wiki-unicode#resources","content":"The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!) – Joel on Software Pragmatic Unicode | Ned Batchelder "},{"title":"Friday, July 21, 2023","type":0,"sectionRef":"#","url":"/journal/2023/07/21","content":" Mysql, redis, or other db connections pool vs as single connection in Nodejs Since Node.js and Redis are both effectively single threaded there is no need to use multiple client instances or any pooling mechanism save for a few exceptions;","keywords":""},{"title":"Tuesday, July 25, 2023","type":0,"sectionRef":"#","url":"/journal/2023/07/25","content":" Authentication and Authorization in Microservices Authentication in microservices involves two main occasions: authentication required when end users communicate with services.authentication happens between internal services.authentication needed when external services enter internal services. OAuth 2.0 provides the industry-standard protocol for authorizing users in distributed systems. The OAuth framework reduces the burden on developers, eliminating duplications to build their own authentication mechanism in each microservice. Authentication &amp; Authorization in Microservices Architecture - Part I https://softwareengineering.stackexchange.com/questions/366815/microservice-architecture-using-auth-server-as-a-user-resource-server https://auth0.com/docs/get-started User registration flow in microservice Communication between microservices Share user data between micro services User service and Comment service populate user data into Comment service, save user data in comment service, update user data in comment service https://stackoverflow.com/questions/67543408/microservices-storing-user-data-in-separate-database Ideally, the client communicates with the each service directly, and no interaction between the services! However, there is the need for communication between these services. For example, o what happens if a user deletes his account? What if you delete a TV show? You probably want to trigger some events that will update the data in your comment microservice. In the long run you want to keep everything &quot;eventually consistent&quot;. The event-driven architecture comes up! Data retrieved from two or more services For example, you send a request from UI saying &quot;give me comments with usernames&quot;, GraphQL interface then first issues a request to comments service, then to user service and finally sends one response with combined data NOTE: issue a number of requests to various micro-services to collect all the data and return it in only 1 response Rest needs to send many. https://softwareengineering.stackexchange.com/questions/418153/design-a-correct-microservices-architecture-with-data-relations Event-Driven Data Management for Microservices - NGINX","keywords":""},{"title":"Wednesday, July 19, 2023","type":0,"sectionRef":"#","url":"/journal/2023/07/19","content":" I still prefer os.path over Pathlib, as follows Consistency, I'm used to use path string as an argument between functions and I think Pathlib is not flexible enough to handle argumentsPure and Function, Although Pathlib brings many useful features like glob, stem, and so on. I still like the concept of simplicity that don't put all things together! Trim $ for clipboard copy in Docusaurus in code block bash. Ignore $ for clipboard copy · Issue #1745 · facebook/docusaurus · GitHub Some common issues I often hit when using git Configure username/password for different repos or remotes Global configuration git config --global --list git config --local --list GIT two popular authentication methods: ssh key How to Authenticate Your Git to GitHub with SSH Keys git credentials Store username/password instead of ssh for multiple remotes To enable git credentials # local git config credential.helper store # global git config --global credential.helper store Each credential is stored in ~/.git-credentials file on its own line as a URL like: https://&lt;USERNAME&gt;:&lt;PASSWORD&gt;@github.com Configure credentials, # Global git config --global credential.https://github.com.username &lt;your_username&gt; # Or git config --local user.name &lt;your_username&gt; git config --local user.email &lt;your_useremail&gt; # Then git pull or git push to let it cache your username/password after it prompt you to input password in the first time Alternatively, we can directly edit our global Git config file ~/.gitconfig, [credential &quot;https://github.com&quot;] username = &lt;username&gt; Git - Config Username &amp; Password - Store Credentials - ShellHacks Configuring Git Credentials Programming Algorithms Top Algorithms Every Programmer Should Know What is Algorithm | Introduction to Algorithms - GeeksforGeeks","keywords":""},{"title":"Wednesday, July 26, 2023","type":0,"sectionRef":"#","url":"/journal/2023/07/26","content":"postgres + node + data model(typescript) Build a Data Access Layer with PostgreSQL and Node.js | AppSignal Blog","keywords":""},{"title":"Friday, August 4, 2023","type":0,"sectionRef":"#","url":"/journal/2023/08/04","content":" Authentication and Authorization in Microservices Authentication and Authorization in each serviceAuthentication in a centralized service, and Authorization in each serviceAuthentication and Authorization in a centralized service Auth Service and User (Profile) Service Never write a UserService again. Or when to use external Microservices Microservices Authentication Best Strategy | Aspecto Authentication and Authorization Concepts for MicroServices · GitHub design - Microservice Architecture - using Auth Server as a User Resource server How to Run Your Own Decentralized Authentication Service Using AuthN Implement event-driven architecture microservices using Redis Using Redis as an Event Store for Communication Between Microservices","keywords":""},{"title":"Monday, August 14, 2023","type":0,"sectionRef":"#","url":"/journal/2023/08/14","content":" Write best ChatGPT prompts https://stackoverflow.com/questions/6760685/creating-a-singleton-in-python https://codereview.stackexchange.com/questions/31789/progress-report-for-a-long-running-process-using-yield","keywords":""}]